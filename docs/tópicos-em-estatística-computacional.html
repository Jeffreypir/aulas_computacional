<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Tópicos em Estatística Computacional | ESTATÍSTICA COMPUTACIONAL</title>
  <meta name="description" content="Disciplina de Estatística Computacional - Departamento de Estatística" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Tópicos em Estatística Computacional | ESTATÍSTICA COMPUTACIONAL" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://prdm0.github.io/aulas_computacional/" />
  
  <meta property="og:description" content="Disciplina de Estatística Computacional - Departamento de Estatística" />
  <meta name="github-repo" content="prdm0/aulas_computacional" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Tópicos em Estatística Computacional | ESTATÍSTICA COMPUTACIONAL" />
  
  <meta name="twitter:description" content="Disciplina de Estatística Computacional - Departamento de Estatística" />
  

<meta name="author" content="Docente: Prof. Dr. Pedro Rafael Diniz Marinho   E-mail: pedro.rafael.marinho@gmail.com / pedro@de.ufpb.br   Website: https://prdm0.rbind.io" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="r-miscelânea-e-tópicos-avançados.html"/>

<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<script src="libs/d3-3.3.8/d3.min.js"></script>
<script src="libs/dagre-0.4.0/dagre-d3.min.js"></script>
<link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet" />
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/chromatography-0.1/chromatography.js"></script>
<script src="libs/DiagrammeR-binding-1.0.6.1/DiagrammeR.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Início</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html"><i class="fa fa-check"></i>Prefácio</a>
<ul>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html#tecnologias-abordadas-no-curso"><i class="fa fa-check"></i>Tecnologias abordadas no curso</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html#teorias-abordadas-no-curso"><i class="fa fa-check"></i>Teorias abordadas no curso</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html#sugestões-de-passos-para-revisão-da-linguagem-r"><i class="fa fa-check"></i>Sugestões de passos para revisão da linguagem R</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="revisão-básica-da-linguagem-r.html"><a href="revisão-básica-da-linguagem-r.html"><i class="fa fa-check"></i><b>1</b> Revisão básica da linguagem R</a>
<ul>
<li class="chapter" data-level="" data-path="revisão-básica-da-linguagem-r.html"><a href="revisão-básica-da-linguagem-r.html#exercícios-propostos"><i class="fa fa-check"></i>Exercícios propostos</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sistemas-gnulinux.html"><a href="sistemas-gnulinux.html"><i class="fa fa-check"></i><b>2</b> Sistemas GNU/Linux</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sistemas-gnulinux.html"><a href="sistemas-gnulinux.html#um-breve-histórico"><i class="fa fa-check"></i><b>2.1</b> Um breve histórico</a></li>
<li class="chapter" data-level="2.2" data-path="sistemas-gnulinux.html"><a href="sistemas-gnulinux.html#vantagens-em-utilizar-gnulinux"><i class="fa fa-check"></i><b>2.2</b> Vantagens em utilizar GNU/Linux</a></li>
<li class="chapter" data-level="2.3" data-path="sistemas-gnulinux.html"><a href="sistemas-gnulinux.html#algumas-distribuições"><i class="fa fa-check"></i><b>2.3</b> Algumas distribuições</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="versionamento-de-código.html"><a href="versionamento-de-código.html"><i class="fa fa-check"></i><b>3</b> Versionamento de código</a>
<ul>
<li class="chapter" data-level="3.1" data-path="versionamento-de-código.html"><a href="versionamento-de-código.html#git"><i class="fa fa-check"></i><b>3.1</b> Git</a></li>
<li class="chapter" data-level="3.2" data-path="versionamento-de-código.html"><a href="versionamento-de-código.html#github"><i class="fa fa-check"></i><b>3.2</b> GitHub</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="relatório-markdown-em-r.html"><a href="relatório-markdown-em-r.html"><i class="fa fa-check"></i><b>4</b> Relatório Markdown em R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="relatório-markdown-em-r.html"><a href="relatório-markdown-em-r.html#markdown"><i class="fa fa-check"></i><b>4.1</b> Markdown</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="relatório-markdown-em-r.html"><a href="relatório-markdown-em-r.html#sintaxe"><i class="fa fa-check"></i><b>4.1.1</b> Sintaxe</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="relatório-markdown-em-r.html"><a href="relatório-markdown-em-r.html#r-markdown"><i class="fa fa-check"></i><b>4.2</b> R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html"><i class="fa fa-check"></i><b>5</b> R - miscelânea e tópicos avançados</a>
<ul>
<li class="chapter" data-level="5.1" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#operador---pipe"><i class="fa fa-check"></i><b>5.1</b> Operador %&gt;% - Pipe</a>
<ul>
<li class="chapter" data-level="" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#exercícios-1"><i class="fa fa-check"></i>Exercícios</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#funções"><i class="fa fa-check"></i><b>5.2</b> Funções</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#passando-atributos"><i class="fa fa-check"></i><b>5.2.1</b> Passando atributos</a></li>
<li class="chapter" data-level="5.2.2" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#funções-anônimas"><i class="fa fa-check"></i><b>5.2.2</b> Funções anônimas</a></li>
<li class="chapter" data-level="5.2.3" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#escopo-léxico"><i class="fa fa-check"></i><b>5.2.3</b> Escopo léxico</a></li>
<li class="chapter" data-level="5.2.4" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#avaliação-preguiçosa"><i class="fa fa-check"></i><b>5.2.4</b> Avaliação preguiçosa</a></li>
<li class="chapter" data-level="5.2.5" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#varargs-dot-dot-dot"><i class="fa fa-check"></i><b>5.2.5</b> varargs: … (dot-dot-dot)</a></li>
<li class="chapter" data-level="5.2.6" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#funções-infixas"><i class="fa fa-check"></i><b>5.2.6</b> Funções infixas</a></li>
<li class="chapter" data-level="5.2.7" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#função-de-substituição"><i class="fa fa-check"></i><b>5.2.7</b> Função de substituição</a></li>
<li class="chapter" data-level="5.2.8" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#closures"><i class="fa fa-check"></i><b>5.2.8</b> Closures</a></li>
<li class="chapter" data-level="" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#exercícios-2"><i class="fa fa-check"></i>Exercícios</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#funcionais"><i class="fa fa-check"></i><b>5.3</b> Funcionais</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#funcionais-do-r-base"><i class="fa fa-check"></i><b>5.3.1</b> Funcionais do R Base</a></li>
<li class="chapter" data-level="5.3.2" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#funcionais-do-pacote-purrr"><i class="fa fa-check"></i><b>5.3.2</b> Funcionais do pacote purrr</a></li>
<li class="chapter" data-level="" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#exercícios-3"><i class="fa fa-check"></i>Exercícios</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#sistema-s3"><i class="fa fa-check"></i><b>5.4</b> Sistema S3</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#classes"><i class="fa fa-check"></i><b>5.4.1</b> Classes</a></li>
<li class="chapter" data-level="5.4.2" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#criando-funções-genéricas"><i class="fa fa-check"></i><b>5.4.2</b> Criando funções genéricas</a></li>
<li class="chapter" data-level="" data-path="r-miscelânea-e-tópicos-avançados.html"><a href="r-miscelânea-e-tópicos-avançados.html#exercício"><i class="fa fa-check"></i>Exercício</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html"><i class="fa fa-check"></i><b>6</b> Tópicos em Estatística Computacional</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#geração-de-números-pseudo-aleatórios"><i class="fa fa-check"></i><b>6.1</b> Geração de Números Pseudo-Aleatórios</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#método-da-transformação-inversa-caso-discreto"><i class="fa fa-check"></i><b>6.1.1</b> Método da Transformação Inversa (Caso Discreto)</a></li>
<li class="chapter" data-level="6.1.2" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#método-da-aceitação-e-rejeição"><i class="fa fa-check"></i><b>6.1.2</b> Método da aceitação e rejeição</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#exercício-1"><i class="fa fa-check"></i>Exercício</a></li>
<li class="chapter" data-level="6.2" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#otimização-não-linear"><i class="fa fa-check"></i><b>6.2</b> Otimização Não-Linear</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#metódos-gradiente"><i class="fa fa-check"></i><b>6.2.1</b> Metódos Gradiente</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#otimização-não-linear-no-r"><i class="fa fa-check"></i><b>6.3</b> Otimização não-linear no R</a></li>
<li class="chapter" data-level="" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#exercício-2"><i class="fa fa-check"></i>Exercício</a></li>
<li class="chapter" data-level="6.4" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#monte-carlo"><i class="fa fa-check"></i><b>6.4</b> Monte Carlo</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#um-breve-histórico-1"><i class="fa fa-check"></i><b>6.4.1</b> Um breve histórico</a></li>
<li class="chapter" data-level="6.4.2" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#métodos-de-monte-carlo"><i class="fa fa-check"></i><b>6.4.2</b> Métodos de Monte Carlo</a></li>
<li class="chapter" data-level="6.4.3" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#integração-por-monte-carlo"><i class="fa fa-check"></i><b>6.4.3</b> Integração por Monte Carlo</a></li>
<li class="chapter" data-level="6.4.4" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#aproximando-o-valor-de-pi"><i class="fa fa-check"></i><b>6.4.4</b> Aproximando o valor de <span class="math inline">\(\pi\)</span></a></li>
<li class="chapter" data-level="6.4.5" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#paralelizando-um-procedimento-de-monte-carlo"><i class="fa fa-check"></i><b>6.4.5</b> Paralelizando um procedimento de Monte Carlo</a></li>
<li class="chapter" data-level="6.4.6" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#speedup"><i class="fa fa-check"></i><b>6.4.6</b> Speedup</a></li>
<li class="chapter" data-level="6.4.7" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#pacote-parallel"><i class="fa fa-check"></i><b>6.4.7</b> Pacote parallel</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#exercício-3"><i class="fa fa-check"></i>Exercício</a></li>
<li class="chapter" data-level="6.5" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#bootstrap"><i class="fa fa-check"></i><b>6.5</b> Bootstrap</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#estimando-erro-padrão"><i class="fa fa-check"></i><b>6.5.1</b> Estimando erro-padrão</a></li>
<li class="chapter" data-level="6.5.2" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#diminuindo-o-viés"><i class="fa fa-check"></i><b>6.5.2</b> Diminuindo o viés</a></li>
<li class="chapter" data-level="6.5.3" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#construindo-intervalos-aleatórios"><i class="fa fa-check"></i><b>6.5.3</b> Construindo intervalos aleatórios</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tópicos-em-estatística-computacional.html"><a href="tópicos-em-estatística-computacional.html#exercício-4"><i class="fa fa-check"></i>Exercício</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ESTATÍSTICA COMPUTACIONAL</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tópicos-em-estatística-computacional" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Tópicos em Estatística Computacional</h1>
<div id="geração-de-números-pseudo-aleatórios" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Geração de Números Pseudo-Aleatórios</h2>
<p>O conteúdo para esse tópico entra-se em PDF e poderá ser acessado <a href="files/computacional.pdf"><strong>aqui</strong></a>. Em um futuro próximo, essa seção será reescrita e fará parte do corpo deste HTML.</p>
<div id="método-da-transformação-inversa-caso-discreto" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Método da Transformação Inversa (Caso Discreto)</h3>
<p>O método da transformação inversa também poderá ser aplicado também para gerar observações de v.a.’s discretas. Seja <span class="math inline">\(X\)</span> uma v.a. discreta, tal que</p>
<p><span class="math display">\[... &lt; x_{i-1} &lt; x_i &lt; x_{i+1} &lt;\, ...\,.\]</span>
As observações acima são pontos de descontinuidade de <span class="math inline">\(F_X(x)\)</span>. Então, a transformação inversa é <span class="math inline">\(F_X^{-1} = x_i\)</span>, quando <span class="math inline">\(F_X(x_{i-1}) &lt; u \leq F_X(x_i)\)</span>. O algoritmo que segue poderá ser utilizado para gerar observações de <span class="math inline">\(X\)</span>.</p>
<p><strong>Algoritmo</strong>:</p>
<ol style="list-style-type: decimal">
<li>Gere um número pseudo-leatório <span class="math inline">\(u\)</span> de uma v.a. <span class="math inline">\(U \sim \mathcal{U}(0,1)\)</span>;</li>
<li>Retorne <span class="math inline">\(x_i\)</span> como observação de <span class="math inline">\(X\)</span>, tal que <span class="math inline">\(F(x_{i-1}) &lt; u \leq F(x_i)\)</span>.</li>
</ol>
<p>Em outras palavras, gere <span class="math inline">\(u\)</span> de uma v.a. <span class="math inline">\(U \sim \mathcal{U}(0,1)\)</span> e compare na sequência:</p>
<ol style="list-style-type: decimal">
<li>Se <span class="math inline">\(u &lt; p_0\)</span>, faça <span class="math inline">\(X = x_0\)</span> e pare;</li>
<li>Se <span class="math inline">\(p_0 \leq u &lt; p_0 + p_1\)</span>, faça <span class="math inline">\(X = x_1\)</span> e pare;</li>
<li>Se <span class="math inline">\(p_0 + p_1\leq u &lt; p_0 + p_1 + p_2\)</span>, faça <span class="math inline">\(X = x_2\)</span> e pare;</li>
<li>…</li>
<li>Se <span class="math inline">\(\sum_{i = 0}^{j-1} p_i \leq u &lt; \sum_{i=0}^j p_i\)</span>, faça <span class="math inline">\(X = x_j\)</span> e pare;</li>
<li>…</li>
</ol>
<p>em que <span class="math inline">\(p_j = P(X = j)\)</span>.</p>
<p><strong>Exemplo</strong>: Implemente, em R, uma função que retorna a quantidade de observações de uma v.a. <span class="math inline">\(X\)</span> com função de probabilidade:</p>
<p><span class="math display">\[P(X = 1) = 0.3, P(X = 2) = 0.2, P(X = 3) = 0.35, P(X = 4) = 0.15.\]</span></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="tópicos-em-estatística-computacional.html#cb1-1" aria-hidden="true"></a>random &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">n =</span> 1L){</span>
<span id="cb1-2"><a href="tópicos-em-estatística-computacional.html#cb1-2" aria-hidden="true"></a>  x &lt;-<span class="st"> </span>1L<span class="op">:</span>4L</span>
<span id="cb1-3"><a href="tópicos-em-estatística-computacional.html#cb1-3" aria-hidden="true"></a>  probs &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.3</span>, <span class="fl">0.2</span>, <span class="fl">0.35</span>, <span class="fl">0.15</span>)</span>
<span id="cb1-4"><a href="tópicos-em-estatística-computacional.html#cb1-4" aria-hidden="true"></a>  </span>
<span id="cb1-5"><a href="tópicos-em-estatística-computacional.html#cb1-5" aria-hidden="true"></a>  u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>)</span>
<span id="cb1-6"><a href="tópicos-em-estatística-computacional.html#cb1-6" aria-hidden="true"></a>  </span>
<span id="cb1-7"><a href="tópicos-em-estatística-computacional.html#cb1-7" aria-hidden="true"></a>  <span class="co"># Criando uma função para ser passada à um funcional.</span></span>
<span id="cb1-8"><a href="tópicos-em-estatística-computacional.html#cb1-8" aria-hidden="true"></a>  comp &lt;-<span class="st"> </span><span class="cf">function</span>(u){</span>
<span id="cb1-9"><a href="tópicos-em-estatística-computacional.html#cb1-9" aria-hidden="true"></a>    <span class="co"># Retorna a primeira ocorrência de TRUE</span></span>
<span id="cb1-10"><a href="tópicos-em-estatística-computacional.html#cb1-10" aria-hidden="true"></a>    <span class="kw">match</span>(<span class="ot">TRUE</span>, u <span class="op">&lt;</span><span class="st"> </span><span class="kw">cumsum</span>(probs))</span>
<span id="cb1-11"><a href="tópicos-em-estatística-computacional.html#cb1-11" aria-hidden="true"></a>  }</span>
<span id="cb1-12"><a href="tópicos-em-estatística-computacional.html#cb1-12" aria-hidden="true"></a>  </span>
<span id="cb1-13"><a href="tópicos-em-estatística-computacional.html#cb1-13" aria-hidden="true"></a>  purrr<span class="op">::</span><span class="kw">map_dbl</span>(<span class="dt">.x =</span> u, <span class="dt">.f =</span> <span class="op">~</span><span class="st"> </span><span class="kw">comp</span>(.x))</span>
<span id="cb1-14"><a href="tópicos-em-estatística-computacional.html#cb1-14" aria-hidden="true"></a>  </span>
<span id="cb1-15"><a href="tópicos-em-estatística-computacional.html#cb1-15" aria-hidden="true"></a>}</span>
<span id="cb1-16"><a href="tópicos-em-estatística-computacional.html#cb1-16" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb1-17"><a href="tópicos-em-estatística-computacional.html#cb1-17" aria-hidden="true"></a><span class="kw">random</span>(<span class="dt">n =</span> 10L)</span></code></pre></div>
<pre><code>##  [1] 4 1 2 3 4 1 4 4 3 3</code></pre>
<p>Em um estudo de simulação, poderemos ter interesse em gerar observações equiprováveis, em que a v.a. <span class="math inline">\(X\)</span> assume um número finito de observações, tal forma que:</p>
<p><span class="math display">\[P(X = j) = \frac{1}{n}, \,\, j = 1, 2, \ldots, n.\]</span>
Porém, note que para esse caso, não precisaremos fazer muitas comparações, uma vez que sabemos que <span class="math inline">\(x = j\)</span> quando <span class="math inline">\(u \leq \frac{j-1}{n}\)</span>. Sendo assim, tomamos <span class="math inline">\(x = j\)</span> quando <span class="math inline">\(nu \leq j - 1\)</span>.</p>
<p>Note que fazer <span class="math inline">\(x = j\)</span> quando <span class="math inline">\(nu \leq j - 1\)</span> equivale a fazer <span class="math inline">\(x = \mathrm{Int}(nu) + 1\)</span>, em que <span class="math inline">\(\mathrm{Int}(\cdot)\)</span> aqui irá retornar o menor inteiro de um número.</p>
<p><strong>Exemplo</strong>: Seja <span class="math inline">\(X \sim Bernoulli(p)\)</span>, em que <span class="math inline">\(P(X = 0) = 1 - p\)</span> e <span class="math inline">\(P(X = 1) = p\)</span>, com <span class="math inline">\(0\leq p \leq 1\)</span>. A função <code>rbernoulli(n = 1L, p)</code> retorna possíveis observações de <span class="math inline">\(X\)</span>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="tópicos-em-estatística-computacional.html#cb3-1" aria-hidden="true"></a>rbernoulli &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">n =</span> 1L, p){</span>
<span id="cb3-2"><a href="tópicos-em-estatística-computacional.html#cb3-2" aria-hidden="true"></a>  u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>)</span>
<span id="cb3-3"><a href="tópicos-em-estatística-computacional.html#cb3-3" aria-hidden="true"></a>  comp &lt;-<span class="st"> </span><span class="cf">function</span>(x){</span>
<span id="cb3-4"><a href="tópicos-em-estatística-computacional.html#cb3-4" aria-hidden="true"></a>    <span class="kw">ifelse</span>(x <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p, 0L, 1L)</span>
<span id="cb3-5"><a href="tópicos-em-estatística-computacional.html#cb3-5" aria-hidden="true"></a>  }</span>
<span id="cb3-6"><a href="tópicos-em-estatística-computacional.html#cb3-6" aria-hidden="true"></a>  purrr<span class="op">::</span><span class="kw">map_int</span>(<span class="dt">.x =</span> u, <span class="dt">.f =</span> <span class="op">~</span><span class="st"> </span><span class="kw">comp</span>(.x))</span>
<span id="cb3-7"><a href="tópicos-em-estatística-computacional.html#cb3-7" aria-hidden="true"></a>}</span>
<span id="cb3-8"><a href="tópicos-em-estatística-computacional.html#cb3-8" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">0</span>) <span class="co"># Fixando uma semente.</span></span>
<span id="cb3-9"><a href="tópicos-em-estatística-computacional.html#cb3-9" aria-hidden="true"></a>n &lt;-<span class="st"> </span><span class="fl">1e4</span> <span class="co"># Número de observações.</span></span>
<span id="cb3-10"><a href="tópicos-em-estatística-computacional.html#cb3-10" aria-hidden="true"></a>result &lt;-<span class="st"> </span><span class="kw">rbernoulli</span>(<span class="dt">n =</span> n, <span class="dt">p =</span> <span class="fl">0.6</span>) <span class="co"># prob.  de sucesso = 0.6.</span></span>
<span id="cb3-11"><a href="tópicos-em-estatística-computacional.html#cb3-11" aria-hidden="true"></a><span class="co"># Probabilidade de sucesso aproximada.</span></span>
<span id="cb3-12"><a href="tópicos-em-estatística-computacional.html#cb3-12" aria-hidden="true"></a><span class="kw">sum</span>(result <span class="op">==</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span>n</span></code></pre></div>
<pre><code>## [1] 0.5973</code></pre>
</div>
<div id="método-da-aceitação-e-rejeição" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Método da aceitação e rejeição</h3>
<p>Em situações em que não podemos fazer uso do método da inversão (situações em que não é possível obter a função quantílica) e nem conhecemos uma transformação que envolve uma variável aleatória ao qual sebemos gerar observações, poderemos fazer uso do <strong>método a aceitação e rejeição</strong>.</p>
<p>Suponha que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> são variáveis aleatórias com função densidade de probabilidade (fdp) ou função de probabilidade (fp) <span class="math inline">\(f\)</span> e <span class="math inline">\(g\)</span>, respectivamente. Além disso, suponha que existe uma constante <span class="math inline">\(c\)</span> de tal forma que</p>
<p><span class="math display">\[\frac{f(t)}{g(t)} \leq c,\]</span>
para todo valor de <span class="math inline">\(t\)</span>, com <span class="math inline">\(f(t) &gt; 0\)</span>. Para utilizar o método a aceitação e rejeição para gerar observações da v.a. <span class="math inline">\(X\)</span>, utilizando o algoritmo mais abaixo, antes, encontre uma v.a. <span class="math inline">\(Y\)</span> com pdf ou fp <span class="math inline">\(g\)</span>, tal que satisfaça a condição acima.</p>
<p><strong>Importante</strong>:</p>

<div class="rmdimportant">
<div class="text-justify">
<p>É importante que a v.a. <span class="math inline">\(Y\)</span> escolhida seja de tal forma que você consiga gerar facilmente suas observações. Isso se deve ao fato do método da aceitação e rejeição ser computacionalmente mais intensivo que métodos mais diretos como o método da transformação ou o método da inversão que exige apenas a regração de números pseudo-aleatórios com distribuição uniforme.</p>
</div>
</div>
<p><strong>Algoritmo do Método da Aceitação e Rejeição</strong>:</p>
<p>1 - Gere uma observação <span class="math inline">\(y\)</span> proveniente de uma v.a. <span class="math inline">\(Y\)</span> com fdp/fp <span class="math inline">\(g\)</span>;</p>
<p>2 - Gere uma observação <span class="math inline">\(u\)</span> de uma v.a. <span class="math inline">\(U\sim \mathcal{U} (0, 1)\)</span>;</p>
<p>3 - Se <span class="math inline">\(u &lt; \frac{f(y)}{cg(y)}\)</span> aceite <span class="math inline">\(x = y\)</span>; caso contrário rejeite <span class="math inline">\(y\)</span> como observação da v.a. <span class="math inline">\(X\)</span> e volte ao passo 1.</p>
<p><strong>Prova</strong>: Consideremos o caso discreto, ou seja, que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> são v.a.s com fp’s <span class="math inline">\(f\)</span> e <span class="math inline">\(g\)</span>, respectivamente. Pelo passo 3 do algoritmo acima, temos que <span class="math inline">\(\{aceitar\} = \{x = y\} = u &lt; \frac{f(y)}{cg(y)}\)</span>. Isto é,</p>
<p><span class="math display">\[P(aceitar | Y = y) = \frac{P(aceitar \cap \{Y = y\})}{g(y)} = \frac{P(U \leq f(y)/cg(y)) \times g(y)}{g(y)} = \frac{f(y)}{cg(y)}.\]</span>
Daí, pelo <a href="https://pt.wikipedia.org/wiki/Lei_da_probabilidade_total"><strong>Teorema da Probabilidade Total</strong></a>, temos que:</p>
<p><span class="math display">\[P(aceitar) = \sum_y P(aceitar|Y=y)\times P(Y=y) = \sum_y \frac{f(y)}{cg(y)}\times g(y) = \frac{1}{c}.\]</span>
Portanto, pelo método da aceitação e rejeição aceitamos ocorrência de <span class="math inline">\(Y\)</span> como sendo uma ocorrência de <span class="math inline">\(X\)</span> com probabilidade <span class="math inline">\(1/c\)</span>. Além disso, pelo Teorema de Bayes, temos que</p>
<p><span class="math display">\[P(Y = y | aceitar) = \frac{P(aceitar|Y = y)\times g(y)}{P(aceitar)} = \frac{[f(y)/cg(y)] \times g(y)}{1/c} = f(y).\]</span>
O resultado logo acima, mostra que aceitar <span class="math inline">\(x = y\)</span> pelo procedimento do algoritmo equivale a aceitar um valor proveniente de <span class="math inline">\(X\)</span> que tem fp <span class="math inline">\(f\)</span>. Para o caso contínuo, a demonstração é similar.</p>
<p><strong>Importante</strong>:</p>

<div class="rmdimportant">
<div class="text-justify">
<p>Perceba que para reduzir o custo computacional do método, deveremos escolher <span class="math inline">\(c\)</span> de tal forma que possamos maximizar <span class="math inline">\(P(aceitar)\)</span>. Sendo assim, escolher um valor exageradamente grande da constante <span class="math inline">\(c\)</span> irá reduzir a probabilidade de aceitar uma observação de <span class="math inline">\(Y\)</span> como sendo observação da v.a. <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Computacionalmente, é conveniente considerar <span class="math inline">\(Y\)</span> como sendo uma v.a. com distribuição uniforme no suporte de <span class="math inline">\(f\)</span>, uma vez que gerar observações de uma distribuição uniforme é algo simples em qualquer computador. Para o caso discreto, considerar <span class="math inline">\(Y\)</span> com distribuição uniforme discreta poderá ser uma boa alternativa.</p>
</div>
</div>
</div>
</div>
<div id="exercício-1" class="section level2 unnumbered">
<h2>Exercício</h2>
<ol style="list-style-type: decimal">
<li><p>Quais as propriedades de um bom gerador de números pseudo-aleatórios? Disserte sobre cada uma delas.</p></li>
<li><p>Implemente o gerador <strong>Midsquare</strong> idealizado pelo matemático John von Neumann. Por que o gerador <strong>Midsquare</strong> não é um bom gerador? Explique.</p></li>
<li><p>Defina matematicamente o gerador congruencial linear. Implemente uma função em R que implementa esse gerador.</p></li>
<li><p>O gerador <strong>Randu</strong> é definido por <span class="math inline">\(x_{i + 1} = 65539 \times x_i\,\mathrm{mod}\,31\)</span>. O <strong>Randu</strong> é um gerador congruencial misto ou multiplicativo?</p></li>
<li><p>Por que o gerador <strong>Randu</strong> é um dos peiores geradores de números pseudo-aleatório já criado? Explique.</p></li>
<li><p>Defina um gerador congruencial de período completo para geração de números pseudo-aleatórios com distribuição uniforme no intervalo <span class="math inline">\((0,1)\)</span></p></li>
<li><p>Explique o método da transformação para geração de números pseudo aleatório. Apresente um exemplo.</p></li>
<li><p>Defina o método da inversão para geração de números pseudo-aleatórios. Sempre será possível utilizar esse método? Explique.</p></li>
<li><p>Implemente uma função para geração de números pseudo-aleatórios com distribuição normal padrão. A função deverá implementar o método de Box-Müller e o método polar. Ao final obtenha um histograma com os números gerados (mil valores) e realize um teste de normalidade. Realize um teste de normalidade.</p></li>
<li><p>Seja <span class="math inline">\(X\)</span> uma variável aleatória em um espaço de probabilidade <span class="math inline">\((\Omega, \mathcal{A},\mathcal{P})\)</span> e suponha que <span class="math inline">\(X \sim \mathcal{U}(0,1)\)</span>. Obtenha a distribuição de <span class="math inline">\(Y = -\log(X)\)</span>.</p></li>
<li><p>Com base na distribuição da variável aleatória (v.a.) <span class="math inline">\(Y\)</span> do exercício acima, implemente uma função em R que gere observações de <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Conhecendo a distribuição da v.a. <span class="math inline">\(X\)</span>, implemente para cada um dos itens que seguem, uma função para geração de observações da v.a. <span class="math inline">\(Y\)</span>:</p>
<ul>
<li><p><span class="math inline">\(X \sim \mathrm{Exp}(\lambda),\)</span> com <span class="math inline">\(x \geq 0\)</span> e <span class="math inline">\(\lambda &gt; 0\)</span> e <span class="math inline">\(Y = \sum_{i = 1}^n X_i \sim \Gamma(n, \lambda)\)</span>;</p></li>
<li><p><span class="math inline">\(X \sim \mathrm{Exp}(\lambda)\)</span>, com <span class="math inline">\(x \geq 0\)</span> e <span class="math inline">\(\lambda&gt;0\)</span> e <span class="math inline">\(Y = \mu - \beta\log(\lambda X) \sim \mathrm{Gumbel}(\mu,\beta)\)</span>, com <span class="math inline">\(\mu \in \Bbb{R}\)</span> e <span class="math inline">\(\beta&gt;0\)</span>;</p></li>
<li><p><span class="math inline">\(X \sim \mathcal{U}(0,1)\)</span> (contínua) e <span class="math inline">\(Y = m + s[-\log(X)]^{-1/\alpha} \sim\)</span> Fréchet<span class="math inline">\((\alpha,s,m)\)</span>, com <span class="math inline">\(x, \alpha,s &gt; 0\)</span> e <span class="math inline">\(m \in \Bbb{R}\)</span>.</p></li>
</ul></li>
<li><p>Cite algumas das propriedades do gerador <strong>Mersenne Twister</strong>. Qual o seu período de ocorrência?</p></li>
<li><p>Explique o algoritmo do método da aceitação e rejeição.</p></li>
<li><p>Utilizando o método da aceitação e rejeição, implemente uma função que gere valores aleatório provenientes da distribuição da v.a. <span class="math inline">\(X\)</span> tal que</p></li>
</ol>
<p><span class="math display">\[P(X = 1) = 0.3, P(X = 2) = 0.2, P(X = 3) = 0.35, P(X = 4) = 0.15.\]</span></p>
<!-- x <- 1L:4L -->
<!-- prob <- c(0.30, 0.20, 0.35, 0.15) -->
<!-- ar <- function(n = 1L, x, prob){ -->
<!--   c <- max(length(prob) * prob) -->
<!--   random_y <- function(i){ -->
<!--     while (TRUE) { -->
<!--       y <- floor(length(x) * runif(n = 1L, min = 0, max = 1)) + 1L -->
<!--       if (runif(n = 1L, 0, 1) < length(prob) * prob[y] / c) return(y)  -->
<!--     } -->
<!--   } -->
<!--   unlist(lapply(X = 1L:n, FUN = random_y)) -->
<!-- } -->
<!-- result <- ar(n = 1e6L, x = 1L:4L, prob = c(0.30, 0.20, 0.35, 0.15)) -->
<!-- # Probabilidades aproximadas. -->
<!-- barplot(table(result)/1e6L) -->
<ol start="16" style="list-style-type: decimal">
<li>Implemente duas funções que geram observações da v.a. <span class="math inline">\(X\)</span> utilizando o método da transformação para v.a. discretas e pelo método da aceitação e rejeição. Qual método é mais eficiente computacionalmente? Por que?</li>
</ol>
<p><span class="math display">\[\begin{eqnarray}
P(X = 0) &amp;=&amp; 0.14, P(X = 1) = 0.27, P(X = 2) = 0.27,\nonumber\\
P(X = 3) &amp;=&amp; 0.18, P(X = 4) = 0.09, P(X = 5) = 0.04, \nonumber\\
P(X = 6) &amp;=&amp; 0.01. \nonumber\\
\end{eqnarray}\]</span></p>
<ol start="17" style="list-style-type: decimal">
<li><p>Implemente a função <code>rdisc(n = 1L, x, probs)</code> que retorna números pseudo-aleatórios de uma v.a. discreta <span class="math inline">\(X\)</span> que assume uma quantidade finita de observações. Os argumentos de <code>rdisc</code> estão especificados abaixo:</p>
<ul>
<li><p><code>n</code>: número de observações a serem geradas;</p></li>
<li><p><code>x</code>: vetor com as possíveis observações da v.a. <span class="math inline">\(X\)</span>;</p></li>
<li><p><code>probs</code>: vetor com as probabilidades das observações passadas à <code>x</code>.</p></li>
</ul></li>
<li><p>Implemente uma função para o método da aceitação e rejeição (<code>ar_fp(n, x, prob)</code>), para o caso em que deseja-se gerar observações de uma v.a. <span class="math inline">\(X\)</span> discreta. O argumento <code>n</code> refere-se à quantidade de observações a serem geradas, <code>x</code> é um vetor de valores assumidos por <span class="math inline">\(X\)</span> e <code>prob</code> é um vetor de probabilidades de cada observação de <span class="math inline">\(X\)</span>. A função <code>ar_fp(n, x, prob)</code> deverá escolher um valor adequado para <span class="math inline">\(c\)</span>.</p></li>
<li><p>Seja <span class="math inline">\(X\)</span> uma v.a. contínua com fdp <span class="math inline">\(f(x) = 6x(x-1)\)</span>, com <span class="math inline">\(0 &lt; x &lt; 1\)</span>. Implemente a função <code>rf(n, c = 1.5)</code> que gera números pseudo-aleatórios como observações de <span class="math inline">\(X\)</span>, pelo método da aceitação e rejeição, em que <code>n</code> é a quantidade de números a serem gerados e <code>c</code> é o valor da constante (0.5 por padrão) no algoritmo do método da aceitação e rejeição. <strong>Dica</strong>: considere <span class="math inline">\(Y \sim \mathcal{U}(0,1)\)</span>.</p></li>
</ol>
<!-- rf <- function(n = 1L, c = 6){ -->
<!--   f <- function(x) 6 * x * (1 - x) -->
<!--   i <- 1L -->
<!--   n_rejeicao <- 0L -->
<!--   vetor <- numeric(n) -->
<!--   while (i < n){ -->
<!--     u <- runif(n = 1L, min = 0, max = 1) -->
<!--     y <- runif(n = 1L, min = 0, max = 1) -->
<!--     if (u <= f(y)/c){ -->
<!--       vetor[i] <- y -->
<!--       i <- i + 1L -->
<!--     }  -->
<!--     else{ -->
<!--       n_rejeicao <- n_rejeicao + 1L -->
<!--     } -->
<!--   } -->
<!--   list(valores = vetor, rejeicao = n_rejeicao) -->
<!-- } -->
<!-- set.seed(0) -->
<!-- n <- 2e4 -->
<!-- c <- 20 -->
<!-- result <- rf(n = n, c = c) -->
<!-- # Probabilidade de aceitar: -->
<!-- 1/c -->
<!-- # Aproximacao da probabilidade de aceitar: -->
<!-- 1 - result$rejeicao/(n + result$rejeicao) -->
<ol start="20" style="list-style-type: decimal">
<li>Considerando a função <code>rf(n, c)</code> implementada no exercício anterior, quantos passos serão necessários para que possamos gerar 10 mil observações proveniente da distribuição de <span class="math inline">\(X\)</span>, considerando <code>c = 6</code>? Respectivamente, quantos passos serão necessários para serem gerados a mesma quantidade de observações de <span class="math inline">\(X\)</span> considerando <code>c = 0.5</code>? <strong>Dica</strong>: antes de chamar a função implementada, fixe a semente fazendo <code>set.seed(0)</code>.</li>
</ol>
</div>
<div id="otimização-não-linear" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Otimização Não-Linear</h2>
<p>Na estatísticas, em muitas situações práticas, temos o interesse de maximizar ou minimizar uma função objetivo. Por exemplo, na inferência esatística, é comum o nosso interesse na obtenção dos estimadores de máxima verossimilhança de parâmetros que indexam modelos ou distribuições de probabilidade. Um outro problema comum na estatística, mais precisamente na área de regressão é o de minimizar a soma dos quadrados de um conjunto de erros, em um modelo de regressão não-linear por meio de mínimos quadrados não-lineares.</p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Aqui, o termo <strong>otimizar</strong> estará se referindo à <strong>minimiar</strong> ou <strong>maximizar</strong> uma função objetivo. Dessa forma, por meio do contexto em que o termo esteja sendo utilizado, a ideia estará implícita. Além disso, por uma simples modificação na função objetivo, um algoritmo utilizado para maximizar uma função poderá ser convertido em um algoritmo para minimização de uma função.</p>
</div>
</div>
<p>Suponha que temos interesse em maximizar uma função objetivo, seja ela <span class="math inline">\(\psi(\pmb{\Theta}): \pmb{\Theta} \rightarrow \mathbb{R}\)</span>, em que <span class="math inline">\(\pmb{\Theta}\)</span> é um subspaço do <span class="math inline">\(\mathbb{R}^p\)</span>. Dessa forma, queremos encontrar o vetor <span class="math inline">\(\pmb{\theta}\)</span> (<span class="math inline">\(p \times 1\)</span>) que maximiza a função objetivo <span class="math inline">\(\psi(\cdot)\)</span>. Ou seja, queremos obter</p>
<p><span class="math display">\[ \underset{\pmb{\theta}\, \in\, \pmb{\Theta}}{\mathrm{arg\,max}}\,\psi(\pmb{\theta}).\]</span></p>
<p>A maioria das situações práticas nos levam à problemas com a condição de primeira ordem,</p>
<p><span class="math display">\[\frac{\partial\,\psi(\pmb{\theta})}{\partial\,\pmb{\theta}} = \pmb{0},\]</span></p>
<p>resulta em um sistema de equações não-lineares que não apresenta solução em forma fechada. Nesses casos, a solução do problema de minimizar <span class="math inline">\(\psi(\pmb{\theta})\)</span> é obtida utilizando-se de métodos/algoritmos iterativos.</p>
<div id="metódos-gradiente" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Metódos Gradiente</h3>
<p>A classe de métodos de otimizações mais utilizadas em situações em que a condição de primeira ordem resulta em um sistema não-linear que não possue forma fechada é denominada de <strong>classe de métodos gradiente</strong>. Nessa classe de métodos, a atualização de <span class="math inline">\(\pmb{\theta}\)</span> para um vetor que mais se aproxima do ponto que minimiza <span class="math inline">\(\psi(\cdot)\)</span> (função objetivo) é dada de forma iterativa. Dessa forma, seja <span class="math inline">\(\pmb{\theta}_0\)</span> o ponto inicial (chute inicial) na <span class="math inline">\(t\)</span>-ésima iteração. Se o valor de <span class="math inline">\(\pmb{\theta}\)</span> que maximiza globalmente a função <span class="math inline">\(\psi(\cdot)\)</span> não tiver sido alcançado, calcula-se o vetor direcional (vetor gradiente) de <span class="math inline">\(\psi(\cdot)\)</span>, denotado aqui por <span class="math inline">\(\pmb\Delta_t\)</span> (<span class="math inline">\(p \times 1\)</span>) e o “tamanho do passo” <span class="math inline">\(\lambda_t\)</span>. Assim, o próximo valor de <span class="math inline">\(\pmb\theta\)</span> será atualizado para:</p>
<p><span class="math display">\[\pmb\theta_{t+1} = \pmb\theta_t + \lambda_t \pmb \Delta_t.\]</span></p>
<p><strong>Importante</strong>:</p>

<div class="rmdimportant">
<div class="text-justify">
<p>O vetor gradiente fornece a direção e o sentido de deslocamento, apartir de um ponto especificado, de subida que fornece um incremento em uma grandeza. No nosso caso, <span class="math inline">\(\pmb\Delta_t\)</span> (<span class="math inline">\(p \times 1\)</span>) irá indicar o sentido de subida, em que poderemos atualizar o valor de <span class="math inline">\(\pmb \theta\)</span> para um ponto que maximiza <span class="math inline">\(\psi(\cdot)\)</span>. Dessa forma, <span class="math inline">\(-\pmb\Delta_t\)</span> fornecerá a direção e o sentido de atualização de <span class="math inline">\(\pmb\theta\)</span> que nos levam à pontos que minimizam <span class="math inline">\(\psi(\cdot)\)</span>.</p>
</div>
</div>
<p>Note também que, em cada iteração do algoritmo, temos que <span class="math inline">\(\pmb \theta_t\)</span> e <span class="math inline">\(\pmb \Delta_t\)</span> são conhecidos, uma vez que <span class="math inline">\(\pmb \theta_t\)</span> é o ponto <span class="math inline">\(\pmb \theta\)</span> atualizado na iteração <span class="math inline">\(t-1\)</span> e <span class="math inline">\(\pmb \Delta_t\)</span> é o vetor gradiente da função objetivo avaliado em <span class="math inline">\(\pmb \theta_t\)</span>.</p>
<p>Dado o conhecimento dessas quantidade, perceba que precisamos obter o “tamanho do passo” <span class="math inline">\(\lambda_t\)</span>. Assim, iremos recair em um problema de otimização secundário, denominado de <strong>procura em linha</strong>. Sendo assim, busca-se <span class="math inline">\(\lambda_t\)</span> de tal forma que</p>
<p><span class="math display">\[\frac{\partial \pmb\,\psi(\pmb \theta_t + \lambda_t\pmb\Delta_t)}{\partial \lambda_t} = \delta(\pmb \theta_t + \lambda_t\pmb\Delta_t)^{&#39;}\pmb \Delta_t = 0,\]</span>
em que <span class="math inline">\(\delta(\pmb \theta_t + \lambda_t\pmb\Delta_t)^{&#39;}\)</span> é o vetor gradiente tansposto (<span class="math inline">\(1 \times p\)</span>) da função objetivo avaliado no ponto <span class="math inline">\(\pmb \theta_t + \lambda_t\pmb\Delta_t.\)</span></p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-8"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-8-1.png" alt="Poblema de **procura em linha**, em que a função objetivo é função penas do tamanho do passo." width="672" />
<p class="caption">
Figura 6.1: Poblema de <strong>procura em linha</strong>, em que a função objetivo é função penas do tamanho do passo.
</p>
</div>
<p><strong>Observação</strong>:</p>

<div class="rmdobservation">
<div class="text-justify">
<p>É importante observar que o processo de busca em linha em um algoritmo de otimização não-linear tornará esse algoritmo computacionalmente intensivo. Dessa forma, muitos algoritmos adotam um conjunto de regras <em>ad hoc</em> que são computacionalmente menos custosas. Essa classe de algoritmos é o que denominamos de <strong>classe de métodos gradiente</strong>.</p>
</div>
</div>
<p>Na classe de métodos gradiente, fazemos</p>
<p><span class="math display">\[\pmb \Delta_t = M_t\delta_t,\]</span>
em que <span class="math inline">\(M_t\)</span> (<span class="math inline">\(p \times p\)</span>) é uma matriz positiva-definida e <span class="math inline">\(\delta_t\)</span> (<span class="math inline">\(p \times 1\)</span>) é o gradiente de <span class="math inline">\(\pmb\psi\)</span>, ambos na <span class="math inline">\(t\)</span>-ésima iteração. Para deixar claro, temos que <span class="math inline">\(\delta_t\)</span> = <span class="math inline">\(\delta_t(\pmb \theta_t) = \partial \, \psi(\pmb \theta_t)/\partial\, \pmb \theta_t\)</span>.</p>
<p>A motivação por trás dos métodos gradientes, ao em tomar <span class="math inline">\(\pmb \Delta_t = M_t\delta_t\)</span>, poderá ser entendida ao considerar uma aproximação para <span class="math inline">\(\psi(\pmb \theta_t + \lambda_t\pmb\Delta_t)\)</span> por uma <a href="https://pt.wikipedia.org/wiki/S%C3%A9rie_de_Taylor"><strong>série de Taylor</strong></a> de primeira ordem, em torno do ponto <span class="math inline">\(\lambda_t = 0\)</span>. Assim, temos que,</p>
<p><span class="math display">\[\psi(\pmb \theta_t + \lambda_t\pmb\Delta_t) \approx \psi(\pmb \theta_t) + \lambda_t \delta_t^{&#39;}\pmb \Delta_t,\]</span>
em que <span class="math inline">\(\delta_t^{&#39;}\)</span> é o vetor gradiente transposto (<span class="math inline">\(1 \times p\)</span>). Para reduzir a notação, tome <span class="math inline">\(\psi(\pmb \theta_t + \lambda_t\pmb\Delta_t) = \psi_{t+1}\)</span>. Assim, temos que</p>
<p><span class="math display">\[\psi_{t+1} - \psi_{t} \approx \lambda_t \delta_t^{&#39;}\pmb \Delta_t.\]</span></p>
<p>Assim, considerando <span class="math inline">\(\pmb \Delta_t = M_t\delta_t\)</span>, temos que</p>
<p><span class="math display">\[\psi_{t+1} - \psi_{t} \approx \lambda_t \delta_t^{&#39;}M_t\delta_t.\]</span></p>
<p>Para <span class="math inline">\(\delta_t\)</span> diferente de zero e <span class="math inline">\(\lambda_t\)</span> suficientemente pequeno, se <span class="math inline">\(\psi(\pmb\theta)\)</span> não assume o valor máximo da função, podemos sempre encontrar um tamanho de passo tal que uma iteração adicional no algoritmo irá incrementar o valor da função, ou seja, se aproximará um pouco mais do máximo global da função objetivo.</p>
<p>Perceba que sempre temos que <span class="math inline">\(\psi_{t+1} - \psi_{t} \geq 0\)</span>. Isso sempre será verdade, uma vez que <span class="math inline">\(M_t\)</span> é uma matriz positiva-definida, o que implica que <span class="math inline">\(\delta_t^{&#39;}M_t\delta_t &gt; 0\)</span>. Além disso, na situação de <span class="math inline">\(\psi(\pmb\theta)\)</span> não encontar-se no ponto máximo, como mencionado no parágrafo anterior, sempre haverá um tamanho de passo <span class="math inline">\(\lambda_t\)</span>, por menor que ele seja.</p>
<div id="steepest-ascent" class="section level4" number="6.2.1.1">
<h4><span class="header-section-number">6.2.1.1</span> Steepest Ascent</h4>
<p>O algoritmo <strong>steepest ascent</strong> (“subida mais inclinada”) é o mais simples dos métodos gradientes. A ideia do algoritmo <strong>steepest ascent</strong> é considerar</p>
<p><span class="math display">\[M_t = I,\]</span>
em que <span class="math inline">\(I\)</span> é a matriz identidade (<span class="math inline">\(p \times p\)</span>). Dessa forma, temos que <span class="math inline">\(\pmb \Delta_t = \delta_t\)</span>, em todos os passos iterativos. Daí, a atualização de <span class="math inline">\(\pmb \theta\)</span> é dada por:</p>
<p><span class="math display">\[\pmb \theta_{t+1} = \theta + \lambda_t\delta_t.\]</span></p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Esse algoritmo tende a ser pouco utilizado na prática, uma vez que apresenta convergência lenta. Esse método é muito semelhante ao algoritmo gradiente descendente <a href="https://en.wikipedia.org/wiki/Gradient_descent"><strong>steepest descent</strong></a>, utilizado para minimização. Não confunda <strong>steepest descent</strong> citado aqui com um método de aproximação de integrais que leva o mesmo nome.</p>
</div>
</div>
</div>
<div id="newton-raphson" class="section level4" number="6.2.1.2">
<h4><span class="header-section-number">6.2.1.2</span> Newton-Raphson</h4>
<p>O método de <strong>Newton-Raphson</strong>, muitas vezes apenas chamado de método de <strong>Newton</strong>, considera a atualização de <span class="math inline">\(\pmb \theta\)</span> na forma</p>
<p><span class="math display">\[\pmb \theta_{t+1} = \pmb \theta_t -H_t^{-1}\delta_t,\]</span>
em que</p>
<p><span class="math display">\[H = H(\theta) = \frac{\partial^2 \psi(\pmb \theta)}{\partial \pmb \theta \partial \pmb \theta^{&#39;}},\]</span>
ou seja, temos que <span class="math inline">\(H\)</span> é a matriz <a href="https://pt.wikipedia.org/wiki/Hessiano"><strong>hessiana</strong></a>. No método de <strong>Newton-Rapshon</strong>, temos que <span class="math inline">\(\lambda_t = 1\)</span> e <span class="math inline">\(M_t = -H_t^{-1}\)</span>, em todas iterações.</p>
<p><strong>Observação</strong>:</p>

<div class="rmdobservation">
<div class="text-justify">
<p>A matriz hessiana nos permite identificar a concavidade de uma função multiparamétrica, desde que estas sejam duplamente diferenciável. Em um problema de maximização de uma função objetivo, temos que a matriz hessiana é negativa definida em uma região muito próxima ao ponto que maximiza a função. Dessa forma, <span class="math inline">\(-H^{-1}\)</span> é uma matriz positiva definida na mesma região, isto é, se <span class="math inline">\(\pmb a\)</span> é um vetor qualquer (<span class="math inline">\(p \times 1\)</span>) e <span class="math inline">\(H^{-1}\)</span> é uma matriz (<span class="math inline">\(p \times p\)</span>), então <span class="math inline">\(-\pmb a^{&#39;} H^{-1} \pmb a &lt; 0\)</span>.</p>
<p>Seja <span class="math inline">\(H\)</span> uma matriz hessiana como apresentada acima. Abaixo estão listadas algumas propriedades da de <span class="math inline">\(H\)</span>. Dessa forma, Então</p>
<ul>
<li><p><span class="math inline">\(\pmb a^{&#39;} H \pmb a &gt; 0\)</span> (positiva-definida): A função é estritamente convexa;</p></li>
<li><p><span class="math inline">\(\pmb a^{&#39;} H \pmb a &lt; 0\)</span> (negativa-definida): A função é estritiamente concava. Essa é a propriedade que estamos considerando, visto que estamos em um problema de maximização de uma função objetivo;</p></li>
<li><p><span class="math inline">\(\pmb a^{&#39;} H \pmb a \geq 0\)</span> (positiva semidefinida): A função é parcialmente convexa;</p></li>
<li><p><span class="math inline">\(\pmb a^{&#39;} H \pmb a \leq 0\)</span> (negativa semidefinida): A função é parcialmente concava;</p></li>
<li><p><span class="math inline">\(H\)</span> é uma matriz simétrica;</p></li>
<li><p>A inversa de uma matriz positiva-definida é também uma matriz positiva-definida;</p></li>
<li><p>Você poderá entender a matriz hessiana como a primeira derivada do vetor gradiente da função objetivo.</p></li>
</ul>
</div>
</div>
<p>O método de <strong>Newton-Raphson</strong> normalmente é utilizado para encontar os zeros de uma função. Quando aplicado sobre a condição de primeira ordem, o método de <strong>Newton-Raphson</strong> nos conduzirá aos pontos críticos da função. Como fazemos uso do vetor gradiente, estaremos sempre a caminhar para os pontos de máximo de <span class="math inline">\(\psi(\cdot)\)</span>. Dessa forma, os pontos críticos são os pontos de máximo da função objetivo.</p>
<p>Para que possamos entender melhor a ideia do método, considere uma <a href="https://pt.wikipedia.org/wiki/S%C3%A9rie_de_Taylor"><strong>expansão de Taylor</strong></a> da condição de primeira ordem em torno de um ponto qualquer <span class="math inline">\(\pmb \theta_0\)</span>. Assim, temos que</p>
<p><span class="math display">\[\frac{\partial\,\psi(\pmb \theta)}{\partial\, \pmb \theta} \approx f(\pmb \theta_0) + H(\pmb \theta_0) (\pmb \theta - \pmb\theta_0).\]</span></p>
<p>Resolvendo o sistema para <span class="math inline">\(\pmb\theta\)</span> e fazendo <span class="math inline">\(\pmb \theta = \pmb \theta_{t+1}\)</span> e <span class="math inline">\(\pmb \theta_0 = \pmb \theta_t\)</span>, obteremos o esquema iterativo do algoritmo apresentado ascima.</p>
<p>A forma mais usual do algoritmo de <strong>Newton-Rapshon</strong> introduz o mecanismo de “procura em linha”. Dessa forma, o esquema iterativo é dada por</p>
<p><span class="math display">\[\pmb \theta_{t+1} = \pmb \theta_t -\lambda_tH_t^{-1}\delta_t.\]</span>
<strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>O método de <strong>Newton-Raphson</strong> apesar de funcionar bem em diversas situações, poderá fornecer estimativas ruins em alguns casos. Por exemplo, um problema comum é quando <span class="math inline">\(\pmb \theta_t\)</span> é um ponto distante do ponto que maximiza <span class="math inline">\(\psi(\cdot)\)</span>, uma vez que nesses pontos, a matriz <span class="math inline">\(M_t = -H^{-1}\)</span> pode não ser positiva-definida.</p>
</div>
</div>
</div>
<div id="bhhh" class="section level4" number="6.2.1.3">
<h4><span class="header-section-number">6.2.1.3</span> BHHH</h4>
<p>O método <strong>BHHH</strong> (<strong>B</strong>erndt-<strong>H</strong>all-<strong>H</strong>all-<strong>H</strong>ausman), foi proposto no artigo Berndt, E. R., Hall, B. H., Hall, R. E., &amp; Hausman, J. A. (1974). <strong>Estimation and inference in nonlinear structural models</strong>. In Annals of Economic and Social Measurement, Volume 3, p. 653-665. O método é muito semelhante ao método de Newton-Raphson, com a diferença que trocamos a matriz <span class="math inline">\(H_t\)</span> pelo auto produto dos vetores gradientes <span class="math inline">\(\delta_t\delta_t^{&#39;}\)</span></p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>A vantagem do método <strong>BHHH</strong> está no fato de não necessitarmos calcular segundas derivadas. Trata-se de um método muito utilizado em aplicações ecnonométricas. O método <strong>BHHH</strong> poderá enfrentar o mesmo problema de convergência que o método de <strong>Newton-Raphson</strong>.</p>
</div>
</div>
</div>
<div id="métodos-quasi-newton" class="section level4" number="6.2.1.4">
<h4><span class="header-section-number">6.2.1.4</span> Métodos quasi-Newton</h4>
<p>A classe de algoritmos quasi-Newton é composta por algoritmos que são bastante eficientes do ponto de vista de convergência e também do ponto de vista computacional, visto que esses algoritmos não requerem o cálculo de segundas derivadas. Nessa classe de algoritmos, é utilizado uma sequência de matrizes tal que</p>
<p><span class="math display">\[M_{t+1} = M_{t} + N_t,\]</span>
sendo <span class="math inline">\(N_t\)</span> uma matriz positiva-definida. Assim, se <span class="math inline">\(M_0\)</span> é positiva-definida, <span class="math inline">\(M_t\)</span> na <span class="math inline">\(t\)</span>-ésima iteração sempre será positiva-definida. A ideia básica desses métodos é construir uma aproximação para <span class="math inline">\(-H(\pmb \theta)^{-1}\)</span>, de tal forma que</p>
<p><span class="math display">\[\lim_{t \to \infty} M_t = -H^{-1}.\]</span></p>
<p>Há diversos algoritmos que pertencem à classe de métodos quasi-Newton. Por exemplo, o método <strong>DFP</strong> (<strong>D</strong>avidon, <strong>F</strong>letcher e <strong>P</strong>owell) atualiza <span class="math inline">\(M_{t+1}\)</span> fazendo</p>
<p><span class="math display">\[M_{t+1} = M_{t} + \frac{\pmb \gamma_t \pmb \gamma_t^{&#39;}}{\pmb \gamma_t^{&#39;}\kappa_t} + \frac{M_t\kappa_t\kappa_t^{&#39;}M_t}{\kappa_t^{&#39;}M_t\pmb \gamma_t},\]</span></p>
<p>em que <span class="math inline">\(\pmb \gamma_t = \pmb \theta_{t+1} - \pmb \theta_t\)</span> (diferença de pontos) e <span class="math inline">\(\kappa_t = \delta(\pmb \theta_{t+1}) - \delta(\pmb \theta_t)\)</span> (diferenças de gradientes avaliados em pontos).</p>
<p>O algoritmo quasi-Newton mais utilizado é o <strong>BFGS</strong> (<strong>B</strong>royden-<strong>F</strong>letcher-<strong>G</strong>oldfarb-<strong>S</strong>hanno). O algoritmo <strong>BFGS</strong> tem a atualização semelhante ao <strong>DFP</strong>, com a diferença que é subtraído o termo <span class="math inline">\(a_tb_tb_t^{&#39;}\)</span>, em que <span class="math inline">\(a_t = \kappa_t^{&#39;}M_t\kappa_t\)</span> e</p>
<p><span class="math display">\[b_t = \frac{\pmb\gamma_t}{\pmb\gamma_t^{&#39;}\kappa_t} - \frac{M_t\kappa_t}{\kappa_t^{&#39;}M_t \kappa_t}.\]</span></p>
<p>Sendo assim, temos que no método <strong>BFGS</strong>, a atualização de <span class="math inline">\(M_t\)</span> de dará por:</p>
<p><span class="math display">\[M_{t+1} = M_{t} + \frac{\pmb \gamma_t \pmb \gamma_t^{&#39;}}{\pmb \gamma_t^{&#39;}\kappa_t} + \frac{M_t\kappa_t\kappa_t^{&#39;}M_t}{\kappa_t^{&#39;}M_t\pmb \gamma_t} - a_tb_tb_t^{&#39;}.\]</span></p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>O termo quasi-Newton é empregado para se referir ao fato de que esses métodos não fazem uso da matriz hessiana. Porém, esses métodos utilizam uma aproximação iterativa de uma matriz <span class="math inline">\(M_t\)</span> que converge para a matriz de segundas derivadas. Dessa forma, não entenda o termo quasi-Newton como se esses métodos fossem inferiores aos métodos de <strong>Newton-Raphson</strong>. Na verdade, os métodos quasi-Newton normalmente apresentam desempenho superior.</p>
</div>
</div>
</div>
</div>
</div>
<div id="otimização-não-linear-no-r" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Otimização não-linear no R</h2>
<p>Em R, é comum minimizar uma função objetivo utilizando a função <code>optim()</code> do pacote <strong>stats</strong> que está disponível em qualquer instalação básica da linguagem. A forma geral de uso da função <code>optim()</code> é:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="tópicos-em-estatística-computacional.html#cb5-1" aria-hidden="true"></a><span class="kw">optim</span>(par, fn, <span class="dt">gr =</span> <span class="ot">NULL</span>, ...,</span>
<span id="cb5-2"><a href="tópicos-em-estatística-computacional.html#cb5-2" aria-hidden="true"></a>      <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;Nelder-Mead&quot;</span>, <span class="st">&quot;BFGS&quot;</span>, <span class="st">&quot;CG&quot;</span>, <span class="st">&quot;L-BFGS-B&quot;</span>, <span class="st">&quot;SANN&quot;</span>,</span>
<span id="cb5-3"><a href="tópicos-em-estatística-computacional.html#cb5-3" aria-hidden="true"></a>                 <span class="st">&quot;Brent&quot;</span>),</span>
<span id="cb5-4"><a href="tópicos-em-estatística-computacional.html#cb5-4" aria-hidden="true"></a>      <span class="dt">lower =</span> <span class="op">-</span><span class="ot">Inf</span>, <span class="dt">upper =</span> <span class="ot">Inf</span>,</span>
<span id="cb5-5"><a href="tópicos-em-estatística-computacional.html#cb5-5" aria-hidden="true"></a>      <span class="dt">hessian =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>em que:</p>
<ol style="list-style-type: decimal">
<li><code>par</code> é um vetor de chutes inicias;</li>
<li><code>fn</code> é a função objetivo a ser <strong>minimizada</strong>;</li>
<li><code>gr</code> é a função gradiente da função <code>fn</code>;</li>
<li><code>method</code> é o método escolhido par minimizar <code>fn</code>. É possível escolher os métodos de Nelder-Mead, BFGS, CG, L-BFGS-B, SANN (Simulated Annealing) e Brent;</li>
<li><code>...</code> é o operador dot-dot-dot que poderá receber argumentos que por ventura possam existir nas funções <code>fn</code> e <code>gr</code>;</li>
<li><code>lower</code> é um vetor que limita inferiormente os parâmetros a serem otimizados (por padrão é <code>-Inf</code>);</li>
<li><code>upper</code> é um vetor que limita superiormente os parâmetros a serem otimizados (por padrão é <code>Inf</code>);</li>
<li><code>hessian</code> recebe um valor lógico, em que por padrão <code>hessian = FALSE</code>. Se <code>hessian = TRUE</code>, será calculado uma estimativa da matriz hessiana avaliada na estimativa de ponto de mínimo global.</li>
</ol>
<p><strong>Exemplo</strong>: Utilizando a função <code>optim()</code> para minimizar a função <a href="https://en.wikipedia.org/wiki/Rosenbrock_function"><strong>Rosenbrock</strong></a> pelo método BFGS.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-16"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-16-1.png" alt="Gráfico da superfície da função Rosenbrock introduzida por Howard H. Rosenbrock em 1960." width="672" />
<p class="caption">
Figura 6.2: Gráfico da superfície da função Rosenbrock introduzida por Howard H. Rosenbrock em 1960.
</p>
</div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="tópicos-em-estatística-computacional.html#cb6-1" aria-hidden="true"></a><span class="co"># Função Rosenbrock</span></span>
<span id="cb6-2"><a href="tópicos-em-estatística-computacional.html#cb6-2" aria-hidden="true"></a>f_objetivo &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">a =</span> <span class="dv">2</span>, <span class="dt">b =</span> <span class="dv">40</span>) {</span>
<span id="cb6-3"><a href="tópicos-em-estatística-computacional.html#cb6-3" aria-hidden="true"></a>    x1 &lt;-<span class="st"> </span>x[<span class="dv">1</span>]</span>
<span id="cb6-4"><a href="tópicos-em-estatística-computacional.html#cb6-4" aria-hidden="true"></a>    x2 &lt;-<span class="st"> </span>x[<span class="dv">2</span>]</span>
<span id="cb6-5"><a href="tópicos-em-estatística-computacional.html#cb6-5" aria-hidden="true"></a>    (a <span class="op">-</span><span class="st"> </span>x1) <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span>(x2 <span class="op">-</span><span class="st"> </span>x1 <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb6-6"><a href="tópicos-em-estatística-computacional.html#cb6-6" aria-hidden="true"></a>}</span>
<span id="cb6-7"><a href="tópicos-em-estatística-computacional.html#cb6-7" aria-hidden="true"></a><span class="kw">optim</span>(<span class="dt">par =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">fn =</span> f_objetivo, <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>)</span></code></pre></div>
<pre><code>## $par
## [1] 1.999998 3.999992
## 
## $value
## [1] 2.761362e-11
## 
## $counts
## function gradient 
##      128       45 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<p><strong>Entendendo a saída (retorno da função)</strong>:</p>
<ol style="list-style-type: decimal">
<li><p><code>par</code> é um vetor contendo as estimativas para <span class="math inline">\(x_1\)</span> e <span class="math inline">\(x_2\)</span>;</p></li>
<li><p><code>value</code> é o valor da função avaliada nas estimativas obtidas;</p></li>
<li><p><code>counts</code> é a quantidade de chamadas da função a ser otimizada e do seu gradiente. Note que não passamos o gradiente da função de objetivo mas este teve que ser calculado numericamente;</p></li>
<li><p><code>convergence</code> é um vetor de uma única posição, em que 0 indica convergência. Qualquer número diferente de zero indica que houve problema de convergência no algoritmo escolhido para mininizar a função objetivo;</p></li>
<li><p><code>message</code> retorna alguma mensagem com informações adicionais, se necessário. Caso contrário, <code>NULL</code> será o retorno.</p></li>
</ol>
<p>A função de Rosenbrock tem mínimo analítico no ponto <span class="math inline">\((a, a^2)\)</span> (ponto ótimo), em que <span class="math inline">\(f(a, a^2) = 0\)</span>. Dessa forma, um bom método de otimização nos trará uma estimativa próxima ao ponto <span class="math inline">\((2, 4)\)</span>, uma vez que foi considerado, no código acima, <span class="math inline">\(a = 2\)</span> e <span class="math inline">\(b = 40\)</span>. Como pode-se observar, o método BFGS forneceu uma boa estimativa para ponto ótimo analítico.</p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Para o exemplo acima, <span class="math inline">\(x_1\)</span> e <span class="math inline">\(x_2\)</span> são chamadas de <strong>variáveis</strong>, visto que a função de Rosenbrock é determinística. Porém, em problemas estatísticos, por exemplo, quando desejamos maximizar uma função de log-verossimilhança, a otimização é realizada em termos dos <strong>parâmetros</strong> que indexam o modelo estatístico. Nesse caso, cada ponto da função</p>
</div>
</div>
<p>O argumento <code>...</code> é muito importante para nós que necessitamos frequentemente maximizar uma função de log-vessimilhança <span class="math inline">\(\mathcal{l}(\pmb \theta)\)</span>. É por meio desse argumento que passamos a amostra para <span class="math inline">\(\mathcal{l}(\pmb \theta)\)</span>. Sem ele, teríamos que implementa uma função de verossimilhança para cada tamanho de amostra, o que seria impraticável. Com a amostra especificada, poderemos proceder a minimização de <span class="math inline">\(-\mathcal{l}(\pmb \theta)\)</span> e obter o vetor <span class="math inline">\(\pmb \theta\)</span> com as estimativas de máxima verossimilhança dos parâmetros que indexam um modelo probablístico.</p>
<p><strong>Exemplo</strong>: Considere o conjunto de dados obtido abaixo:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="tópicos-em-estatística-computacional.html#cb8-1" aria-hidden="true"></a><span class="kw">set.seed</span>(0L)</span>
<span id="cb8-2"><a href="tópicos-em-estatística-computacional.html#cb8-2" aria-hidden="true"></a>dados &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> 750L, <span class="dt">mean =</span> <span class="dv">2</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>Seja <span class="math inline">\(X_1, \ldots, X_n\)</span> uma amostra aleatória (v.a.’s i.i.d), em que <span class="math inline">\(X_i \sim \mathcal{N}(\mu = 2, \sigma^2 = 1)\, \forall i\)</span>. Obtenha pelo método BFGS os estimadores de máxima verossimilhança para <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma^2\)</span>. Seja <span class="math inline">\(\mathcal{l(\pmb\theta)}\)</span> a função de verossimilhança para amostra e <span class="math inline">\(\pmb \theta^{&#39;} = (\mu, \sigma^2)\)</span>. Precisaremos implementar a função de verossmilhança e multiplica-la por -1, uma vez que minimizando <span class="math inline">\(-\mathcal{l}(\pmb \theta)\)</span> equivale à maximizar <span class="math inline">\(\mathcal{l}(\pmb \theta)\)</span>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="tópicos-em-estatística-computacional.html#cb9-1" aria-hidden="true"></a><span class="kw">set.seed</span>(0L)</span>
<span id="cb9-2"><a href="tópicos-em-estatística-computacional.html#cb9-2" aria-hidden="true"></a>dados &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> 750L, <span class="dt">mean =</span> <span class="dv">2</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</span>
<span id="cb9-3"><a href="tópicos-em-estatística-computacional.html#cb9-3" aria-hidden="true"></a></span>
<span id="cb9-4"><a href="tópicos-em-estatística-computacional.html#cb9-4" aria-hidden="true"></a><span class="co"># Função de log-verssimilhança da amostra aleatória.</span></span>
<span id="cb9-5"><a href="tópicos-em-estatística-computacional.html#cb9-5" aria-hidden="true"></a>loglikelihood_normal &lt;-<span class="st"> </span><span class="cf">function</span>(par, x){</span>
<span id="cb9-6"><a href="tópicos-em-estatística-computacional.html#cb9-6" aria-hidden="true"></a>  mu &lt;-<span class="st"> </span>par[<span class="dv">1</span>]</span>
<span id="cb9-7"><a href="tópicos-em-estatística-computacional.html#cb9-7" aria-hidden="true"></a>  sigma2 &lt;-<span class="st"> </span>par[<span class="dv">2</span>]</span>
<span id="cb9-8"><a href="tópicos-em-estatística-computacional.html#cb9-8" aria-hidden="true"></a>  <span class="op">-</span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> <span class="kw">sqrt</span>(sigma2))))</span>
<span id="cb9-9"><a href="tópicos-em-estatística-computacional.html#cb9-9" aria-hidden="true"></a>}</span>
<span id="cb9-10"><a href="tópicos-em-estatística-computacional.html#cb9-10" aria-hidden="true"></a></span>
<span id="cb9-11"><a href="tópicos-em-estatística-computacional.html#cb9-11" aria-hidden="true"></a><span class="co"># maximizando -log-likelihood da amostra aleatória.</span></span>
<span id="cb9-12"><a href="tópicos-em-estatística-computacional.html#cb9-12" aria-hidden="true"></a>resultado &lt;-<span class="st"> </span><span class="kw">optim</span>(<span class="dt">par =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">fn =</span> loglikelihood_normal,</span>
<span id="cb9-13"><a href="tópicos-em-estatística-computacional.html#cb9-13" aria-hidden="true"></a>                   <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>, <span class="dt">x =</span> dados)</span>
<span id="cb9-14"><a href="tópicos-em-estatística-computacional.html#cb9-14" aria-hidden="true"></a></span>
<span id="cb9-15"><a href="tópicos-em-estatística-computacional.html#cb9-15" aria-hidden="true"></a><span class="co"># Graficando a densidade estimada sobre os dados ----------------------------------</span></span>
<span id="cb9-16"><a href="tópicos-em-estatística-computacional.html#cb9-16" aria-hidden="true"></a></span>
<span id="cb9-17"><a href="tópicos-em-estatística-computacional.html#cb9-17" aria-hidden="true"></a><span class="co"># Sequência no domínio da distribuição:</span></span>
<span id="cb9-18"><a href="tópicos-em-estatística-computacional.html#cb9-18" aria-hidden="true"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">6</span>, <span class="dt">length.out =</span> 1000L)</span>
<span id="cb9-19"><a href="tópicos-em-estatística-computacional.html#cb9-19" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">dnorm</span>(<span class="dt">x =</span> x, <span class="dt">mean =</span> resultado<span class="op">$</span>par[<span class="dv">1</span>], resultado<span class="op">$</span>par[<span class="dv">2</span>])</span>
<span id="cb9-20"><a href="tópicos-em-estatística-computacional.html#cb9-20" aria-hidden="true"></a><span class="co"># Histograma das observações:</span></span>
<span id="cb9-21"><a href="tópicos-em-estatística-computacional.html#cb9-21" aria-hidden="true"></a><span class="kw">hist</span>(<span class="dt">x =</span> dados, <span class="dt">main =</span> <span class="st">&quot;Função Densidade de Probabilidade Estimada&quot;</span>,</span>
<span id="cb9-22"><a href="tópicos-em-estatística-computacional.html#cb9-22" aria-hidden="true"></a>     <span class="dt">ylab =</span> <span class="st">&quot;Probabilidade&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>, <span class="dt">probability =</span> <span class="ot">TRUE</span>,</span>
<span id="cb9-23"><a href="tópicos-em-estatística-computacional.html#cb9-23" aria-hidden="true"></a>     <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="dv">1</span>, <span class="fl">0.9</span>, <span class="fl">0.8</span>), <span class="dt">border =</span> <span class="ot">NA</span>)</span>
<span id="cb9-24"><a href="tópicos-em-estatística-computacional.html#cb9-24" aria-hidden="true"></a><span class="co"># Tracejando a densidade sobre o histograma:</span></span>
<span id="cb9-25"><a href="tópicos-em-estatística-computacional.html#cb9-25" aria-hidden="true"></a><span class="kw">lines</span>(x, y, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>Importante</strong>:</p>

<div class="rmdimportant">
<div class="text-justify">
<p>Nunca esqueça que minimizar <span class="math inline">\(-f\)</span> é equivalente a maximizar <span class="math inline">\(f\)</span>, sendo tabém verdadeira a recíproca. Além disso, lembre-se também que a função <code>optim()</code> é implementada de forma a minimizar uma função objetivo.</p>
</div>
</div>
</div>
<div id="exercício-2" class="section level2 unnumbered">
<h2>Exercício</h2>
<ol style="list-style-type: decimal">
<li><p>Defina matematicamente o método gradiente para maximização de uma função <span class="math inline">\(\psi(\pmb{\theta}): \pmb{\Theta} \rightarrow \mathbb{R}\)</span>, em que <span class="math inline">\(\pmb{\Theta}\)</span> é um subespaço do <span class="math inline">\(\mathbb{R}^p\)</span>.</p></li>
<li><p>Qual a desvantagem do uso do processo de busca em linha em algoritmos de otimização não-linear?</p></li>
<li><p>Defina os métodos quasi-Newton e o que os diferenciam dos de Newton? Qual as vantagens que a maioria desses métodos apresentam com relação aos métodos de Newton?</p></li>
<li><p>Enuncie os métodos <strong>Steepest Ascent</strong>, <strong>Newton-Raphson</strong> e <strong>BHHH</strong>. Esses são métodos de Newton ou quasi-Newton? Explique.</p></li>
<li><p>Considere a função abaixo:</p>
<p><span class="math display">\[f(\theta) = 6 + \theta ^ 2 \times \sin(14\theta),\]</span>
em que <span class="math inline">\(-2.5 \leq \theta \leq 2.5\)</span>. Obtenha uma estimativa para o ponto de máximo global dessa função. Houve convergência? Explique. Além disso, construa um gráfico da função <span class="math inline">\(f(\theta)\)</span> destacando o ponto de máximo no gráfico da função.</p></li>
<li><p>Considere a <a href="https://en.wikipedia.org/wiki/File:Matyas_function.pdf"><strong>Matyas function</strong></a>, função definida logo abaixo:</p>
<p><span class="math display">\[f(x, y) = 0.26 \times (x^2 + y^2) - 0.48 \times xy,\]</span>
em que <span class="math inline">\(0 \leq x, y ,\leq 10\)</span>. Qual o ponto de mínimo global da função? Obtenha uma estimativa, utilizando o método BFGS, para o ponto de mínimo global da função. Além disso, construa o gráfico da superfície obtida pela função e o gráfico com as curvas de níveis da função com a estimativa obtida indicada como um ponto nesse último gráfico. Interprete o resultado obtido. Houve convergência?</p></li>
<li><p>Considere a <a href="https://en.wikipedia.org/wiki/Test_functions_for_optimization#/media/File:Himmelblau_function.svg"><strong>Himmelblau’s function</strong></a>, função definida por:</p>
<p><span class="math display">\[f(x, y) = (x^2 + y -11)^2 + (x + y^2 - 7)^2,\]</span></p>
<p>com <span class="math inline">\(-5 \leq x,y \leq 5\)</span>. Essa função possui quatro pontos de mínimo global, são eles:</p>
<p><span class="math display">\[
\mathrm{Min} = \left \{
\begin{array}{rcc}
f(3.0, 2.0) &amp; = &amp; 0.0 \\
f(-2.805118, 3.131312) &amp; = &amp; 0.0 \\
f(-3.779310, -3.283186) &amp; = &amp; 0.0 \\
f(3.584428, -1.848126) &amp; = &amp; 0.0
\end{array}
\right.
\]</span>
Obtenha uma estimativa, utilizando o método BFGS, para o ponto de mínimo global da função. Além disso, construa o gráfico da superfície obtida pela função e o gráfico com as curvas de níveis da função com a estimativa obtida indicada como um ponto nesse último gráfico. Interprete o resultado obtido. Houve convergência?</p></li>
<li><p>Considere a <a href="https://en.wikipedia.org/wiki/File:Easom_function.pdf"><strong>Earson function</strong></a>, função definida abaixo:</p>
<p><span class="math display">\[f(x,y) = -\cos(x)\cos(y)\exp\{-[(x-\pi)^2 + (y-\pi)^2]\},\]</span></p>
<p>em que <span class="math inline">\(-100 \leq x,y \leq 100\)</span>. Essa função possui mínimo global no ponto <span class="math inline">\((\pi,\pi)\)</span>, com <span class="math inline">\(f(\pi,\pi) = -1\)</span>. Obtenha uma estimativa, utilizando o método BFGS, para o ponto de mínimo global da função. Além disso, construa o gráfico da superfície obtida pela função e o gráfico com as curvas de níveis da função com a estimativa obtida indicada como um ponto nesse último gráfico. Interprete o resultado obtido. Houve convergência? O que você observa variando os chutes iniciais?</p></li>
<li><p>Por que os métodos de Newton ou quasi-Newton apresentam dificuldades de otmizar uma função objetivo como a função do exercício logo acima? Explique.</p></li>
<li><p>Considere <a href="https://en.wikipedia.org/wiki/File:Holder_table_function.pdf"><strong>Hölder table function</strong></a>, função definida como:</p></li>
</ol>
<p><span class="math display">\[f(x,y) = - \left| \sin(x) \cos(y) \exp \left( \left| 1 - \frac{\sqrt{x^2 + y^2}}{\pi}  \right|  \right)   \right|,\]</span>
em que <span class="math inline">\(-10 \leq x,y \leq 10\)</span>. Essa função possui mínimos globais em:</p>
<p><span class="math display">\[
   \mathrm{Min} = \left\{
   \begin{array}{ccc}
   f(8.05502,\, 9.66459) &amp; = &amp; -19.2085
   \\
   f(-8.05502,\, 9.66459) &amp; = &amp; -19.2085
   \\
   f(8.05502,\, -9.66459) &amp; = &amp; -19.2085
   \\
   f(-8.05502,\,-9.66459) &amp; = &amp; -19.2085
   \\
   \end{array}
   \right.
   \]</span>
Obtenha uma estimativa, utilizando o método BFGS, para o ponto de mínimo global da função. Além disso, construa o gráfico da superfície obtida pela função e o gráfico com as curvas de níveis da função com a estimativa obtida indicada como um ponto nesse último gráfico. Interprete o resultado obtido. Houve convergência?</p>
<ol start="11" style="list-style-type: decimal">
<li><p>Considere a <a href="https://en.wikipedia.org/wiki/File:Eggholder_function.pdf"><strong>Eggholder function</strong></a>, função definida como:</p>
<p><span class="math display">\[f(x,y) = -(y + 47)\sin \left(\sqrt{\left|\frac{x}{2} + (y + 47)\right|}\right) - x\sin(\left|x - (y + 47)\right|),\]</span>
em que <span class="math inline">\(-512\leq x,y \leq 512\)</span>. Essa função possui mínimo global no ponto <span class="math inline">\((512, 404.2319)\)</span>, assumiando o valor mínio, nesse ponto, em <span class="math inline">\(-959.6407\)</span>. Obtenha uma estimativa, utilizando o método BFGS, para o ponto de mínimo global. Além disso, construa o gráfico da superfície e o gráfico com as curvas de níveis, em que este último deverá apresentar o ponto da estimativa obtida. Houve convergência?</p></li>
<li><p><a href="https://link.springer.com/article/10.1007/s10182-011-0154-5"><strong>Nadarajah e Haghighi (2011)</strong></a> propuseram a distribuição de probabilidade Nadarajah-Haghighi (NH), em que se <span class="math inline">\(X\)</span> é uma v.a. tal que <span class="math inline">\(X \sim \mathrm{NH}(\alpha, \lambda)\)</span>, então a f.d.p. da v.a. <span class="math inline">\(X\)</span> é dada por:</p>
<p><span class="math display">\[f_X(x) = \alpha \lambda (1 + \lambda x)^{\alpha - 1}\exp\{1 - (1 + \lambda x)^\alpha\},\]</span>
com <span class="math inline">\(x &gt; 0\)</span> e <span class="math inline">\(\alpha, \lambda &gt; 0\)</span>. Perceba para <span class="math inline">\(\alpha = 1\)</span>, obtemos a f.d.p. de uma v.a. com distribuição exponencial com parâmetro <span class="math inline">\(\lambda\)</span>. Considere o conjunto de dados: 1.7, 2.2, 14.4, 1.1, 0.4, 20.6, 5.3, 0.7, 1.9, 13.0, 12.0, 9.3, 1.4, 18.7, 8.5, 25.5, 11.6, 14.1, 22.1, 1.1, 2.5, 14.4, 1.7, 37.6, 0.6, 2.2, 39.0, 0.3, 15.0, 11.0, 7.3, 22.9, 1.7, 0.1, 1.1, 0.6, 9.0, 1.7, 7.0, 20.1, 0.4, 2.8, 14.1, 9.9, 10.4, 10.7, 30.0, 3.6, 5.6, 30.8, 13.3, 4.2, 25.5, 3.4, 11.9, 21.5, 27.6, 36.4, 2.7, 64.0, 1.5, 2.5, 27.4, 1.0, 27.1, 20.2, 16.8, 5.3, 9.7, 27.5, 2.5, 27.0. <strong>1</strong> - Obtenha as estimativas de máxima verossimilhança, pelo método BFGS, para os parâmetros <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\lambda\)</span> que indexam <span class="math inline">\(f_X(x)\)</span>. <strong>2</strong> - Construa o histograma dos dados e sobreponha a f.d.p. estimada sobre o histograma. <strong>3</strong> - A densidade estimada parece ajusta-se bem ao conjunto de dados? <strong>4</strong> - Houve convergência do método BFGS? <strong>5</strong> - Em caso de haver convergência, ela é suficiente para garantir de a <span class="math inline">\(f_X(x)\)</span> irá modelar o conjunto de dados? Explique.</p></li>
<li><p>Refaça o exercício acima considerando o conjunto de dados: 0.08, 2.09, 3.48, 4.87, 6.94, 8.66, 13.11, 23.63, 0.20, 2.23, 3.52, 4.98, 6.97, 9.02, 13.29, 0.40, 2.26, 3.57, 5.06, 7.09, 9.22, 13.80, 25.74, 0.50, 2.46, 3.64, 5.09, 7.26, 9.47, 14.24, 25.82, 0.51, 2.54, 3.70, 5.17, 7.28, 9.74, 14.76, 26.31, 0.81, 2.62, 3.82, 5.32, 7.32, 10.06, 14.77, 32.15, 2.64, 3.88, 5.32, 7.39, 10.34, 14.83, 34.26, 0.90, 2.69, 4.18, 5.34, 7.59, 10.66, 15.96, 36.66, 1.05, 2.69, 4.23, 5.41, 7.62, 10.75, 16.62, 43.01, 1.19, 2.75, 4.26, 5.41, 7.63, 17.12, 46.12, 1.26, 2.83, 4.33, 5.49, 7.66, 11.25, 17.14, 79.05, 1.35, 2.87, 5.62, 7.87, 11.64, 17.36, 1.40, 3.02, 4.34, 5.71, 7.93, 11.79, 18.10, 1.46, 4.40, 5.85, 8.26, 11.98, 19.13, 1.76, 3.25, 4.50, 6.25, 8.37, 12.02, 2.02, 3.31, 4.51, 6.54, 8.53, 12.03, 20.28, 2.02, 3.36, 6.76, 12.07, 21.73, 2.07, 3.36, 6.93, 8.65, 12.63, 22.69.</p></li>
</ol>
</div>
<div id="monte-carlo" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Monte Carlo</h2>
<div id="um-breve-histórico-1" class="section level3" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Um breve histórico</h3>
<p>Os métodos de Monte Carlo (MC) é uma classe de metodologias bastante utilizada na estatística moderna. De um modo geral, tais metodologias calculam quantidades sob amostras aleatórias que são gerada/obtidas de forma iterativa, em que ao final obtem-se estatísticas de interesse com base nos resultados armazenados. Os métodos de MC, por exemplo, poderão ser utilizado para estimar parâmetros da distribuição amostral de uma estatística e para o cálculo do erro quadrático médio (EQM). Estudos de MC podem ser projetados para avaliar a probabilidade de cobertura de um intervalo aleatório (probabilidade do intervalo conter o parâmetro verdadeiro) ou para avaliação do Erro Tipo I em um procedimento de teste de hipóteses. Esses são apenas alguns exemplo do uso dos métodos de MC.</p>
<p>Os métodos de MC auxiliam os estatísticos no processo de compararem modelos/estatísticas, em que cada um(a) desses modelos/estatísticas serão submetidos à amostras com “características” prefixadas. Normalmente essas comparações serão realizadas em situações em que evidências analíticas não são possíveis de serem obtidas devido à complexidade dos modelos/estatísticas envolvidas. Sendo assim, ao utilizar-se um procedimento de MC, torna-se desnecessário escrever as equações diferenciais que descrevem o comportamento de um sistema complexo.</p>
<p>Além da estatística, os métodos de MC são bastante utilizados por profissionais em campos díspares como finanças, engenheria, física, biologia, entre outros.</p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Para implementar um método de MC é necessário ter uma fonte de geração de números pseudo-aleatórios além da capacidade de controlarmos a sequência de números gerados. No R, como vimos anteriormente, teremos a nossa disposição diversas funções para a geração de números pseudo-aleatórios uniforme e não-uniformes e poderemos controlar a sequência gerada utilizando a função <code>set.seed()</code>.</p>
</div>
</div>
<p>De acordo com Hammersley, no livro <a href="https://www.springer.com/gp/book/9789400958210"><strong>Monte Carlo Methods</strong></a>, 1964, o nome “Monte Carlo” surgiu durante o projeto Manhattan na época da Segunda Guerra Mundial. O Projeto Manhattan foi liderado pelos Estados Unidos com o apoio do Reino Unido e Canadá. O projeto tinha como objetivo desenvolver pesquisas para a produção das primeiras bombas atômicas durante o período de guerra. O projeto foi uma das maiores colaborações científicas já realizadas que deram origem a inúmeras novas tecnologias, indo muito além do aproveitamente da fissão nuclear.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-23"></span>
<img src="images/trinity.png" alt="Primeiro teste nuclear (nome de código **Trinity**), uma das três bombas atômicas produzidas pelo Projeto Manhattan. Teste realizado em 16 de julho de 1945. Com apenas 0.025 segundos após a detonação, o impacto já tomava conta de uma região com 100 metros de diâmetro." width="75%" />
<p class="caption">
Figura 6.3: Primeiro teste nuclear (nome de código <strong>Trinity</strong>), uma das três bombas atômicas produzidas pelo Projeto Manhattan. Teste realizado em 16 de julho de 1945. Com apenas 0.025 segundos após a detonação, o impacto já tomava conta de uma região com 100 metros de diâmetro.
</p>
</div>
<p>O Projeto Manhattan foi conduzido no Laboratório Nacional de Los Alamos, construído para desenvolver as primeiras bombas atômicas utilizadas na Segunda Guerra Mundial. À época, tratava-se de um centro secreto das forças <a href="https://pt.wikipedia.org/wiki/Aliados"><strong>aliadas</strong></a> para o desenvolvimento de armas nucleares conhecido por <strong>Site Y</strong>. Atualmente o laboratório trata-se de uma das maiores instituições científicas multidisciplinares.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-24"></span>
<img src="images/los_alamos.jpeg" alt="Laboratório de Los Alamos,  laboratório federal pertencente ao Departamento de Energia dos Estados Unidos (DOE), gerido pela Universidade da Califórnia, localizado em Los Alamos, Novo México." width="70%" />
<p class="caption">
Figura 6.4: Laboratório de Los Alamos, laboratório federal pertencente ao Departamento de Energia dos Estados Unidos (DOE), gerido pela Universidade da Califórnia, localizado em Los Alamos, Novo México.
</p>
</div>
<p>O Laboratório Nacional de Los Alamos, em toda sua história, reuniu diversos cientistas catedráticos e ganhadores de prêmios importantes como, por exemplo, o Prêmio Nobel. Na época da Segunda Guerra, diversos cientisticas de grande importância para o desenvolvimento científico e tecnológico atual faziam parte do projeto como <a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam"><strong>Stanislaw Ulam</strong></a>, <a href="https://pt.wikipedia.org/wiki/Richard_Feynman"><strong>Richard Feynman</strong></a> e <a href="https://pt.wikipedia.org/wiki/John_von_Neumann"><strong>John von Neumann</strong></a>.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-25"></span>
<img src="images/Ulam_Feynman_von_Neumann.jpeg" alt="John von Neumann, Richard Feynman e Stanislaus Ulam em Los Alamos durante o Projeto Manhattan (da direita para a esquerda)." width="75%" />
<p class="caption">
Figura 6.5: John von Neumann, Richard Feynman e Stanislaus Ulam em Los Alamos durante o Projeto Manhattan (da direita para a esquerda).
</p>
</div>
<p>No ano de 1946, enquanto se recuperava de uma encefalite, o matemático Stanislaw Ulam jovava paciência. Ele tentou calcular as probabilidades de alguns eventos no jogo utilizando análise combinatória. Porém, percebeu que uma alternativa mais prática seria realizar inúmeras jogadas e contar quantas vezes cada resultado ocorria, ou seja, utilizar a teoria frequentista de probabilidade. Detalhes sobre essa história poderá ser encontrada em <a href="https://permalink.lanl.gov/object/tr?what=info:lanl-repo/lareport/LA-UR-88-9068"><strong>Stam Ulam, John Von Neumann, and the Monte Carlo method, Los Alamos Science n. 15, pg 131 (1987)</strong></a>, artigo livre e disponibilizado pela <a href="https://www.lanl.gov/library"><strong>Los Alamos National Laboratory Research Library</strong></a>. Nesse artigo é apresentado trechos de cartas trocadas entre John von Neuman e Stanislau Ulam. O documento também apresenta uma descrição de 1983 que ajudou a entender a origem dos métodos de Monte Carlo realizada por Stanislaw Ulam, um ano antes do seu falecimento. Abaixo segue uma tradução aproximada do que foi dito:</p>
<blockquote>
<p>“Os primeiros pensamentos e tentativas que fiz para praticar [o método de Monte Carlo] foram sugeridos por uma questão que me ocorreu em 1946, quando eu estava convalescendo de uma doença e jogando paciência. A questão é quais são as chances de um jogador sair com sucesso em um jogo de paciência com 52 cartas? Depois de passar muito tempo tentando estimar, por puro cálculo de combinação, eu me perguntei se um método mais prático que o pensamento abstrato não seria expor cem vezes e simplesmente contar o número de jogadas bem-sucedidas. Isso já foi possível prever com o início da nova era de computadores rápidos, e eu imediatamente pensei em problemas de difusão de nêutrons e outras questões de física/matemática, e mais genericamente como mudar processos descritos por certas equações diferenciais em uma forma equivalente interpretável
como uma sucessão de operações aleatórias. Mais tarde, … [em 1946, eu] descrevi a ideia
à John von Neumann e começamos a planejar cálculos reais.”</p>
</blockquote>
<blockquote>
<p>— Stanislaw Ulam.</p>
</blockquote>
<p>Ulam entendia que as técnicas de amostragem não eram muito utilizadas por envolverem cálculos extremamente demorados, tediósos e sujeito à erros, em uma época em que utilizavam-se dispositivos meânicos para realização de cálculos. Porém, nessa época surgiu o primeiro computador eletrônico, o <a href="https://pt.wikipedia.org/wiki/ENIAC"><strong>ENIAC</strong></a>. Embora muito mais lento que os computadores atuais, o ENIAC impressionou Ulam que sugeriu o uso de técnicas de amostragem estatística e da teoria frequentista de probabilidade para simular a difusão de nêutrons em materiais sujeitos à fissão nuclear.</p>
<p>O físico <a href="https://pt.wikipedia.org/wiki/Nicholas_Metropolis"><strong>Nicholas Metropolis</strong></a>, que também participou do Projeto Manhattan sugeriu o nome <strong>Monte Carlo</strong> para o método estatístico. O nome foi inspirado em um tio de Ulam que sempre tomava dinheiro emprestado com parentes para ir jogar no <a href="https://pt.wikipedia.org/wiki/Casino_de_Monte_Carlo"><strong>cassino de Monte Carlo</strong></a>, no distrito de Monte Carlo, em Mônaco.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-26"></span>
<img src="images/cassino_mc.jpg" alt="[**Le Casino de Monte-Carlo**](https://pt.wikipedia.org/wiki/Casino_de_Monte_Carlo), complexo de jogos e entretenimento localizado no distrito de Monte Carlo, Mônaco." width="75%" />
<p class="caption">
Figura 6.6: <a href="https://pt.wikipedia.org/wiki/Casino_de_Monte_Carlo"><strong>Le Casino de Monte-Carlo</strong></a>, complexo de jogos e entretenimento localizado no distrito de Monte Carlo, Mônaco.
</p>
</div>
<p>Esse fato pode ser lido no artigo <a href="https://la-science.lanl.gov/cgi-bin/getfile?00326866.pdf"><strong>The Beginning of the Monte Carlo Method, escrito por Nicholas Metropolis, Los Alamos, 1987</strong></a>, um outro artigo livre e também disponibilizado pela <a href="https://www.lanl.gov/library"><strong>Los Alamos National Laboratory Research Library</strong></a>. Nicholas Metropolis é também responsável pelo desenvolvimento de trabalhos que deram origem ao algoritmo de <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"><strong>Mepropolis-Hastings</strong></a>, método de MC muito utilizado na geração de números pseudo-aleatórios de distribuições multidimensionais, especialmente quando o número de dimensões é alto.</p>
</div>
<div id="métodos-de-monte-carlo" class="section level3" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Métodos de Monte Carlo</h3>
<p>Nos dias atuais, é muito mais fácil codificar uma simulação de MC para obetenção de aproximações que poderiam ser complicadas de serem obtidas analiticamente. Porém, os procedimentos de MC podem ser utilizados para resolver um problema deterministo. Por exemplo, é possível construir um procedimento de MC para aproximar o valor médio de uma função, bem como para calcular uma integral definida de uma função contínua em um intervalo <span class="math inline">\([a, b]\)</span>, sendo estes exemplos notoriamente determinísticos. Porém, os procedimentos de MC são procedimentos que fazem uso de amostragem aleatória massiva para a obtenção de resultados numéricos aproximados. Por exemplo, o <a href="tópicos-em-estatística-computacional.html#método-da-aceitação-e-rejeição"><strong>método da aceitação e rejeição</strong></a>, apresentado em seções anteriores, é um típico procedimento de MC, uma vez que o método é iterativo e em suas iterações faz uso de geração de observações de uma sequência de variáveis aleatórias. O exemplo que segue mostra a construção de um procedimento simples de MC para o cálculo aproximado do valor médio de uma função.</p>
<p><strong>Exemplo</strong>: Calculando o ponto médio de uma função determinística utilizando simulações de MC. Seja <span class="math inline">\(h(x) = \mathrm{sen}(x)\)</span>, tal que <span class="math inline">\(x \in [0, 2\pi]\)</span>. Então, analiticamente, o ponto médio da função <span class="math inline">\(h(x)\)</span> é dado por:</p>
<p><span class="math display">\[\overline{h} = \frac{1}{2\pi} \int_0^{2\pi} \mathrm{sen}(x) dx = \frac{1}{2\pi}[-\cos(x)] \Big|_0^{2\pi} = -\frac{1}{2\pi}[\cos(2\pi) - \cos(0)] = -\frac{1}{2\pi}\times 0 = 0.\]</span>
<strong>Lembre-se</strong>: O ponto médio de uma função diferenciável no intervalo <span class="math inline">\([a,b]\)</span> é dado por</p>
<p><span class="math display">\[\overline{h} = \frac{1}{b-a} \int_a^b h(x) dx.\]</span>
Para a função em questão, sob um olhar gráfico, temos que:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-27"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-27-1.png" alt="Função seno(x), em que a reta azul destaca o ponto médio analítico da função." width="672" />
<p class="caption">
Figura 6.7: Função seno(x), em que a reta azul destaca o ponto médio analítico da função.
</p>
</div>
<p>Caso não desejássemos calcular a integral acima, o que não justifica-se, uma vez que a integral é bastante simples, poderemos aproximar o valor médio da função <span class="math inline">\(h(x)\)</span> utilizando uma simples simulação de MC. Para tanto, deveremos selecionar aleatoriamente diversos pontos da função e tirar uma média aritmética. Quanto mais pontos gearmos, melhor será a nossa aproximiação.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="tópicos-em-estatística-computacional.html#cb10-1" aria-hidden="true"></a><span class="co"># Número de réplicas de Monte Carlo (MC):</span></span>
<span id="cb10-2"><a href="tópicos-em-estatística-computacional.html#cb10-2" aria-hidden="true"></a>N &lt;-<span class="st"> </span>50L</span>
<span id="cb10-3"><a href="tópicos-em-estatística-computacional.html#cb10-3" aria-hidden="true"></a><span class="co"># Fixando uma semente.</span></span>
<span id="cb10-4"><a href="tópicos-em-estatística-computacional.html#cb10-4" aria-hidden="true"></a><span class="kw">set.seed</span>(1L) </span>
<span id="cb10-5"><a href="tópicos-em-estatística-computacional.html#cb10-5" aria-hidden="true"></a><span class="co"># Média dos valores da função:</span></span>
<span id="cb10-6"><a href="tópicos-em-estatística-computacional.html#cb10-6" aria-hidden="true"></a>mean_est &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">sin</span>(<span class="kw">runif</span>(<span class="dt">n =</span> N, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi)))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-29"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-29-1.png" alt="Função seno(x), em que a reta azul destaca o ponto médio analítico e a reta em vermelho destaca o ponto médio estimado para 50 réplicas de MC, com os pontos selecionados estão destacados." width="672" />
<p class="caption">
Figura 6.8: Função seno(x), em que a reta azul destaca o ponto médio analítico e a reta em vermelho destaca o ponto médio estimado para 50 réplicas de MC, com os pontos selecionados estão destacados.
</p>
</div>
</div>
<div id="integração-por-monte-carlo" class="section level3" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> Integração por Monte Carlo</h3>
<p>O exercício anterior nos fornece tudo que precisaremos para desenvolver um método de MC para o cálculo aproximado de uma integral definida de uma função <span class="math inline">\(h(x)\)</span> com <span class="math inline">\(x \in [a, b]\)</span>. Se</p>
<p><span class="math display">\[\overline{h} = \frac{1}{b-a}\int_a^b h(x) dx\]</span>
e sabemos estimar <span class="math inline">\(\overline{h}\)</span> pelo método de MC, então saberemos caclular <span class="math inline">\(\int_a^b h(x) dx\)</span>, uma vez que basta fazer:</p>
<p><span class="math display">\[\int_a^b h(x) dx = (b - a)\overline{h},\]</span>
em que <span class="math inline">\(\overline{h}\)</span> é aproximado por MC.</p>
<p><strong>Observação</strong>:</p>

<div class="rmdobservation">
<div class="text-justify">
<p>Para obtermos uma aproximação para a integral de uma função <span class="math inline">\(h(x)\)</span> com <span class="math inline">\(x \in [a, b]\)</span>, precisamos apenas calcular o ponto médio da função e multiplicar por <span class="math inline">\((b-a)\)</span>. Dessa forma, estimando o ponto médio de uma função por MC nos conduz diretamente ao método de MC para obter <span class="math inline">\(\int_a^b h(x) dx\)</span>.</p>
</div>
</div>
<p><strong>Exemplo</strong>: Seja <span class="math inline">\(X\)</span> uma v.a. tal que <span class="math inline">\(X \sim Weibull(\alpha, \beta)\)</span>, com <span class="math inline">\(\alpha, \beta &gt; 0\)</span> e <span class="math inline">\(x \geq 0\)</span>. Implemente a função <code>intmc(N = 1e3L, fun, lower = NULL, upper = NULL, ...)</code>, que aproxima por MC a integral de uma função, em que <code>N</code> é o número de réplicas de MC, <code>fun</code> é a função que desejamos integrar, <code>lower</code> é o limite inferior de integração, <code>upper</code> é o limite superior de integração e <code>...</code> é o operador dot-dot-dot. Por meio da função <code>intmc()</code> e da função <code>integrate()</code>, obtenha uma aproximação para <span class="math inline">\(P(X \leq 2)\)</span>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="tópicos-em-estatística-computacional.html#cb11-1" aria-hidden="true"></a>fdp_weibull &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) <span class="kw">dweibull</span>(x, <span class="dt">shape =</span> alpha, <span class="dt">scale =</span> beta)</span>
<span id="cb11-2"><a href="tópicos-em-estatística-computacional.html#cb11-2" aria-hidden="true"></a></span>
<span id="cb11-3"><a href="tópicos-em-estatística-computacional.html#cb11-3" aria-hidden="true"></a>intmc &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, fun, <span class="dt">lower =</span> <span class="ot">NULL</span>, <span class="dt">upper =</span> <span class="ot">NULL</span>, ...){</span>
<span id="cb11-4"><a href="tópicos-em-estatística-computacional.html#cb11-4" aria-hidden="true"></a>  <span class="cf">if</span> (<span class="kw">missing</span>(fun)) <span class="kw">stop</span> (<span class="st">&quot;The function has been omitted.&quot;</span>)</span>
<span id="cb11-5"><a href="tópicos-em-estatística-computacional.html#cb11-5" aria-hidden="true"></a>  <span class="cf">if</span> (<span class="kw">is.null</span>(lower) <span class="op">||</span><span class="st"> </span><span class="kw">is.null</span>(upper)) <span class="kw">stop</span> (<span class="st">&quot;Integration limits must be specified.&quot;</span>)</span>
<span id="cb11-6"><a href="tópicos-em-estatística-computacional.html#cb11-6" aria-hidden="true"></a>  </span>
<span id="cb11-7"><a href="tópicos-em-estatística-computacional.html#cb11-7" aria-hidden="true"></a>  <span class="co"># Gerando valores uniformes no suporte da função:</span></span>
<span id="cb11-8"><a href="tópicos-em-estatística-computacional.html#cb11-8" aria-hidden="true"></a>  u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> N, <span class="dt">min =</span> lower, <span class="dt">max =</span> upper)</span>
<span id="cb11-9"><a href="tópicos-em-estatística-computacional.html#cb11-9" aria-hidden="true"></a>  </span>
<span id="cb11-10"><a href="tópicos-em-estatística-computacional.html#cb11-10" aria-hidden="true"></a>  <span class="co"># Valor aproximado da integral:</span></span>
<span id="cb11-11"><a href="tópicos-em-estatística-computacional.html#cb11-11" aria-hidden="true"></a>  (upper <span class="op">-</span><span class="st"> </span>lower) <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(<span class="kw">fun</span>(<span class="dt">x =</span> u, ...)) </span>
<span id="cb11-12"><a href="tópicos-em-estatística-computacional.html#cb11-12" aria-hidden="true"></a>}</span>
<span id="cb11-13"><a href="tópicos-em-estatística-computacional.html#cb11-13" aria-hidden="true"></a></span>
<span id="cb11-14"><a href="tópicos-em-estatística-computacional.html#cb11-14" aria-hidden="true"></a><span class="co"># P(X &lt; 2):</span></span>
<span id="cb11-15"><a href="tópicos-em-estatística-computacional.html#cb11-15" aria-hidden="true"></a><span class="kw">round</span>(<span class="kw">pweibull</span>(<span class="dt">q =</span> <span class="dv">2</span>, <span class="dt">shape =</span> <span class="fl">1.5</span>, <span class="dt">scale =</span> <span class="fl">1.2</span>), <span class="dt">digits =</span> 4L)</span></code></pre></div>
<pre><code>## [1] 0.8837</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="tópicos-em-estatística-computacional.html#cb13-1" aria-hidden="true"></a><span class="kw">set.seed</span>(1L)</span>
<span id="cb13-2"><a href="tópicos-em-estatística-computacional.html#cb13-2" aria-hidden="true"></a><span class="co"># P(X &lt; 2) por MC:</span></span>
<span id="cb13-3"><a href="tópicos-em-estatística-computacional.html#cb13-3" aria-hidden="true"></a><span class="kw">round</span>(<span class="kw">intmc</span>(<span class="dt">N =</span> <span class="fl">5e6</span>, <span class="dt">fun =</span> fdp_weibull, <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">2</span>,</span>
<span id="cb13-4"><a href="tópicos-em-estatística-computacional.html#cb13-4" aria-hidden="true"></a>      <span class="dt">alpha =</span> <span class="fl">1.5</span>, <span class="dt">beta =</span> <span class="fl">1.2</span>), <span class="dt">digits =</span> 4L)</span></code></pre></div>
<pre><code>## [1] 0.8837</code></pre>
<p>O método de integraçao de MC poderá ser entendido também por meio de uma interpretação estatística. Seja <span class="math inline">\(h(x)\)</span> uma função, com <span class="math inline">\(x \in [a, b]\)</span> e suponha que desejamos obter uma estimativa para</p>
<p><span class="math display">\[I = \int_a^b h(x) dx.\]</span></p>
<p>Note que a integral acima poderá ser reescrita, sem alterar o seu resultado, como:</p>
<p><span class="math display">\[I = (b - a) \int_a^b h(x) \frac{1}{b-a}dx.\]</span>
Perceba também que se <span class="math inline">\(X\)</span> é uma v.a., tal que <span class="math inline">\(X \sim \mathcal{U}(a, b)\)</span>, então, <span class="math inline">\(f_X(x) = \frac{1}{b-a}\)</span>, com <span class="math inline">\(a \leq x \leq b\)</span> é a f.d.p. de <span class="math inline">\(X\)</span>. Dessa forma,</p>
<p><span class="math display">\[\begin{eqnarray}
I &amp; = &amp; (b - a) \int_a^b h(x) \frac{1}{b-a}dx = (b - a) \int_a^b h(x) f_X(x)dx = (b - a) \times \mathrm{E}[h(X)]\\
  &amp; = &amp; (b - a) \times \mu.
\end{eqnarray}\]</span></p>
<p>Assim, perceba que o problema de calcular <span class="math inline">\(I\)</span> recai sobre o problema de calcular um valor esperado, isto é, calcular <span class="math inline">\(\mu\)</span>. Dessa forma, precisaremos de um <span class="math inline">\(\hat{\mu}\)</span> que nos forneça uma boa estimativa para <span class="math inline">\(\mu\)</span>. Consideremos</p>
<p><span class="math display">\[\hat{\mu} = n^{-1}\sum_{i=1}^n h(X_i),\]</span>
um estimador para <span class="math inline">\(\mu\)</span>. Dessa forma, temos especificado um estimador para <span class="math inline">\(I\)</span> que é dado por:</p>
<p><span class="math display">\[\hat{I} = (b - a)\hat{\mu}.\]</span>
Perceba que <span class="math inline">\(\hat{\mu}\)</span> é um estimador não-viesado para <span class="math inline">\(\mu\)</span>. Isso implica que <span class="math inline">\(\hat{I}\)</span> também será um estimador não-viesado para <span class="math inline">\(I\)</span>. Mais importante, temos que <span class="math inline">\(\hat{\mu}\)</span> é um estimador consistente para <span class="math inline">\(\mu\)</span>. Isso é verdade, uma vez que se <span class="math inline">\(X_i, \ldots, X_n\)</span> é uma sequência de v.a.’s i.i.d. em um mesmo espaço de probabilidade, então</p>
<p><span class="math display">\[P\Big(|S_n - n\mu| \geq n\varepsilon\Big) \leq \frac{\mathrm{Var}(S_n)}{\varepsilon^2 n^2},\]</span>
pela desigualdade de Chebychev, em que <span class="math inline">\(S_n = \sum_{i=1}^n h(X_i)\)</span>. Como <span class="math inline">\(X_i, \ldots, X_n\)</span> é uma sequência de v.a.’s i.i.d., tal que <span class="math inline">\(X_i \sim \mathcal{U}(a,b), \, \forall\, i\)</span>, então</p>
<p><span class="math display">\[\mathrm{Var}(S_n) = n \mathrm{Var}[h(X_i)].\]</span>
Logo,</p>
<p><span class="math display">\[\lim_{n \to +\infty}P\Big(\Big|S_n - n\mu\Big| \geq n\varepsilon\Big) \leq \lim_{n \to +\infty}\frac{\mathrm{Var}[h(X_i)]}{n\varepsilon^2} = 0,\]</span>
uma vez que <span class="math inline">\(h(x)\)</span> é uma função contínua no intervalo <span class="math inline">\([a, b]\)</span>, logo existe um <span class="math inline">\(M\)</span> tal que <span class="math inline">\(|h(X_i)| \leq M, \forall\, i\)</span>.</p>
<p>Assim, temos que <span class="math inline">\(\hat{\mu}\)</span> converge em probabilidade para <span class="math inline">\(\mu\)</span> (<span class="math inline">\(\hat{\mu}\)</span> é consistente para se estimar <span class="math inline">\(\mu\)</span>) e denotamos por <span class="math inline">\(\hat{\mu} \overset{p}{\to} \mu\)</span>. Sendo assim, temos que <span class="math inline">\(\hat{I}\)</span> é um estimador consistente para <span class="math inline">\(I\)</span>. Isso garante que a medida que tomamos mais pontos, mais nos aproximamos do valor verdadeiro da integral, ou seja, mais nos aproximamos de <span class="math inline">\(I\)</span>.</p>
<p>Note que a variância de <span class="math inline">\(\hat{I}\)</span> é dada por:</p>
<p><span class="math display">\[\mathrm{Var}(\hat{I}) = (b - a)^2 \mathrm{Var}(\hat{\mu}) = \frac{(b - a)^2}{n}\mathrm{Var}[h(X)].\]</span>
Pela definição de variância, temos que</p>
<p><span class="math display">\[\sigma^2 = \mathrm{Var}(\hat{I}) =  \mathrm{E}\Big(\hat{I}^2\Big) - E^2(\hat{I}) = \gamma - \eta^2.\]</span>
Assim, um estimador para <span class="math inline">\(\mathrm{Var}(\hat{I})\)</span> também poderá ser obtido utilizando um procedimento de MC, de tal forma que:</p>
<p><span class="math display">\[\widehat{\sigma}^2 = \widehat{\mathrm{Var}(\hat{I})} = \overline{\widehat{\gamma}} - \overline{\widehat{\eta}}^2,\]</span></p>
<p>em que <span class="math inline">\(\overline{\widehat{\gamma}} = n^{-1} \sum_{i=1}^n \hat{I}_i^2\)</span> e <span class="math inline">\(\overline{\widehat{\eta}}^2 = \Big(n^{-1}\sum_{i=1}^n\hat{I}_i\Big)^2\)</span>. Perceba que <span class="math inline">\(\hat{I}_i\)</span> é obtido por um procedimento de MC para cada <span class="math inline">\(i\)</span>, com <span class="math inline">\(i = 1, \ldots, n\)</span>. Sendo assim, necessitamos de várias estimativas da integral para se obter uma estimativa de <span class="math inline">\(\mathrm{Var}(\hat{I})\)</span> que também é um procedimento de MC.</p>
<p><strong>Exemplo</strong>: Abaixo é implementado a função <code>intvarmc(N = 1e3L, fun, lower = NULL, upper = NULL, ...)</code> que retona uma estimativa para a integral de uma função, a variância estimada por MC do estimador <span class="math inline">\(\hat{I}\)</span> e um vetor de estimativas <span class="math inline">\(\hat{I}\)</span> utilizados para o cálculo de <span class="math inline">\(\widehat{\mathrm{Var}(\hat{I})}\)</span> por MC. Em que</p>
<ul>
<li><p><code>N</code> é a quantidade de réplicas de MC. Por padrão <code>N = 1e3L</code>;</p></li>
<li><p><code>fun</code> é a função contínua que desejamos integrar;</p></li>
<li><p><code>lower</code> é o limite inferior de integração;</p></li>
<li><p><code>upper</code> é o limite superior de integração;</p></li>
<li><p><code>...</code> é o argumento dot-dot-dot (varargs) que será útil para passarmos outros argumentos à função que desejamos integrar.</p></li>
</ul>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="tópicos-em-estatística-computacional.html#cb15-1" aria-hidden="true"></a>fdp_weibull &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) <span class="kw">dweibull</span>(x, <span class="dt">shape =</span> alpha,</span>
<span id="cb15-2"><a href="tópicos-em-estatística-computacional.html#cb15-2" aria-hidden="true"></a>                                                 <span class="dt">scale =</span> beta)</span>
<span id="cb15-3"><a href="tópicos-em-estatística-computacional.html#cb15-3" aria-hidden="true"></a></span>
<span id="cb15-4"><a href="tópicos-em-estatística-computacional.html#cb15-4" aria-hidden="true"></a>intmc &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, fun, <span class="dt">lower =</span> <span class="ot">NULL</span>, <span class="dt">upper =</span> <span class="ot">NULL</span>, ...){</span>
<span id="cb15-5"><a href="tópicos-em-estatística-computacional.html#cb15-5" aria-hidden="true"></a>  <span class="cf">if</span> (<span class="kw">missing</span>(fun)) <span class="kw">stop</span> (<span class="st">&quot;The function has been omitted.&quot;</span>)</span>
<span id="cb15-6"><a href="tópicos-em-estatística-computacional.html#cb15-6" aria-hidden="true"></a>  <span class="cf">if</span> (<span class="kw">is.null</span>(lower) <span class="op">||</span><span class="st"> </span><span class="kw">is.null</span>(upper)) <span class="kw">stop</span> (<span class="st">&quot;Integration limits must be specified.&quot;</span>)</span>
<span id="cb15-7"><a href="tópicos-em-estatística-computacional.html#cb15-7" aria-hidden="true"></a>  </span>
<span id="cb15-8"><a href="tópicos-em-estatística-computacional.html#cb15-8" aria-hidden="true"></a>  <span class="co"># Gerando valores uniformes no suporte da função:</span></span>
<span id="cb15-9"><a href="tópicos-em-estatística-computacional.html#cb15-9" aria-hidden="true"></a>  u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> N, <span class="dt">min =</span> lower, <span class="dt">max =</span> upper)</span>
<span id="cb15-10"><a href="tópicos-em-estatística-computacional.html#cb15-10" aria-hidden="true"></a>  </span>
<span id="cb15-11"><a href="tópicos-em-estatística-computacional.html#cb15-11" aria-hidden="true"></a>  <span class="co"># Valor aproximado da integral:</span></span>
<span id="cb15-12"><a href="tópicos-em-estatística-computacional.html#cb15-12" aria-hidden="true"></a>  (upper <span class="op">-</span><span class="st"> </span>lower) <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(<span class="kw">fun</span>(<span class="dt">x =</span> u, ...))</span>
<span id="cb15-13"><a href="tópicos-em-estatística-computacional.html#cb15-13" aria-hidden="true"></a>  </span>
<span id="cb15-14"><a href="tópicos-em-estatística-computacional.html#cb15-14" aria-hidden="true"></a>}</span>
<span id="cb15-15"><a href="tópicos-em-estatística-computacional.html#cb15-15" aria-hidden="true"></a></span>
<span id="cb15-16"><a href="tópicos-em-estatística-computacional.html#cb15-16" aria-hidden="true"></a><span class="co"># Essa função retorna uma estimativa da integral de uma função h(x) por MC</span></span>
<span id="cb15-17"><a href="tópicos-em-estatística-computacional.html#cb15-17" aria-hidden="true"></a><span class="co"># uma estimativa da da variância do estimador de MC para integral de h(x):</span></span>
<span id="cb15-18"><a href="tópicos-em-estatística-computacional.html#cb15-18" aria-hidden="true"></a>intvarmc &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, fun, <span class="dt">lower =</span> <span class="ot">NULL</span>, <span class="dt">upper =</span> <span class="ot">NULL</span>, ...){</span>
<span id="cb15-19"><a href="tópicos-em-estatística-computacional.html#cb15-19" aria-hidden="true"></a></span>
<span id="cb15-20"><a href="tópicos-em-estatística-computacional.html#cb15-20" aria-hidden="true"></a>  intmc_map &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...) <span class="kw">intmc</span>(N, fun, lower, upper, ...)</span>
<span id="cb15-21"><a href="tópicos-em-estatística-computacional.html#cb15-21" aria-hidden="true"></a>    </span>
<span id="cb15-22"><a href="tópicos-em-estatística-computacional.html#cb15-22" aria-hidden="true"></a>  i_hat &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map_dbl</span>(<span class="dt">.x =</span> <span class="dv">1</span><span class="op">:</span>N, <span class="dt">.f =</span> intmc_map, ...)</span>
<span id="cb15-23"><a href="tópicos-em-estatística-computacional.html#cb15-23" aria-hidden="true"></a>    </span>
<span id="cb15-24"><a href="tópicos-em-estatística-computacional.html#cb15-24" aria-hidden="true"></a>  var_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(i_hat <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(i_hat) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb15-25"><a href="tópicos-em-estatística-computacional.html#cb15-25" aria-hidden="true"></a>    </span>
<span id="cb15-26"><a href="tópicos-em-estatística-computacional.html#cb15-26" aria-hidden="true"></a>  <span class="kw">list</span>(<span class="dt">i_hat =</span> <span class="kw">mean</span>(i_hat), <span class="dt">var_hat =</span> var_hat, <span class="dt">vec_ihat =</span> i_hat)</span>
<span id="cb15-27"><a href="tópicos-em-estatística-computacional.html#cb15-27" aria-hidden="true"></a>}</span>
<span id="cb15-28"><a href="tópicos-em-estatística-computacional.html#cb15-28" aria-hidden="true"></a></span>
<span id="cb15-29"><a href="tópicos-em-estatística-computacional.html#cb15-29" aria-hidden="true"></a><span class="kw">set.seed</span>(0L)</span>
<span id="cb15-30"><a href="tópicos-em-estatística-computacional.html#cb15-30" aria-hidden="true"></a>result &lt;-<span class="st"> </span><span class="kw">intvarmc</span>(<span class="dt">N =</span> <span class="fl">5e3</span>L, <span class="dt">fun =</span> fdp_weibull, <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">10</span>,</span>
<span id="cb15-31"><a href="tópicos-em-estatística-computacional.html#cb15-31" aria-hidden="true"></a>                   <span class="dt">alpha =</span> <span class="fl">1.5</span>, <span class="dt">beta =</span> <span class="fl">1.5</span>)</span>
<span id="cb15-32"><a href="tópicos-em-estatística-computacional.html#cb15-32" aria-hidden="true"></a><span class="kw">str</span>(result)</span></code></pre></div>
<pre><code>## List of 3
##  $ i_hat   : num 1
##  $ var_hat : num 0.000503
##  $ vec_ihat: num [1:5000] 1.029 0.975 0.999 1.005 1.031 ...</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="tópicos-em-estatística-computacional.html#cb17-1" aria-hidden="true"></a><span class="co"># Realizando um teste de normalidade pelo</span></span>
<span id="cb17-2"><a href="tópicos-em-estatística-computacional.html#cb17-2" aria-hidden="true"></a><span class="co"># teste de Shapiro-Wilk:</span></span>
<span id="cb17-3"><a href="tópicos-em-estatística-computacional.html#cb17-3" aria-hidden="true"></a><span class="kw">shapiro.test</span>(result<span class="op">$</span>vec_ihat)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  result$vec_ihat
## W = 0.99969, p-value = 0.6642</code></pre>
<p>Uma vez que são médias, perceba que as estimativas obtidas por <span class="math inline">\(\hat{I}_1, \ldots, \hat{I}_n\)</span> aparentemente segue uma distribuição normal, em que <span class="math inline">\(\hat{I}_i \sim \mathcal{N}(I, \sigma^2/n)\)</span>, o que é garantido pelo <a href="https://pt.wikipedia.org/wiki/Teorema_central_do_limite"><strong>Teorema Central do Limite</strong></a>.</p>
<p>Construindo um histograma e realizando um teste de normalidade, temos:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="tópicos-em-estatística-computacional.html#cb19-1" aria-hidden="true"></a><span class="kw">hist</span>(result<span class="op">$</span>vec_ihat, <span class="dt">main =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Estimativas &quot;</span>, <span class="kw">hat</span>(I)[i])), </span>
<span id="cb19-2"><a href="tópicos-em-estatística-computacional.html#cb19-2" aria-hidden="true"></a>     <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">hat</span>(I)[i]), <span class="dt">ylab =</span> <span class="st">&quot;Frequência&quot;</span>,</span>
<span id="cb19-3"><a href="tópicos-em-estatística-computacional.html#cb19-3" aria-hidden="true"></a>     <span class="dt">border =</span> <span class="ot">NA</span>, <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="dv">1</span>, <span class="fl">0.9</span>, <span class="fl">0.8</span>))</span></code></pre></div>
<p><img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-33-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>Observação</strong>:</p>

<div class="rmdobservation">
<div class="text-justify">
<p>Note que a distribuição de <span class="math inline">\(\hat{I}_i, \forall \, i\)</span> é centrada no valor da integral que desejamos calcular. No caso do exercício acima, como a função é uma f.d.p, então a distribuição será centrada em 1.</p>
</div>
</div>
</div>
<div id="aproximando-o-valor-de-pi" class="section level3" number="6.4.4">
<h3><span class="header-section-number">6.4.4</span> Aproximando o valor de <span class="math inline">\(\pi\)</span></h3>
<p>Uma outra aplicação bastante conhecida dos métodos de MC é a obtenção de um valor aproximado para a constante <span class="math inline">\(\pi\)</span>. O método para aproximação do valor de <span class="math inline">\(\pi\)</span> é construído considerando inicialmente uma circunferência de raio (<span class="math inline">\(r = 1\)</span>) na seguinte forma:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-35"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-35-1.png" alt="Cicunferência centrada no ponton (0,0) de raio igual à 1 (um) e de área igual à constante de desejamos estimar." width="480" />
<p class="caption">
Figura 6.9: Cicunferência centrada no ponton (0,0) de raio igual à 1 (um) e de área igual à constante de desejamos estimar.
</p>
</div>
<p>A estatégia por meio de um procedimento de MC é gerar massivamente (mil, 10 mil, 100 mil, …) pontos no interior do quadrado de área 1. Dessa forma, deveremos contabilizar a quantidade de pontos que cairam no interior da circunferência e dividir pelo total de pontos, isto é, desejamos obter a proporção de pontos que cairam dentro da circunferência, onde teremos, assim, uma aproximação da área. Porém, perceba que poderemos nos restringir ao primeiro quadrante, com área igual à <span class="math inline">\(\frac{\pi}{4}\)</span>. Dessa forma, considerando apenas o primerio quadrante, temos que a porporção de pontos que caem no interior da circunferência multiplicada por 4 irá fornecer uma aproximação para o valor de <span class="math inline">\(\pi\)</span>.</p>
<p><strong>Exemplo</strong>: Implemente a função <code>insideplot(x, y)</code> que recebe como argumentos dois vetores de mesmo comprimento. A função deverá construir um gráfico do primeiro quadrante da circunferência, em um quadrado unitário, com os pontos formados pelos valores dos vetores, par a par, destancando de vermelho os pontos no interior da circunferência e de azul àqueles que caem fora dela.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="tópicos-em-estatística-computacional.html#cb20-1" aria-hidden="true"></a>insideplot &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) {</span>
<span id="cb20-2"><a href="tópicos-em-estatística-computacional.html#cb20-2" aria-hidden="true"></a>  <span class="kw">plot.new</span>()</span>
<span id="cb20-3"><a href="tópicos-em-estatística-computacional.html#cb20-3" aria-hidden="true"></a>  <span class="kw">plot.window</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb20-4"><a href="tópicos-em-estatística-computacional.html#cb20-4" aria-hidden="true"></a>  <span class="kw">axis</span>(<span class="dv">1</span>); <span class="kw">axis</span>(<span class="dv">2</span>)</span>
<span id="cb20-5"><a href="tópicos-em-estatística-computacional.html#cb20-5" aria-hidden="true"></a>  <span class="kw">title</span>(<span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;y&quot;</span>)</span>
<span id="cb20-6"><a href="tópicos-em-estatística-computacional.html#cb20-6" aria-hidden="true"></a></span>
<span id="cb20-7"><a href="tópicos-em-estatística-computacional.html#cb20-7" aria-hidden="true"></a>  x_circ &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> 1000L)</span>
<span id="cb20-8"><a href="tópicos-em-estatística-computacional.html#cb20-8" aria-hidden="true"></a>  y_circ &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>x_circ <span class="op">^</span><span class="st"> </span><span class="dv">2</span>)</span>
<span id="cb20-9"><a href="tópicos-em-estatística-computacional.html#cb20-9" aria-hidden="true"></a></span>
<span id="cb20-10"><a href="tópicos-em-estatística-computacional.html#cb20-10" aria-hidden="true"></a>  test &lt;-<span class="st"> </span><span class="cf">function</span>(x, y){</span>
<span id="cb20-11"><a href="tópicos-em-estatística-computacional.html#cb20-11" aria-hidden="true"></a>    <span class="cf">if</span> ((x <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>y <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1</span>) <span class="kw">points</span>(x, y, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">pch =</span> <span class="dv">19</span>)</span>
<span id="cb20-12"><a href="tópicos-em-estatística-computacional.html#cb20-12" aria-hidden="true"></a>    <span class="cf">else</span> <span class="kw">points</span>(x, y, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">pch =</span> <span class="dv">19</span>)</span>
<span id="cb20-13"><a href="tópicos-em-estatística-computacional.html#cb20-13" aria-hidden="true"></a>  }</span>
<span id="cb20-14"><a href="tópicos-em-estatística-computacional.html#cb20-14" aria-hidden="true"></a>  <span class="kw">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dt">lwd =</span> <span class="dv">2</span>); <span class="kw">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb20-15"><a href="tópicos-em-estatística-computacional.html#cb20-15" aria-hidden="true"></a>  <span class="kw">segments</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>); <span class="kw">segments</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb20-16"><a href="tópicos-em-estatística-computacional.html#cb20-16" aria-hidden="true"></a></span>
<span id="cb20-17"><a href="tópicos-em-estatística-computacional.html#cb20-17" aria-hidden="true"></a>  <span class="kw">lines</span>(x_circ, y_circ, <span class="dt">lwd =</span> 2L)</span>
<span id="cb20-18"><a href="tópicos-em-estatística-computacional.html#cb20-18" aria-hidden="true"></a>  <span class="kw">invisible</span>(<span class="kw">mapply</span>(<span class="dt">FUN =</span> test, x, y))</span>
<span id="cb20-19"><a href="tópicos-em-estatística-computacional.html#cb20-19" aria-hidden="true"></a>}</span>
<span id="cb20-20"><a href="tópicos-em-estatística-computacional.html#cb20-20" aria-hidden="true"></a>x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.42</span>, <span class="fl">0.24</span>, <span class="fl">0.81</span>, <span class="fl">0.93</span>)</span>
<span id="cb20-21"><a href="tópicos-em-estatística-computacional.html#cb20-21" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.21</span>, <span class="fl">0.47</span>, <span class="fl">0.72</span>, <span class="fl">0.85</span>)</span>
<span id="cb20-22"><a href="tópicos-em-estatística-computacional.html#cb20-22" aria-hidden="true"></a><span class="kw">insideplot</span>(x, y)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-36"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-36-1.png" alt="Resultado do uso da função insideplot() nos pontos (0.42, 0.21), (0.24, 0.47), (0.81, 0.72) e (0.93, 0.85), em que pontos vemelhos estão no interior da circunferência e pontos azuis fora dela." width="480" />
<p class="caption">
Figura 6.10: Resultado do uso da função insideplot() nos pontos (0.42, 0.21), (0.24, 0.47), (0.81, 0.72) e (0.93, 0.85), em que pontos vemelhos estão no interior da circunferência e pontos azuis fora dela.
</p>
</div>
<p><strong>Exemplo</strong>: Implementando a função <code>mcpi(N = 1e3L)</code> que aproxima o valor da constante <span class="math inline">\(\pi\)</span> por meio de um procedimento de MC. A função <code>mcpi()</code> retornará o valor aproximado da constante <span class="math inline">\(\pi\)</span> e construirá o gráfico com os pontos gerados utilizando a função <code>insideplot()</code>.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="tópicos-em-estatística-computacional.html#cb21-1" aria-hidden="true"></a><span class="co"># Aproximando o valor da constante pi por MC:</span></span>
<span id="cb21-2"><a href="tópicos-em-estatística-computacional.html#cb21-2" aria-hidden="true"></a>mcpi &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L){</span>
<span id="cb21-3"><a href="tópicos-em-estatística-computacional.html#cb21-3" aria-hidden="true"></a>  x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> N, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>)</span>
<span id="cb21-4"><a href="tópicos-em-estatística-computacional.html#cb21-4" aria-hidden="true"></a>  y &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> N, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>)</span>
<span id="cb21-5"><a href="tópicos-em-estatística-computacional.html#cb21-5" aria-hidden="true"></a></span>
<span id="cb21-6"><a href="tópicos-em-estatística-computacional.html#cb21-6" aria-hidden="true"></a>  inside &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) <span class="kw">ifelse</span>((x <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>y <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1</span>, <span class="ot">TRUE</span>, <span class="ot">FALSE</span>)</span>
<span id="cb21-7"><a href="tópicos-em-estatística-computacional.html#cb21-7" aria-hidden="true"></a></span>
<span id="cb21-8"><a href="tópicos-em-estatística-computacional.html#cb21-8" aria-hidden="true"></a>  <span class="kw">insideplot</span>(x, y)</span>
<span id="cb21-9"><a href="tópicos-em-estatística-computacional.html#cb21-9" aria-hidden="true"></a></span>
<span id="cb21-10"><a href="tópicos-em-estatística-computacional.html#cb21-10" aria-hidden="true"></a>  <span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">mapply</span>(<span class="dt">FUN =</span> inside, x, y)) <span class="op">/</span><span class="st"> </span>N</span>
<span id="cb21-11"><a href="tópicos-em-estatística-computacional.html#cb21-11" aria-hidden="true"></a></span>
<span id="cb21-12"><a href="tópicos-em-estatística-computacional.html#cb21-12" aria-hidden="true"></a>  <span class="co"># ou sum(purrr::map2_lgl(.x = x, .y = y, .f = inside)) / N</span></span>
<span id="cb21-13"><a href="tópicos-em-estatística-computacional.html#cb21-13" aria-hidden="true"></a>}</span>
<span id="cb21-14"><a href="tópicos-em-estatística-computacional.html#cb21-14" aria-hidden="true"></a><span class="co"># Fixando uma semente:</span></span>
<span id="cb21-15"><a href="tópicos-em-estatística-computacional.html#cb21-15" aria-hidden="true"></a><span class="kw">set.seed</span>(1L)</span>
<span id="cb21-16"><a href="tópicos-em-estatística-computacional.html#cb21-16" aria-hidden="true"></a><span class="co"># Aproximando o valor de pi (mil réplicas):</span></span>
<span id="cb21-17"><a href="tópicos-em-estatística-computacional.html#cb21-17" aria-hidden="true"></a><span class="kw">mcpi</span>()</span></code></pre></div>
<p><img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-37-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 3.148</code></pre>
</div>
<div id="paralelizando-um-procedimento-de-monte-carlo" class="section level3" number="6.4.5">
<h3><span class="header-section-number">6.4.5</span> Paralelizando um procedimento de Monte Carlo</h3>
<p>A classe de procedimentos de MC contemplam metodologias típias que podem ser paralelizadas, isto é, por se tratarem de procedimentos iterativos, cada iteração poderá ser realizada em paralelo. Porém, é importante deixar claro que nem todo o procedimento iterativo poderá ser paralelizado. Essa é uma restrição do ponto de vista matemático e não do ponto de vista de computação. Isso deve-se ao fato de que nem todos procedimentos iterativos são matematicamente independentes, isto é, nesses procedimentos, para realizarmos a iteração <span class="math inline">\(t + 1\)</span> necessariamente devemos esperar pelos cálculos realizados na <span class="math inline">\(t\)</span>-ésima iteração.</p>
<p>Tipicamente, os procedimentos de MC são matematicamente independentes. Embora a construção de tais procedimentos que produzem amostras com as propriedades desejadas geralmente não seja difícil, a tarefa de garantir a convergência a uma taxa compatível com os recursos computacionais atuais continua sendo um grande desafio.</p>
<p>Nos dias atuais, é comum observarmos códigos passíveis de paralização sem fazer o devido aproveitamento de todos os recursos computacionais disponíveis em um dado computador. Em dias atuais, é comum processadores e GPUS (Graphics Processing Unit) com vários núcleos de processamento.</p>
<p>A linguagem R disponibiliza diversas bibliotecas para se trabalhar com computação paralela. Ente alguns pacotes importantes que viablizam o uso de computação paralela em R destaco o <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a> e o <a href="https://cran.r-project.org/web/packages/snow"><strong>snow</strong></a> (“<strong>S</strong>imple <strong>N</strong>etwork of <strong>W</strong>orkstations”). Tempos atrás, havia também o pacote <a href="https://cran.r-project.org/web/packages/multicore"><strong>multicore</strong></a> que foi removido do CRAN, sendo substituído pelo pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a>.</p>
<p>Diversas funções do pacote <strong>parallel</strong> são derivadas do pacote <strong>snow</strong> e do antigo pacote <strong>multicore</strong>. O pacote <strong>parallel</strong> reúne as melhores características desses pacotes, com algumas modificações e características próprias. Além desses pacote, há diversas outas bibliotecas em R disponíveis para implementação de códigos paralelizados. Porém, a maioria dessas bibliotecas utilizam-se do <strong>parallel</strong> e <strong>snow</strong> como backend para suas implementações. Por exemplo, <strong>foreach</strong> + <strong>doParallel</strong> normalmente são utilizados em conjunto para a criação de loops com execução em paralelo, em que utiliza-se das funções <code>foreach()</code> + <code>%dopar%</code> do pacote <strong>foreach</strong>. Nesse exemplo, o pacote <strong>doParallel</strong> atuará como uma interface para o pacote <strong>parallel</strong> que é o verdadeiro responsável para efetuar a paralelização do loop.</p>
<p>Uma das vantagem do pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a> está no fato dele ser distribuído em conjunto com a linguagem R. Mais precisamente, o pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a> foi incluído, pela primeira vez, em 31 de Outubro de 2011, na versão 2.14.0 da linguagem R. Uma outra vantagem do pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a> é que ele necessita de menos configurações iniciais para a utilização dos seus funcionais em um procedimento de paralização <strong>multicore</strong> em um mesmo processador.</p>
<p>A única desvantagem do pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a> diz respeito aos usuários do sistema operacional (SO) Windows, em que alguns de seus funcionais não irão funcionar de forma paralela. Porém, o pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a> dispõe de funcionais alternativos para a realização de computação paralela em Windows. A vantagem de utilizar-se um sistema <strong>*nix</strong> é que os funcionais que funcionam em Windows também funcionarão em sistemas <strong>*nix</strong>.</p>
<p>Aqui trataremos apenas da paralelização <strong>multicore</strong> de memória compartilhada em um único processador, isto é, em um mesmo chip, utilizando a linguagem R. Para os exemplos, utilizaremos os típicos procedimentos de MC que são passíveis de execução em paralelo.</p>
<p>Processadores com múltiplos núcleos são muito comuns nos dias atuais. Também é comum estamos implementando nossas simulações em computadores pessoais que normalmente possue apenas um único processador com vários núcleos de processamento. A ideia é discutir como aproveitarmos todo o recurso computacional desses processadores e assim usufruirmos de um código com maior performance, uma vez que temos esses recursos a nossa disposição. Abaixo encontra-se uma representação típica de um processador com vários núcleos de processamento, mais precisamente, 4 (cores) destacados em azul e 8 (oito) threads destacados em vermelho.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-38"></span>
<img src="images/processador_threads.png" alt="Representação de um processador **multicore** (múltiplos núcleos), em que os retângulos vermelhos representam os pseudo-cores (hardware threads) e a parte cinza onde encontra-se o processador chamamos de soquete." width="50%" />
<p class="caption">
Figura 6.11: Representação de um processador <strong>multicore</strong> (múltiplos núcleos), em que os retângulos vermelhos representam os pseudo-cores (hardware threads) e a parte cinza onde encontra-se o processador chamamos de soquete.
</p>
</div>
<p>Abaixo encontram-se listados alguns conceitos comumente utilizados em computação paralela. Entender essas nomenclaturas ajudará bastante a compreensão de textos em computação paralela.</p>
<ul>
<li><p><strong>Nó</strong>: um único computador que consiste basicamente de uma placa-mãe com uma memória e um processador;</p></li>
<li><p><strong>Processador</strong>/<strong>soquete</strong>: a unidade física que contém um ou mais núcleos que fazem cálculos;</p></li>
<li><p><strong>Core</strong>/<strong>núcleo</strong>: a menor unidade de computação do processador. Cada core é capaz de executar um único programa/tarefa;</p></li>
<li><p><strong>Thread</strong> (hardware): também conhecido como core lógico, as threads, do ponto de vista de hardware, são unidades de computação dentro dos cores que poderá permitir que um core faça duas ou mais tarefas ao mesmo tempo.</p></li>
<li><p><strong>Trabalhador</strong>/<strong>worker</strong>: um processo independente que conduz o cálculo e fornece os resultados para o processo <strong>mestre</strong>/<strong>master</strong>. Alguns texto referem-se aos trabalhadores como threads (software), em que <strong>thread mestre</strong>/<strong>thread master</strong> é o processo mestre e as bifurcações geridas por esse processo principal em outros processos são chamados de <strong>threads escravas</strong>/<strong>slave threads</strong>.</p></li>
</ul>
<p><strong>Importante</strong>:</p>

<div class="rmdimportant">
<div class="text-justify">
<p>Com o pacote <strong>parallel</strong> é possível também fazer uso de computação paralela utilizando <a href="https://pt.wikipedia.org/wiki/Message_Passing_Interface"><strong>Message Passing Interface - MPI</strong></a> (um padrão de dados em computação paralela), quando temos a nossa disposição um cluster configurado com várias máquina (vários nós), cada um com vários processadores com múltiplos núcleos de processamento.</p>
<p><strong>Também é importante deixar destacar que nem sempre os custos que o computador tem em gerir diversos processos justifica a paralelização de um código. Por exemplo, é possível que um código funcione de forma mais eficiente quando executado de forma serial quando comparado ao seu análogo paralelo.</strong></p>
</div>
</div>
</div>
<div id="speedup" class="section level3" number="6.4.6">
<h3><span class="header-section-number">6.4.6</span> Speedup</h3>
<p>Uma forma de mensurar o ganho ou perda computacional ao executar um código em paralelo é utilizando a medida <strong>speedup</strong> que é definido como a relação de tempo gasto para executar uma terefa de forma serial com o tempo gasta para executar a mesma tarefa em <span class="math inline">\(n\)</span> threads. Ou seja, se <span class="math inline">\(S\)</span> é o <strong>speedup</strong>, então</p>
<p><span class="math display">\[S(n) = \frac{T(1)}{T(n)},\]</span>
em que <span class="math inline">\(T(1)\)</span> é o tempo serial e <span class="math inline">\(T(n)\)</span> é o tempo em paralelo ao considerar <span class="math inline">\(N\)</span> cores, em um processador que suporta essa quantidade de núcleos. Assim, quanto maior o <strong>speedup</strong>, maior será o ganho computacional ao se paralelizar um código.</p>
<p><strong>Lei de Amdahl</strong></p>
<p>Se o tempo de processamento de uma tarefa pode ser escalonado linearmente com o número de núcleos utilizados em paralelo, dizemos que o código em paralelo produz uma aceleração linear, sendo este o melhor dos cenários. Porém, na maioria dos problemas em que desejamos paralelizar, o tempo de computação atinge uma “parede assintótica”, em que os benefícios de utilizar núcleos adicionais são compensados pelos custos adicionais de gerenciar o fluxo de informações entre tantos trabalhadores. Essa função assintótica <strong>poderá</strong> seguir a <strong>Lei de Amdahl</strong>, definida por <a href="https://en.wikipedia.org/wiki/Gene_Amdahl"><strong>Gene Myron Amdahl</strong></a>, em uma conferência, em 1967. A lei diz que:</p>
<p><span class="math display">\[T(n) = T(1)\Big[s + \frac{1}{n}(1 - s)\Big],\]</span>
em que <span class="math inline">\(T(n)\)</span> é o tempo que um algoritmo leva para ser executado de forma paralela utilizando <span class="math inline">\(n\)</span> núcleos e <span class="math inline">\(s\)</span> é a proporção do código que deve ser executado de forma serial, sendo <span class="math inline">\(1 - s\)</span> a proporção de código executado de forma paralela.</p>
<p>Sendo assim, dado <span class="math inline">\(s\)</span>, o <strong>speedup</strong> teórico é dado por:</p>
<p><span class="math display">\[S(n) = \frac{T(1)}{T(n)} = \frac{T(1)}{T(1)\Big[s + \frac{1}{n}(1 - s)\Big]} = \frac{1}{s + \frac{1}{n}(1-s)}.\]</span>
Perceba que,</p>
<p><span class="math display">\[\lim_{n \to \infty} \frac{1}{s + \frac{1}{n}(1-s)} = \frac{1}{s},\]</span>
é o <strong>speedup</strong> máximo alcançado, segundo essa lei.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-40"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-40-1.png" alt="Speedup estimado utilizando a Lei de Amdhal levando em consideração a quantidade de núcleos disponiveis e a proporção de código passível de paralelização de um algoritmo." width="672" />
<p class="caption">
Figura 6.12: Speedup estimado utilizando a Lei de Amdhal levando em consideração a quantidade de núcleos disponiveis e a proporção de código passível de paralelização de um algoritmo.
</p>
</div>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Existem diversas métricas para entender o comportamento de um aplicação paralela em face ao número de núcleos utilizados, em que todas elas tem suas limitações. A principal limitação da Lei de Amdahl é o fato dela ingnorar ao gerenciar-se diversos processos.</p>
<p>O que é mais importante para os nossos objetivos é a conciência da existência de uma barreira assintótica para o <strong>speedup</strong>. Na prática, essa barreira torna-se-á bastante frequênte devido aos custos computacionais relacionados ao transporte de dados entre os processos que será muito provavelmente diminuído com o passar dos anos.</p>
</div>
</div>
</div>
<div id="pacote-parallel" class="section level3" number="6.4.7">
<h3><span class="header-section-number">6.4.7</span> Pacote parallel</h3>
<p>O pacote <strong>parallel</strong> possui diversas funções úteis. Você poderá encontrar um tutorial do <strong>parallel</strong> clicando <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>aqui</strong></a>. O pacote <strong>parallel</strong> possui diversas funções úteis, em que um vetor completo com o nome das funções pode ser obtido fazendo:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="tópicos-em-estatística-computacional.html#cb23-1" aria-hidden="true"></a><span class="kw">library</span>(parallel)</span>
<span id="cb23-2"><a href="tópicos-em-estatística-computacional.html#cb23-2" aria-hidden="true"></a><span class="kw">ls</span>(<span class="st">&quot;package:parallel&quot;</span>)</span></code></pre></div>
<pre><code>##  [1] &quot;clusterApply&quot;        &quot;clusterApplyLB&quot;      &quot;clusterCall&quot;        
##  [4] &quot;clusterEvalQ&quot;        &quot;clusterExport&quot;       &quot;clusterMap&quot;         
##  [7] &quot;clusterSetRNGStream&quot; &quot;clusterSplit&quot;        &quot;detectCores&quot;        
## [10] &quot;getDefaultCluster&quot;   &quot;makeCluster&quot;         &quot;makeForkCluster&quot;    
## [13] &quot;makePSOCKcluster&quot;    &quot;mc.reset.stream&quot;     &quot;mcaffinity&quot;         
## [16] &quot;mccollect&quot;           &quot;mclapply&quot;            &quot;mcMap&quot;              
## [19] &quot;mcmapply&quot;            &quot;mcparallel&quot;          &quot;nextRNGStream&quot;      
## [22] &quot;nextRNGSubStream&quot;    &quot;parApply&quot;            &quot;parCapply&quot;          
## [25] &quot;parLapply&quot;           &quot;parLapplyLB&quot;         &quot;parRapply&quot;          
## [28] &quot;parSapply&quot;           &quot;parSapplyLB&quot;         &quot;pvec&quot;               
## [31] &quot;setDefaultCluster&quot;   &quot;splitIndices&quot;        &quot;stopCluster&quot;</code></pre>
<p>As funções que serão destacadas aqui e que nos ajudaram a paralelizar um procedimento de MC são as funções <code>mclapply()</code>, <code>mcmapply()</code>, <code>mcMap()</code> e <code>detectCores()</code>. Perceba que algumas funções iniciam-se com <strong>mc</strong>, o que faz alusão à expressão <strong>multicore</strong> (múltiplos núcleos). Dessa forma, <code>mclapply()</code> equivale ao funcional <code>lapply()</code>, porém trabalhando de forma paralela, <code>mcmapply()</code> é análogo paralelo do funcional <code>mapply()</code> e <code>mcMap()</code> é o analogo paralelo do funcional <code>Map()</code>.</p>
<p>As funções <code>mclapply()</code> e <code>mcmapply()</code> trabalham de forma <strong>multicore</strong>, ou seja, sobre um único processador com vários núcleos físicos e lógicos. Isso é feito utilizando o conceito de <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a>, sendo este um conceito de sistemas operacionais <a href="https://pt.wikipedia.org/wiki/POSIX"><strong>POSIX</strong></a> que está disponível em todas as plataformas R, exceto em Windows. O sistema <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a> cria um novo processo de R tomando uma cópia completa do processo mestre, incluindo o espaço de trabalho e o estado de fluxo de números aleatórios. Porém, em um SO razoável, as cópias compartilham páginas de memória com o processo mestre até o momento em que o que é comum entre entre os processos seja modificado, permitindo assim que este procedimento de <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a> seja eficiente.</p>
<p><strong>Exemplo</strong>: Comparando a execução serial e paralela da função <code>intvarmc()</code>. Como é possível observar, optou-se em paralelizar a função <code>intmc()</code> que é utilizado pela função <code>intvarmc()</code> para o cálculo das integrais aproximadas por um procedimento de MC. É possível observar que paralelizar a execução da função <code>intvarmc()</code> contribuiu significativamente na melhoria da peformance da função <code>intvarmc()</code>. Observe as saídas dos tempos de execução das funções <code>intvarmc()</code> (função com execução serial) e <code>intvarmc_parallel()</code> (cópia paralelizada da função <code>intvarmc()</code>):</p>
<p><strong>Código Serial</strong>:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="tópicos-em-estatística-computacional.html#cb25-1" aria-hidden="true"></a><span class="co"># Código Serial -----------------------------------------------------------</span></span>
<span id="cb25-2"><a href="tópicos-em-estatística-computacional.html#cb25-2" aria-hidden="true"></a>intvarmc &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, fun, <span class="dt">lower =</span> <span class="ot">NULL</span>, <span class="dt">upper =</span> <span class="ot">NULL</span>, ...){</span>
<span id="cb25-3"><a href="tópicos-em-estatística-computacional.html#cb25-3" aria-hidden="true"></a></span>
<span id="cb25-4"><a href="tópicos-em-estatística-computacional.html#cb25-4" aria-hidden="true"></a>  intmc_map &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...) <span class="kw">intmc</span>(N, fun, lower, upper, ...)</span>
<span id="cb25-5"><a href="tópicos-em-estatística-computacional.html#cb25-5" aria-hidden="true"></a></span>
<span id="cb25-6"><a href="tópicos-em-estatística-computacional.html#cb25-6" aria-hidden="true"></a>  i_hat &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map_dbl</span>(<span class="dt">.x =</span> <span class="dv">1</span><span class="op">:</span>N, <span class="dt">.f =</span> intmc_map, ...)</span>
<span id="cb25-7"><a href="tópicos-em-estatística-computacional.html#cb25-7" aria-hidden="true"></a></span>
<span id="cb25-8"><a href="tópicos-em-estatística-computacional.html#cb25-8" aria-hidden="true"></a>  var_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(i_hat <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(i_hat) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb25-9"><a href="tópicos-em-estatística-computacional.html#cb25-9" aria-hidden="true"></a></span>
<span id="cb25-10"><a href="tópicos-em-estatística-computacional.html#cb25-10" aria-hidden="true"></a>  <span class="kw">list</span>(<span class="dt">i_hat =</span> <span class="kw">mean</span>(i_hat), <span class="dt">var_hat =</span> var_hat, <span class="dt">vec_ihat =</span> i_hat)</span>
<span id="cb25-11"><a href="tópicos-em-estatística-computacional.html#cb25-11" aria-hidden="true"></a>}</span>
<span id="cb25-12"><a href="tópicos-em-estatística-computacional.html#cb25-12" aria-hidden="true"></a></span>
<span id="cb25-13"><a href="tópicos-em-estatística-computacional.html#cb25-13" aria-hidden="true"></a><span class="kw">set.seed</span>(0L)</span>
<span id="cb25-14"><a href="tópicos-em-estatística-computacional.html#cb25-14" aria-hidden="true"></a>time_serial &lt;-<span class="st"> </span><span class="kw">system.time</span>(result_serial &lt;-</span>
<span id="cb25-15"><a href="tópicos-em-estatística-computacional.html#cb25-15" aria-hidden="true"></a><span class="st">                             </span><span class="kw">intvarmc</span>(<span class="dt">N =</span> <span class="fl">5e3</span>L, <span class="dt">fun =</span> fdp_weibull,</span>
<span id="cb25-16"><a href="tópicos-em-estatística-computacional.html#cb25-16" aria-hidden="true"></a>                                      <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">10</span>,</span>
<span id="cb25-17"><a href="tópicos-em-estatística-computacional.html#cb25-17" aria-hidden="true"></a>                                      <span class="dt">alpha =</span> <span class="fl">1.5</span>, <span class="dt">beta =</span> <span class="fl">1.5</span>))</span>
<span id="cb25-18"><a href="tópicos-em-estatística-computacional.html#cb25-18" aria-hidden="true"></a>result_serial<span class="op">$</span>i_hat</span></code></pre></div>
<pre><code>## [1] 1.000779</code></pre>
<p><strong>Código Paralelizado</strong>:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="tópicos-em-estatística-computacional.html#cb27-1" aria-hidden="true"></a><span class="co"># Código Paralelizado -----------------------------------------------------</span></span>
<span id="cb27-2"><a href="tópicos-em-estatística-computacional.html#cb27-2" aria-hidden="true"></a>intvarmc_parallel &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, fun, <span class="dt">lower =</span> <span class="ot">NULL</span>, <span class="dt">upper =</span> <span class="ot">NULL</span>, ...){</span>
<span id="cb27-3"><a href="tópicos-em-estatística-computacional.html#cb27-3" aria-hidden="true"></a></span>
<span id="cb27-4"><a href="tópicos-em-estatística-computacional.html#cb27-4" aria-hidden="true"></a>  intmc_map &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...) <span class="kw">intmc</span>(N, fun, lower, upper, ...)</span>
<span id="cb27-5"><a href="tópicos-em-estatística-computacional.html#cb27-5" aria-hidden="true"></a></span>
<span id="cb27-6"><a href="tópicos-em-estatística-computacional.html#cb27-6" aria-hidden="true"></a>  <span class="co"># Reescrita da função intmc() para que seja possível utilizar</span></span>
<span id="cb27-7"><a href="tópicos-em-estatística-computacional.html#cb27-7" aria-hidden="true"></a>  <span class="co"># em um funcional baseado no funcional lapply().</span></span>
<span id="cb27-8"><a href="tópicos-em-estatística-computacional.html#cb27-8" aria-hidden="true"></a>  i_hat &lt;-<span class="st"> </span><span class="kw">unlist</span>(parallel<span class="op">::</span><span class="kw">mclapply</span>(<span class="dt">X =</span> 1L<span class="op">:</span>N, <span class="dt">FUN =</span> intmc_map, ...,</span>
<span id="cb27-9"><a href="tópicos-em-estatística-computacional.html#cb27-9" aria-hidden="true"></a>                                     <span class="dt">mc.cores =</span>  parallel<span class="op">::</span><span class="kw">detectCores</span>()))</span>
<span id="cb27-10"><a href="tópicos-em-estatística-computacional.html#cb27-10" aria-hidden="true"></a></span>
<span id="cb27-11"><a href="tópicos-em-estatística-computacional.html#cb27-11" aria-hidden="true"></a>  var_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(i_hat <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(i_hat) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb27-12"><a href="tópicos-em-estatística-computacional.html#cb27-12" aria-hidden="true"></a></span>
<span id="cb27-13"><a href="tópicos-em-estatística-computacional.html#cb27-13" aria-hidden="true"></a>  <span class="kw">list</span>(<span class="dt">i_hat =</span> <span class="kw">mean</span>(i_hat), <span class="dt">var_hat =</span> var_hat, <span class="dt">vec_ihat =</span> i_hat)</span>
<span id="cb27-14"><a href="tópicos-em-estatística-computacional.html#cb27-14" aria-hidden="true"></a>}</span>
<span id="cb27-15"><a href="tópicos-em-estatística-computacional.html#cb27-15" aria-hidden="true"></a></span>
<span id="cb27-16"><a href="tópicos-em-estatística-computacional.html#cb27-16" aria-hidden="true"></a><span class="kw">set.seed</span>(0L)</span>
<span id="cb27-17"><a href="tópicos-em-estatística-computacional.html#cb27-17" aria-hidden="true"></a><span class="kw">system.time</span>(result_parallel &lt;-<span class="st"> </span><span class="kw">intvarmc_parallel</span>(<span class="dt">N =</span> <span class="fl">5e3</span>L, <span class="dt">fun =</span> fdp_weibull,</span>
<span id="cb27-18"><a href="tópicos-em-estatística-computacional.html#cb27-18" aria-hidden="true"></a>                                                 <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">10</span>,</span>
<span id="cb27-19"><a href="tópicos-em-estatística-computacional.html#cb27-19" aria-hidden="true"></a>                                                 <span class="dt">alpha =</span> <span class="fl">1.5</span>, <span class="dt">beta =</span> <span class="fl">1.5</span>))</span></code></pre></div>
<pre><code>##   usuário   sistema decorrido 
##     2.992     0.421     0.881</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="tópicos-em-estatística-computacional.html#cb29-1" aria-hidden="true"></a>result_parallel<span class="op">$</span>i_hat</span></code></pre></div>
<pre><code>## [1] 1.00001</code></pre>
<p><strong>Importante</strong>:</p>

<div class="rmdimportant">
<div class="text-justify">
<p>O código paralelizado no exemplo anterior irá verdadeiramente funcionar de forma paralela em sistemas *<strong>nix</strong> e não trabalhará corretamente em Windows. Isso se deve ao fato de muitas funções do pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a> serem derivadas do pacote <strong>multicore</strong> e utilizarem <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a>, uma chamada de sistema <a href="https://pt.wikipedia.org/wiki/POSIX"><strong>POSIX</strong></a> não compatível com o SO Windows. Essas funções, em que <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a> é apenas uma delas, constroem uma interface entre um processo e o SO.</p>
<p>Em Windows, uma abordagem paralelizada também poderá ser implementada utilizando o pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a>, a custo de <strong>um pouco mais</strong> de passos, já que não há suporte à <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a>. Como função <code>mclapply()</code> e funções derivadas fazem uso de <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a>, deveremos considerar funções que não fazem uso de <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a>.</p>
</div>
</div>
<p><strong>Exemplo</strong>: Implementação da função <code>intvarmc_parallel()</code> para que funcione de forma paralelizada em Windows. Perceba que foi necessário incluir mais passos e substituir a função <code>mclapply()</code> pela função <code>parLapply()</code> que também está disponível no pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a>.</p>
<p>Assim como o <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a>, o <strong>PSOCK</strong> é também uma chamada de sistema <a href="https://pt.wikipedia.org/wiki/POSIX"><strong>POSIX</strong></a> que define uma nova forma de transporte de dados e comunicação entre as threads e o processo mestre. O <strong>PSOCK</strong> faz algumas execuções do comando <code>Rscript</code>, conforme a quantidade de núcleos utilizados para realizar um trabalho. Nesse sistema, a comunicação das threads com o processo mestre se dá utilizando conecções de soquete. Sendo assim, quando deseja-se fazer uso de paralelismo <strong>multicore</strong>, em Windows, há a necessidade da criação de um cluster do tipo <strong>PSOCK</strong>.</p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>É sempre uma boa prática desligar as theads chamando a função <code>stopCluster()</code> ao final da execução da função em paralelo, muito embora em alguns tipos de clusters o encerramento é automático. Caso contrário, poderemos correr o risco de transbordar threads, por exemplo, se o tipo de cluster for alterado, o que poderá gerar diversos conflitos e inconsistências.</p>
</div>
</div>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="tópicos-em-estatística-computacional.html#cb31-1" aria-hidden="true"></a><span class="co"># No Windows --------------------------------------------------------------</span></span>
<span id="cb31-2"><a href="tópicos-em-estatística-computacional.html#cb31-2" aria-hidden="true"></a><span class="co"># Atribuindo a quantidade de núcleos disponíveis.</span></span>
<span id="cb31-3"><a href="tópicos-em-estatística-computacional.html#cb31-3" aria-hidden="true"></a>cores &lt;-<span class="st"> </span><span class="kw">getOption</span>(<span class="st">&quot;mc.cores&quot;</span>, parallel<span class="op">::</span><span class="kw">detectCores</span>())</span>
<span id="cb31-4"><a href="tópicos-em-estatística-computacional.html#cb31-4" aria-hidden="true"></a></span>
<span id="cb31-5"><a href="tópicos-em-estatística-computacional.html#cb31-5" aria-hidden="true"></a><span class="co"># Criando um cluster do tipo PSOCK.</span></span>
<span id="cb31-6"><a href="tópicos-em-estatística-computacional.html#cb31-6" aria-hidden="true"></a>cl &lt;-<span class="st"> </span><span class="kw">makeCluster</span>(cores, <span class="dt">type =</span> <span class="st">&quot;PSOCK&quot;</span>)</span>
<span id="cb31-7"><a href="tópicos-em-estatística-computacional.html#cb31-7" aria-hidden="true"></a></span>
<span id="cb31-8"><a href="tópicos-em-estatística-computacional.html#cb31-8" aria-hidden="true"></a><span class="co"># Exportando as funções intmc() e fdp_weibull() para que sejam reconhecidas</span></span>
<span id="cb31-9"><a href="tópicos-em-estatística-computacional.html#cb31-9" aria-hidden="true"></a><span class="co"># em cada núcleo.</span></span>
<span id="cb31-10"><a href="tópicos-em-estatística-computacional.html#cb31-10" aria-hidden="true"></a><span class="kw">clusterExport</span>(<span class="dt">cl =</span> cl, <span class="dt">varlist =</span> <span class="kw">c</span>(<span class="st">&quot;intmc&quot;</span>, <span class="st">&quot;fdp_weibull&quot;</span>), <span class="dt">envir =</span> <span class="kw">environment</span>())</span>
<span id="cb31-11"><a href="tópicos-em-estatística-computacional.html#cb31-11" aria-hidden="true"></a></span>
<span id="cb31-12"><a href="tópicos-em-estatística-computacional.html#cb31-12" aria-hidden="true"></a>intvarmc_parallel &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, fun, <span class="dt">lower =</span> <span class="ot">NULL</span>, <span class="dt">upper =</span> <span class="ot">NULL</span>, ...){</span>
<span id="cb31-13"><a href="tópicos-em-estatística-computacional.html#cb31-13" aria-hidden="true"></a></span>
<span id="cb31-14"><a href="tópicos-em-estatística-computacional.html#cb31-14" aria-hidden="true"></a>  <span class="co"># Reescrita da função intmc() para que seja possível utilizar</span></span>
<span id="cb31-15"><a href="tópicos-em-estatística-computacional.html#cb31-15" aria-hidden="true"></a>  <span class="co"># em um funcional baseado no funcional lapply().</span></span>
<span id="cb31-16"><a href="tópicos-em-estatística-computacional.html#cb31-16" aria-hidden="true"></a>  intmc_map &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...) <span class="kw">intmc</span>(N, fun, lower, upper, ...)</span>
<span id="cb31-17"><a href="tópicos-em-estatística-computacional.html#cb31-17" aria-hidden="true"></a></span>
<span id="cb31-18"><a href="tópicos-em-estatística-computacional.html#cb31-18" aria-hidden="true"></a>  i_hat &lt;-<span class="st"> </span><span class="kw">unlist</span>(parallel<span class="op">::</span><span class="kw">parLapply</span>(<span class="dt">cl =</span> cl, <span class="dt">X =</span> 1L<span class="op">:</span>N, <span class="dt">fun =</span> intmc_map, ...))</span>
<span id="cb31-19"><a href="tópicos-em-estatística-computacional.html#cb31-19" aria-hidden="true"></a></span>
<span id="cb31-20"><a href="tópicos-em-estatística-computacional.html#cb31-20" aria-hidden="true"></a>  var_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(i_hat <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(i_hat) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb31-21"><a href="tópicos-em-estatística-computacional.html#cb31-21" aria-hidden="true"></a></span>
<span id="cb31-22"><a href="tópicos-em-estatística-computacional.html#cb31-22" aria-hidden="true"></a>  <span class="kw">list</span>(<span class="dt">i_hat =</span> <span class="kw">mean</span>(i_hat), <span class="dt">var_hat =</span> var_hat, <span class="dt">vec_ihat =</span> i_hat)</span>
<span id="cb31-23"><a href="tópicos-em-estatística-computacional.html#cb31-23" aria-hidden="true"></a>}</span>
<span id="cb31-24"><a href="tópicos-em-estatística-computacional.html#cb31-24" aria-hidden="true"></a></span>
<span id="cb31-25"><a href="tópicos-em-estatística-computacional.html#cb31-25" aria-hidden="true"></a><span class="kw">set.seed</span>(0L)</span>
<span id="cb31-26"><a href="tópicos-em-estatística-computacional.html#cb31-26" aria-hidden="true"></a><span class="kw">system.time</span>(result_parallel &lt;-<span class="st"> </span><span class="kw">intvarmc_parallel</span>(<span class="dt">N =</span> <span class="fl">5e3</span>L, <span class="dt">fun =</span> fdp_weibull,</span>
<span id="cb31-27"><a href="tópicos-em-estatística-computacional.html#cb31-27" aria-hidden="true"></a>                                                 <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">10</span>,</span>
<span id="cb31-28"><a href="tópicos-em-estatística-computacional.html#cb31-28" aria-hidden="true"></a>                                                 <span class="dt">alpha =</span> <span class="fl">1.5</span>, <span class="dt">beta =</span> <span class="fl">1.5</span>))</span>
<span id="cb31-29"><a href="tópicos-em-estatística-computacional.html#cb31-29" aria-hidden="true"></a><span class="kw">stopCluster</span>(cl)</span>
<span id="cb31-30"><a href="tópicos-em-estatística-computacional.html#cb31-30" aria-hidden="true"></a>result_parallel<span class="op">$</span>i_hat</span></code></pre></div>
<p>Tanto no exemplo de paralização em SO <strong>*nix</strong> utilizando <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a> quanto em Windows utilizando um cluster <strong>PSOCK</strong>, a função <code>intvarmc_parallel()</code> mostrou-se mais eficiente do sua implementação serial. Porém, nos deparamos com o problema de reprodutibilidade. Perceba que fazer <code>set.seed(0L)</code> antes da execução da função <code>intvarmc_parallel()</code> não é suficiente para garantir os mesmos resultados. Como é de responsabilidade do SO distribuir os processos entre as threads (hardware) disponíveis e o gerador de números pseudo-aleatórios toma estados distintos a depender da thread (hardware) ao qual um trabalhador foi alocado, sequências distintas muito provavelmente serão observadas entre execuções de uma função paralelizada.</p>
<p>O pacote <a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"><strong>parallel</strong></a> contém uma implementação das ideias de L’Ecuyer et al. (2002), cujo o artigo é livre e poderá ser acessado com o link abaixo:</p>
<blockquote>
<p>L’Ecuyer P, Simard R, Chen EJ, Kelton WD (2002). <strong>An object-oriented random-number package with many long streams and substreams</strong>. <em>Operations Research</em>, 50, 1073–5. URL <a href="http://www.iro.umontreal.ca/~lecuyer/myftp/papers/streams00.pdf"><strong>link</strong></a>.</p>
</blockquote>
<p>Assim, em R, é possível fazer uso desse gerador que recebe o nome <strong>L’Ecuyer-CMRG</strong>. Isso poderá ser feito passando a string <code>"L'Ecuyer-CMRG"</code>, alem da semente, para o agumento <code>kind</code> da função <code>set.seed()</code> ou alterando o gerador utilizando a função <code>"RNGkind()"</code> e posteriormente utilizando a função <code>set.seed()</code> para fixar uma semente. As duas formas estão apresentadas abaixo:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="tópicos-em-estatística-computacional.html#cb32-1" aria-hidden="true"></a><span class="co"># Forma 1:</span></span>
<span id="cb32-2"><a href="tópicos-em-estatística-computacional.html#cb32-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dt">seed =</span> 0L, <span class="dt">kind =</span> <span class="st">&quot;L&#39;Ecuyer-CMRG&quot;</span>)</span>
<span id="cb32-3"><a href="tópicos-em-estatística-computacional.html#cb32-3" aria-hidden="true"></a></span>
<span id="cb32-4"><a href="tópicos-em-estatística-computacional.html#cb32-4" aria-hidden="true"></a><span class="co"># Forma 2:</span></span>
<span id="cb32-5"><a href="tópicos-em-estatística-computacional.html#cb32-5" aria-hidden="true"></a><span class="kw">RNGkind</span>(<span class="dt">kind =</span> <span class="st">&quot;L&#39;Ecuyer-CMRG&quot;</span>)</span>
<span id="cb32-6"><a href="tópicos-em-estatística-computacional.html#cb32-6" aria-hidden="true"></a><span class="kw">set.seed</span>(0L)</span></code></pre></div>
<p><strong>Exemplo</strong>: Reproduções da função <code>intvarmc_parallel()</code> usando os sistemas <a href="https://en.wikipedia.org/wiki/Fork_(system_call)"><strong>FORK</strong></a> e <strong>PSOCK</strong>, repectivamente. Trata-se de um exemplo que poderá ser reproduzível, uma vez que foi utilizado o gerador <strong>L’Ecuyer-CMRG</strong> com semente fixa.</p>
<p><strong>Paralelização usando FORK</strong>:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="tópicos-em-estatística-computacional.html#cb33-1" aria-hidden="true"></a><span class="co"># Código Paralelizado -----------------------------------------------------</span></span>
<span id="cb33-2"><a href="tópicos-em-estatística-computacional.html#cb33-2" aria-hidden="true"></a>intvarmc_parallel &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, fun, <span class="dt">lower =</span> <span class="ot">NULL</span>, <span class="dt">upper =</span> <span class="ot">NULL</span>, ...){</span>
<span id="cb33-3"><a href="tópicos-em-estatística-computacional.html#cb33-3" aria-hidden="true"></a></span>
<span id="cb33-4"><a href="tópicos-em-estatística-computacional.html#cb33-4" aria-hidden="true"></a>  intmc_map &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...) <span class="kw">intmc</span>(N, fun, lower, upper, ...)</span>
<span id="cb33-5"><a href="tópicos-em-estatística-computacional.html#cb33-5" aria-hidden="true"></a></span>
<span id="cb33-6"><a href="tópicos-em-estatística-computacional.html#cb33-6" aria-hidden="true"></a>  <span class="co"># Reescrita da função intmc() para que seja possível utilizar</span></span>
<span id="cb33-7"><a href="tópicos-em-estatística-computacional.html#cb33-7" aria-hidden="true"></a>  <span class="co"># em um funcional baseado no funcional lapply().</span></span>
<span id="cb33-8"><a href="tópicos-em-estatística-computacional.html#cb33-8" aria-hidden="true"></a>  i_hat &lt;-<span class="st"> </span><span class="kw">unlist</span>(parallel<span class="op">::</span><span class="kw">mclapply</span>(<span class="dt">X =</span> 1L<span class="op">:</span>N, <span class="dt">FUN =</span> intmc_map, ...,</span>
<span id="cb33-9"><a href="tópicos-em-estatística-computacional.html#cb33-9" aria-hidden="true"></a>                                     <span class="dt">mc.cores =</span>  parallel<span class="op">::</span><span class="kw">detectCores</span>()))</span>
<span id="cb33-10"><a href="tópicos-em-estatística-computacional.html#cb33-10" aria-hidden="true"></a></span>
<span id="cb33-11"><a href="tópicos-em-estatística-computacional.html#cb33-11" aria-hidden="true"></a>  var_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(i_hat <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(i_hat) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb33-12"><a href="tópicos-em-estatística-computacional.html#cb33-12" aria-hidden="true"></a></span>
<span id="cb33-13"><a href="tópicos-em-estatística-computacional.html#cb33-13" aria-hidden="true"></a>  <span class="kw">list</span>(<span class="dt">i_hat =</span> <span class="kw">mean</span>(i_hat), <span class="dt">var_hat =</span> var_hat, <span class="dt">vec_ihat =</span> i_hat)</span>
<span id="cb33-14"><a href="tópicos-em-estatística-computacional.html#cb33-14" aria-hidden="true"></a>}</span>
<span id="cb33-15"><a href="tópicos-em-estatística-computacional.html#cb33-15" aria-hidden="true"></a></span>
<span id="cb33-16"><a href="tópicos-em-estatística-computacional.html#cb33-16" aria-hidden="true"></a><span class="co"># Fixando uma semente para um gerador que poderá</span></span>
<span id="cb33-17"><a href="tópicos-em-estatística-computacional.html#cb33-17" aria-hidden="true"></a><span class="co"># trabalhar sobre processos paralelizados.</span></span>
<span id="cb33-18"><a href="tópicos-em-estatística-computacional.html#cb33-18" aria-hidden="true"></a><span class="kw">set.seed</span>(0L, <span class="dt">kin =</span> <span class="st">&quot;L&#39;Ecuyer-CMRG&quot;</span>)</span>
<span id="cb33-19"><a href="tópicos-em-estatística-computacional.html#cb33-19" aria-hidden="true"></a>time_parallel &lt;-<span class="st"> </span><span class="kw">system.time</span>(result_parallel &lt;-</span>
<span id="cb33-20"><a href="tópicos-em-estatística-computacional.html#cb33-20" aria-hidden="true"></a><span class="st">                               </span><span class="kw">intvarmc_parallel</span>(<span class="dt">N =</span> <span class="fl">5e3</span>L, <span class="dt">fun =</span> fdp_weibull,</span>
<span id="cb33-21"><a href="tópicos-em-estatística-computacional.html#cb33-21" aria-hidden="true"></a>                                                 <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">10</span>,</span>
<span id="cb33-22"><a href="tópicos-em-estatística-computacional.html#cb33-22" aria-hidden="true"></a>                                                 <span class="dt">alpha =</span> <span class="fl">1.5</span>, <span class="dt">beta =</span> <span class="fl">1.5</span>))</span>
<span id="cb33-23"><a href="tópicos-em-estatística-computacional.html#cb33-23" aria-hidden="true"></a><span class="co"># Uma aproximação para integral de uma função</span></span>
<span id="cb33-24"><a href="tópicos-em-estatística-computacional.html#cb33-24" aria-hidden="true"></a><span class="co"># utilizando um procedimento de MC:</span></span>
<span id="cb33-25"><a href="tópicos-em-estatística-computacional.html#cb33-25" aria-hidden="true"></a>result_parallel<span class="op">$</span>i_hat</span></code></pre></div>
<pre><code>## [1] 0.9993872</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="tópicos-em-estatística-computacional.html#cb35-1" aria-hidden="true"></a><span class="co"># Tempo em serial:</span></span>
<span id="cb35-2"><a href="tópicos-em-estatística-computacional.html#cb35-2" aria-hidden="true"></a>time_serial[<span class="dv">3</span>]</span></code></pre></div>
<pre><code>## elapsed 
##   2.298</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="tópicos-em-estatística-computacional.html#cb37-1" aria-hidden="true"></a><span class="co"># Tempo em paralelo:</span></span>
<span id="cb37-2"><a href="tópicos-em-estatística-computacional.html#cb37-2" aria-hidden="true"></a>time_parallel[<span class="dv">3</span>]</span></code></pre></div>
<pre><code>## elapsed 
##    0.99</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="tópicos-em-estatística-computacional.html#cb39-1" aria-hidden="true"></a><span class="co"># Speedup:</span></span>
<span id="cb39-2"><a href="tópicos-em-estatística-computacional.html#cb39-2" aria-hidden="true"></a>time_serial[<span class="dv">3</span>]<span class="op">/</span>time_parallel[<span class="dv">3</span>]</span></code></pre></div>
<pre><code>##  elapsed 
## 2.321212</code></pre>
<p><strong>Paralelização usando PSOCK</strong>:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="tópicos-em-estatística-computacional.html#cb41-1" aria-hidden="true"></a><span class="co"># No Windows --------------------------------------------------------------</span></span>
<span id="cb41-2"><a href="tópicos-em-estatística-computacional.html#cb41-2" aria-hidden="true"></a><span class="co"># Atribuindo a quantidade de núcleos disponíveis.</span></span>
<span id="cb41-3"><a href="tópicos-em-estatística-computacional.html#cb41-3" aria-hidden="true"></a>cores &lt;-<span class="st"> </span><span class="kw">getOption</span>(<span class="st">&quot;mc.cores&quot;</span>, parallel<span class="op">::</span><span class="kw">detectCores</span>())</span>
<span id="cb41-4"><a href="tópicos-em-estatística-computacional.html#cb41-4" aria-hidden="true"></a></span>
<span id="cb41-5"><a href="tópicos-em-estatística-computacional.html#cb41-5" aria-hidden="true"></a><span class="co"># Criando um cluster do tipo PSOCK.</span></span>
<span id="cb41-6"><a href="tópicos-em-estatística-computacional.html#cb41-6" aria-hidden="true"></a>cl &lt;-<span class="st"> </span><span class="kw">makeCluster</span>(cores, <span class="dt">type =</span> <span class="st">&quot;PSOCK&quot;</span>)</span>
<span id="cb41-7"><a href="tópicos-em-estatística-computacional.html#cb41-7" aria-hidden="true"></a></span>
<span id="cb41-8"><a href="tópicos-em-estatística-computacional.html#cb41-8" aria-hidden="true"></a><span class="co"># Exportando as funções intmc() e fdp_weibull() para que sejam reconhecidas</span></span>
<span id="cb41-9"><a href="tópicos-em-estatística-computacional.html#cb41-9" aria-hidden="true"></a><span class="co"># em cada núcleo.</span></span>
<span id="cb41-10"><a href="tópicos-em-estatística-computacional.html#cb41-10" aria-hidden="true"></a><span class="kw">clusterExport</span>(<span class="dt">cl =</span> cl, <span class="dt">varlist =</span> <span class="kw">c</span>(<span class="st">&quot;intmc&quot;</span>, <span class="st">&quot;fdp_weibull&quot;</span>), <span class="dt">envir =</span> <span class="kw">environment</span>())</span>
<span id="cb41-11"><a href="tópicos-em-estatística-computacional.html#cb41-11" aria-hidden="true"></a></span>
<span id="cb41-12"><a href="tópicos-em-estatística-computacional.html#cb41-12" aria-hidden="true"></a>intvarmc_parallel &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, fun, <span class="dt">lower =</span> <span class="ot">NULL</span>, <span class="dt">upper =</span> <span class="ot">NULL</span>, ...){</span>
<span id="cb41-13"><a href="tópicos-em-estatística-computacional.html#cb41-13" aria-hidden="true"></a></span>
<span id="cb41-14"><a href="tópicos-em-estatística-computacional.html#cb41-14" aria-hidden="true"></a>  <span class="co"># Reescrita da função intmc() para que seja possível utilizar</span></span>
<span id="cb41-15"><a href="tópicos-em-estatística-computacional.html#cb41-15" aria-hidden="true"></a>  <span class="co"># em um funcional baseado no funcional lapply().</span></span>
<span id="cb41-16"><a href="tópicos-em-estatística-computacional.html#cb41-16" aria-hidden="true"></a>  intmc_map &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...) <span class="kw">intmc</span>(N, fun, lower, upper, ...)</span>
<span id="cb41-17"><a href="tópicos-em-estatística-computacional.html#cb41-17" aria-hidden="true"></a></span>
<span id="cb41-18"><a href="tópicos-em-estatística-computacional.html#cb41-18" aria-hidden="true"></a>  i_hat &lt;-<span class="st"> </span><span class="kw">unlist</span>(parallel<span class="op">::</span><span class="kw">parLapply</span>(<span class="dt">cl =</span> cl, <span class="dt">X =</span> 1L<span class="op">:</span>N, <span class="dt">fun =</span> intmc_map, ...))</span>
<span id="cb41-19"><a href="tópicos-em-estatística-computacional.html#cb41-19" aria-hidden="true"></a></span>
<span id="cb41-20"><a href="tópicos-em-estatística-computacional.html#cb41-20" aria-hidden="true"></a>  var_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(i_hat <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(i_hat) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb41-21"><a href="tópicos-em-estatística-computacional.html#cb41-21" aria-hidden="true"></a></span>
<span id="cb41-22"><a href="tópicos-em-estatística-computacional.html#cb41-22" aria-hidden="true"></a>  <span class="kw">list</span>(<span class="dt">i_hat =</span> <span class="kw">mean</span>(i_hat), <span class="dt">var_hat =</span> var_hat, <span class="dt">vec_ihat =</span> i_hat)</span>
<span id="cb41-23"><a href="tópicos-em-estatística-computacional.html#cb41-23" aria-hidden="true"></a>}</span>
<span id="cb41-24"><a href="tópicos-em-estatística-computacional.html#cb41-24" aria-hidden="true"></a></span>
<span id="cb41-25"><a href="tópicos-em-estatística-computacional.html#cb41-25" aria-hidden="true"></a><span class="co"># Fixando uma semente para um gerador que poderá</span></span>
<span id="cb41-26"><a href="tópicos-em-estatística-computacional.html#cb41-26" aria-hidden="true"></a><span class="co"># trabalhar sobre processos paralelizados.</span></span>
<span id="cb41-27"><a href="tópicos-em-estatística-computacional.html#cb41-27" aria-hidden="true"></a><span class="kw">set.seed</span>(0L, <span class="dt">kin =</span> <span class="st">&quot;L&#39;Ecuyer-CMRG&quot;</span>)</span>
<span id="cb41-28"><a href="tópicos-em-estatística-computacional.html#cb41-28" aria-hidden="true"></a><span class="kw">system.time</span>(result_parallel &lt;-<span class="st"> </span><span class="kw">intvarmc_parallel</span>(<span class="dt">N =</span> <span class="fl">5e3</span>L, <span class="dt">fun =</span> fdp_weibull,</span>
<span id="cb41-29"><a href="tópicos-em-estatística-computacional.html#cb41-29" aria-hidden="true"></a>                                                 <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">10</span>,</span>
<span id="cb41-30"><a href="tópicos-em-estatística-computacional.html#cb41-30" aria-hidden="true"></a>                                                 <span class="dt">alpha =</span> <span class="fl">1.5</span>, <span class="dt">beta =</span> <span class="fl">1.5</span>))</span>
<span id="cb41-31"><a href="tópicos-em-estatística-computacional.html#cb41-31" aria-hidden="true"></a><span class="kw">stopCluster</span>(cl)</span>
<span id="cb41-32"><a href="tópicos-em-estatística-computacional.html#cb41-32" aria-hidden="true"></a></span>
<span id="cb41-33"><a href="tópicos-em-estatística-computacional.html#cb41-33" aria-hidden="true"></a><span class="co"># Uma aproximação para integral de uma função</span></span>
<span id="cb41-34"><a href="tópicos-em-estatística-computacional.html#cb41-34" aria-hidden="true"></a><span class="co"># utilizando um procedimento de MC:</span></span>
<span id="cb41-35"><a href="tópicos-em-estatística-computacional.html#cb41-35" aria-hidden="true"></a>result_parallel<span class="op">$</span>i_hat</span>
<span id="cb41-36"><a href="tópicos-em-estatística-computacional.html#cb41-36" aria-hidden="true"></a></span>
<span id="cb41-37"><a href="tópicos-em-estatística-computacional.html#cb41-37" aria-hidden="true"></a><span class="co"># Speedup:</span></span>
<span id="cb41-38"><a href="tópicos-em-estatística-computacional.html#cb41-38" aria-hidden="true"></a>time_serial[<span class="dv">3</span>]<span class="op">/</span>time_parallel[<span class="dv">3</span>]</span></code></pre></div>
</div>
</div>
<div id="exercício-3" class="section level2 unnumbered">
<h2>Exercício</h2>
<p>1 - Explique o que é um procedimento de Monte Carlo (MC)?</p>
<p>2 - Enuncie um procedimento de MC para o cálculo de uma integral de uma função contínua em um intervalo <span class="math inline">\([a, b]\)</span>. Depois, escreva um algoritmo para o procedimento enunciado.</p>
<p>3 - Seja <span class="math inline">\(\hat{I}\)</span> o estimador de <span class="math inline">\(I = \int_a^b f(x) dx\)</span>, em que <span class="math inline">\(f\)</span> é uma função contínua no intervalo <span class="math inline">\([a, b]\)</span>, em que</p>
<p><span class="math display">\[\hat{I} = (b-a) \frac{\sum_{i=1}^n f(x_i)}{n},\]</span>
cuja amostra é obtida pelo procedimento de MC enunciado no exercício anterior. Mostre que <span class="math inline">\(\hat{I}\)</span> é um estimador não-viesado e consistente para <span class="math inline">\(I\)</span>.</p>
<p>4 - Implemente a função <code>intmc()</code> que calcula a integral de uma função contínua qualquer definida em um intervalo <span class="math inline">\([a, b]\)</span>. <strong>Dica</strong>: Utilize o operador dot-dot-dot (operador varargs) para que a função <code>intmc()</code> possa receber argumentos da função que será integrada por um procedimento de MC.</p>
<p>5 - Seja <span class="math inline">\(X_1, \ldots, X_n\)</span> uma amostra aleatória de v.a.’s tal que <span class="math inline">\(X_i \sim \mathcal{N}(\mu = 0, \sigma^2 = 1)\)</span>. Construa um procedimento de MC para avaliar os estimadores <span class="math inline">\(\hat{\sigma}^2\)</span> e <span class="math inline">\(S^2\)</span> de <span class="math inline">\(\sigma^2\)</span>, em que</p>
<p><span class="math display">\[\begin{eqnarray}
\hat{\sigma}^2 &amp;=&amp; \frac{1}{n}\sum_{i=1}^n (X_i - \overline{X})^2\\
&amp;\mathrm{e}&amp;\\
S^2 &amp;=&amp; \frac{1}{n - 1}\sum_{i=1}^n (X_i - \overline{X})^2.
\end{eqnarray}\]</span></p>
<p><strong>Dica</strong>: Para comparar, utilize uma aproximação do Erro Quadrático Medio (EQM) obtida por um procedimento de MC. Lembre-se, se <span class="math inline">\(\hat{\theta}\)</span> é um estimador para <span class="math inline">\(\theta\)</span>, então o <span class="math inline">\(\mathrm{EQM}(\hat{\theta}) = \mathrm{E}[(\hat{\theta} - \theta)^2]\)</span>.</p>
<p>6 - Um dado experimento aleatório consiste em lançar dois dados não viesados (6 lados em cada dado) e observar a soma obtida. Por meio de um procedimento de MC, obtenha a probabilidade aproximada da soma ser par. Simule para <span class="math inline">\(N = 10, 100, 1000, 10000\)</span> e <span class="math inline">\(100000\)</span>, em que <span class="math inline">\(N\)</span> é o número de réplicas de MC. O que você observa? Explique.</p>
<p>7 - Walter está jogando um jogo com dois dados de 6 lados equiprováveis. O jogo consiste em lançar ambos os dados e caso a soma dos dados seja divisível por 3, ele ganhará, percendo em caso contrário. Realize um procedimento de MC para avaliar o jogo e responda a pergunta: Em média o jogo é favorável ao jogador?</p>
<p>8 - Suponha que tenhamos uma urna com bolas de mesmo tamanho enumeradas de 1 à 100. Considere o experimento aleatório de retirar uma bola da urna e observar o seu número até obtermos a bola com número desejado. Nesse experimento, será considerado reposição, isto é, caso não tenha sido observado a numeração desejada, a bola será devolvida à urna. Implemente um procedimento de MC considerando 10 mil repetições desse experimento e obtenha a média das retiradas necessárias para obter-se o número desejado. Além disso, retorne uma aproximação da probabilidade de se obter o número desejado. <strong>Dica</strong>: considere o número 77 como o número desejado.</p>
<p>9 - Um dono de cassino estuda disponibilizar um novo jogo e solicita uma consultoria estatística para saber se o jogo será viável para o cassino, isto é, se o valor esperado em dólares do lucro obtido será positivo, em média. Realize uma simulação de MC considerando 100 mil jogos e obtenha o valor médio de lançamentos de um jogador bem como a probabilidade (aproximada) de um jogador jogar apenas uma única partida. Além disso, responda: Se um jogador paga <span class="math inline">\(\$\)</span> 10 dólares para jogar e lucra <span class="math inline">\(\$\)</span> 1,50 dólares por cada jogada, o jogo é rentável para o dono do cassino?</p>
<p><strong>Regras do Jogo</strong>:</p>
<ul>
<li><p>Dois dados são lançados e caso a soma for 5, 6, 7, 8 ou 9 o jogo termina imediatamente;</p></li>
<li><p>Se nenhum dos resultamos acima for obtido, o jogador continua lançando ambos os dados até obter uma soma igual à 11 ou 12.</p></li>
</ul>
<p>10 - Explique, com suas palavras, o que é paralelização <strong>multicore</strong>. Descreva brevemente os conceitos de <strong>nó</strong>, <strong>thread</strong> (hardware), <strong>processo master</strong> e <strong>trabalhadores</strong>.</p>
<p>11 - Descreva brevemente o sistema <strong>FORK</strong> e <strong>PSOCK</strong>. Apresente um exemplo de um código paralelizado usando o sistema <strong>FORK</strong> e <strong>PSOCK</strong>, respectivamente.</p>
<p>12 - Defina <strong>speedup</strong> e explique o significado.</p>
<p>13 - Ao paralelizar um algoritmo, teremos garantia da melhoria do desempenho computacional? Explique.</p>
<p>14 - Enuncie a Lei de Amdahl e cite um ponto negativo dessa lei. Qual o valor máximo de <strong>speedup</strong> definido por essa lei?</p>
<p>15 - Implemente um procedimento de MC, utilizando paralelismo para avaliar o cálculo do estimador de <span class="math inline">\(\hat{I}\)</span> definido no exercício 3. Obtenha o <strong>speedup</strong> e discuta o resultado.</p>
<p>16 - Implemente uma versão paralela dos exercícios 5, 6, 7, 8 e 9. Avalie a implementação paralela com a versão serial. Houveram melhoria no desempenho computacional utilizando as versões paralelizadas? Explique.</p>
<!-- # Exercício 16: (paralelizando o exercício) -->
<!-- mc_ex6 <- function(n = 1e3L){ -->
<!--   dado1 <- ceiling(6L * runif(n)) + 1L -->
<!--   dado2 <- ceiling(6L * runif(n)) + 1L -->
<!--   teste <- function(x, y) ifelse((x + y) %% 2 == 0L , TRUE, FALSE) -->
<!--   sum(parallel::mcmapply(FUN = teste, x = dado1, y = dado2, -->
<!--                          mc.cores = parallel::detectCores()))/n -->
<!--   #sum(purrr::map2_dbl(.f = teste,  .x = dado1, .y = dado2))/n -->
<!-- } -->
<!-- system.time(result <- mc_ex6(n = 1e6)) -->
<!-- result -->
<p>17 - Implemente de forma paralela, uma função que realiza uma simulação de MC para avaliar o procedimento de MC para aproximação da constante <span class="math inline">\(\pi\)</span>. Obtenha o <strong>speedup</strong> e discuta o resultado. Considere 100 mil iterações em ambos os procedimentos.</p>
<p>18 - Implemente uma versão paralelizada do método da aceitação e rejeição para geração de números pseudo-aleatórios. Obtenha o <strong>speedup</strong> e discuta se houve ou não melhorias no desempenho computacional ao considerar-se a versão paralelizada. Explique.</p>
<!-- # Método da Aceitação e Rejeição (SERIAL) --------------------------------- -->
<!-- ar_serial <- function(n = 1L, fun, lower, upper, par, ...){ -->
<!--   func_obj <- function(x) -1 * fun(x, ...) * (upper - lower) -->
<!--   x_c <- optim(fn = func_obj, par = par, lower = lower, -->
<!--                upper = upper, method = "Brent")$par -->
<!--   c <- fun(x_c, ...) * (upper - lower) -->
<!--   test <- function(x){ -->
<!--     repeat{ -->
<!--       y <- runif(1L, min = lower, max = upper) -->
<!--       u <- runif(n = 1L, min = 0, max = 1) -->
<!--       if(u < (fun(y, ...) * (upper - lower) / c)) return(y) -->
<!--     } -->
<!--   } -->
<!--   unlist(lapply(X = 1:n, FUN = test)) -->
<!-- }   -->
<!-- f <- function(x, ...) dnorm(x, mean = ..1, sd = ..2) -->
<!-- result_serial <- ar_serial(n = 1e6L, fun = f, lower = -38,  -->
<!--                            upper = 38, par = 1, 0, 1) -->
<!-- # Método da Aceitação e Rejeição (PARALELO) ------------------------------- -->
<!-- ar_paralelo <- function(n = 1L, fun, lower, upper, par, ...){ -->
<!--   func_obj <- function(x) -1 * fun(x, ...) * (upper - lower) -->
<!--   x_c <- optim(fn = func_obj, par = par, lower = lower, -->
<!--                upper = upper, method = "Brent")$par -->
<!--   c <- fun(x_c, ...) * (upper - lower) -->
<!--   test <- function(x){ -->
<!--     repeat{ -->
<!--       y <- runif(1L, min = lower, max = upper) -->
<!--       u <- runif(n = 1L, min = 0, max = 1) -->
<!--       if(u < (fun(y, ...) * (upper - lower) / c)) return(y) -->
<!--     } -->
<!--   } -->
<!--   unlist(parallel::mclapply(X = 1:n, FUN = test,  -->
<!--                             mc.cores = parallel::detectCores())) -->
<!-- }   -->
<!-- f <- function(x, ...) dnorm(x, mean = ..1, sd = ..2) -->
<!-- result_paralelo <- ar_paralelo(n = 1e6L, fun = f, lower = -38,  -->
<!--                                upper = 38, par = 1, 0, 1) -->
</div>
<div id="bootstrap" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Bootstrap</h2>
<p>O método bootstrap foi introduzido em 1979 por Bradley Efron em um artigo publicado no <a href="https://www.imstat.org/journals-and-publications/annals-of-statistics/"><strong>The Annals of Statistics</strong></a>. A referência do artigo encontra-se abaixo e poderá ser acesso pelo link na referência, uma vez que o artigo é aberto.</p>
<blockquote>
<p>Efron, B. <a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176344552"><strong>Bootstrap methods: another look at the jackknife</strong></a>. The Annals of Statistics,
v. 7, p. 1–26, 1979.</p>
</blockquote>
<p>Tal método foi inspirado em uma metodologia anterior baseada em reamostragem denominada <a href="https://en.wikipedia.org/wiki/Jackknife_resampling"><strong>jackknife</strong></a>, idealizada por <a href="https://en.wikipedia.org/wiki/Maurice_Quenouille"><strong>Maurice Quenouille</strong></a> em 1949 e aperfeiçoada em 1956. Para maiores detalhes, consulte as referências abaixo:</p>
<blockquote>
<p>Quenouille, Maurice H. <a href="https://projecteuclid.org/download/pdf_1/euclid.aoms/1177729989"><strong>Problems in Plane Sampling</strong></a>. The Annals of Mathematical Statistics, v. 20, 355–375, 1949.</p>
</blockquote>
<p>e</p>
<blockquote>
<p>Quenouille, Maurice H. <a href="https://academic.oup.com/biomet/article-abstract/43/3-4/353/345190?redirectedFrom=fulltext"><strong>Notes on Bias in Estimation</strong></a>. Biometrika, v. 43, 353–360, 1956.</p>
</blockquote>
<p>Efron sintetizou as metodologias baseadas em reamostragem que até então existiam e estabeleceu uma nova área de pesquisa. Pode-se dizer que o <strong>jackniffe</strong> é uma aproximação ou mesmo um caso particular do método <strong>bootstrap</strong>.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-51"></span>
<img src="images/efron.jpg" alt="Bradley Efron, criador da técnica de reamostragem **bootstrap** amplamente utilizada na estatística e em outras áreas." width="60%" />
<p class="caption">
Figura 6.13: Bradley Efron, criador da técnica de reamostragem <strong>bootstrap</strong> amplamente utilizada na estatística e em outras áreas.
</p>
</div>
<p>O termo <strong>bootstrap</strong> teve origem na obra literária do escritor alemão <a href="https://en.wikipedia.org/wiki/Rudolf_Erich_Raspe"><strong>Rudolf Erich Raspe</strong></a> (1736–1794), mais precisamente de uma de suas óbras mais conhecidas intitulada <a href="https://en.wikipedia.org/wiki/Baron_Munchausen"><strong>The Surprising Adventures of Baron Munchausen</strong></a>, em que é dito:</p>
<div style="float:right;position: relative;">
<p><img src="images/boots.png" width="250px" height="250px" style="display: block; margin: auto 0 auto auto;" /></p>
</div>
<blockquote>
<p>“The Baron had fallen to the bottom of a deep lake. Just when it looked like all was lost, he thought to pick himself up by his own <strong>bootstraps</strong>.”</p>
</blockquote>
<blockquote>
<p><strong>Tradução</strong>: “O Barão tinha caı́do no fundo de um lago profundo. Justo quando parecia que tudo estava perdido, ele pensou em retirar-se por seus próprios <strong>bootstraps</strong>.”).</p>
</blockquote>
<p>Inicialmente houve ceticismo sobre a metodologia bootstrap, tendo sido tal ceticismo superado à medida em que estudos acumularam evidências de que o bootstrap pode ser consideravelmente mais eficaz que metodologias tradicionais.</p>
<p>A ideia de substituir aproximações complicadas e muitas vezes imprecisas por métodos de simulação baseados em reamostragem tem atraído diversos pesquisadores a desenvolver metodologias baseadas em bootstrap para os mais variados fins. Com a popularização do método bootstrap, alguns pesquisadores começaram a estabelecer condições matemáticas sob as quais o bootstrap é justificável.</p>
<p>Na literatura existem muitos trabalhos que fazem uso de metodologias bootstrap. Em geral, o método bootstrap é utilizado para correção de viés de estimadores, construção de intervalos de confiança, testes de hipóteses, estimação do erro-padrão de um estimador, entre outros.</p>
<p>As metodologias bootstrap apresentam dois paradigmas, sendo eles o <strong>bootstrap paramétrico</strong> e o <strong>bootstrap não-paramétrico</strong>. Bootstrap paramétrico refere-se ao caso em que a reamostragem é feita com base em uma distribuição <span class="math inline">\(F(\widehat{\theta})\)</span> conhecida ou estabelecida, em que <span class="math inline">\(\widehat{\theta}\)</span> é um estimador para <span class="math inline">\(\theta\)</span>. Em contrapartida, no bootstrap não-paramétrico há o desconhecimento da distribuição <span class="math inline">\(F\)</span> verdadeira. A reamostragem é feita com base na função de distribuição empírica <span class="math inline">\(F_n\)</span>. <strong>Reamostrar de <span class="math inline">\(F_n\)</span> equivale a reamostrar dos dados com reposição</strong>.</p>
<p>O bootstrap não-paramétrico trata a amostra como se fosse a população e a reamostragem é realizada dessa amostra como se estevessemos amostrando da população. O método de bootstrap não-paramétrico é frequentemente utilizado quando a distribuição da população alvo não é especificada. Nesse casos, temos apenas as informações contidas na amostra, em que poderemos fazer uso da distribuição empírica (distribuição dos dados) como uma aproximação da distribuição verdadeira <span class="math inline">\(F\)</span> (desconhecida).</p>
<p>Seja <span class="math inline">\(\pmb X = (X_1, \ldots, X_n)\)</span> uma sequência de v.a.’s i.i.d. (uma amostra aleatória), tal que <span class="math inline">\(F_{X_i}\)</span> é <strong>desconhecida</strong>, com <span class="math inline">\(i = 1, \ldots, n\)</span>. Como a natureza funcional de <span class="math inline">\(F_{X_i}\)</span> é desconhecida, as únicas informações que teremos a nossa disposição são as observações da amostra aleatória, ou seja, <span class="math inline">\(\pmb x = (x_1, \ldots, x_n)\)</span>. Muito embora desconhecemos <span class="math inline">\(F_{X_i}\)</span>, sabemos que</p>
<p><span class="math display">\[P\Big(\lim_{n\to \infty} \mathrm{sup}|F_n - F_{X_i}| = 0\Big) = 1,\]</span>
em que <span class="math inline">\(F_n\)</span> é a função de distribuição empírica (função de distribuição dos dados) que é dada por:</p>
<p><span class="math display">\[F_n(t) = \frac{1}{n} \sum_{i = 1} ^ n I\{x_i \leq t\}.\]</span>
O resultado acima é conhecido como <a href="https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem"><strong>Teorema de Glivenko-Cantelli</strong></a>. Em outras palavras, o teorema afirma que <span class="math inline">\(F_n\)</span> converge quase certamente para <span class="math inline">\(F_{X_i}\)</span> (<span class="math inline">\(F_n \overset{q.c.}{\to} F_{X_i}\)</span>). Para maiores detalhes, veja a página 336 do livro <strong>Probabilidade e Variáveis Aleatórias</strong>, Ed. 3, 2011 de Marcos N. Magalhães.</p>
<p><strong>Exemplo</strong>: O código abaixo é responsável pela construção gráfica da distribuição empírica <span class="math inline">\(F_n\)</span> com base em uma amostra. A função <code>empirical()</code> recebe como argumento observações de uma amostra aleatória e constrói o gráfico de <span class="math inline">\(F_n\)</span>. Após o código da função <code>empirical()</code> são gerados números pseudo-aleatórios (50 observações) provenientes de uma amostra aleatória com distribuição <span class="math inline">\(Weibull(\alpha = 1.5, \beta = 2.0)\)</span> (distribuição verdadeira). A função <code>empirical()</code> irá graficar uma estimativa da distribuição <span class="math inline">\(Weibull(\alpha = 1.5, \beta = 2.0)\)</span> por meio de <span class="math inline">\(F_n\)</span> (em laranja), em que a curva preta é a distrbuição verdadeira, isto é, a distribuição <span class="math inline">\(Weibull(\alpha = 1.5, \beta = 2.0)\)</span>. <strong>Dica</strong>: Reproduza o código para diverentes tamanhos de amostra. Perceba que para valores grandes de amostra, por exemplo, 1000, 10000 ou 100000, o gráfico obtido de <span class="math inline">\(F_n\)</span> se confunde com o gráfico de <span class="math inline">\(F\)</span>.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="tópicos-em-estatística-computacional.html#cb42-1" aria-hidden="true"></a>empirical &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...){</span>
<span id="cb42-2"><a href="tópicos-em-estatística-computacional.html#cb42-2" aria-hidden="true"></a></span>
<span id="cb42-3"><a href="tópicos-em-estatística-computacional.html#cb42-3" aria-hidden="true"></a>   domain &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="kw">floor</span>(<span class="kw">min</span>(x)), <span class="dt">to =</span> <span class="kw">ceiling</span>(<span class="kw">max</span>(x)) <span class="op">+</span><span class="st"> </span>1L, <span class="dt">length.out =</span> <span class="fl">1e3</span>L)</span>
<span id="cb42-4"><a href="tópicos-em-estatística-computacional.html#cb42-4" aria-hidden="true"></a></span>
<span id="cb42-5"><a href="tópicos-em-estatística-computacional.html#cb42-5" aria-hidden="true"></a>   test &lt;-<span class="st"> </span><span class="cf">function</span>(i) <span class="kw">sum</span>(x <span class="op">&lt;=</span><span class="st"> </span>domain[i]) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x)</span>
<span id="cb42-6"><a href="tópicos-em-estatística-computacional.html#cb42-6" aria-hidden="true"></a></span>
<span id="cb42-7"><a href="tópicos-em-estatística-computacional.html#cb42-7" aria-hidden="true"></a>   prob &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map_dbl</span>(<span class="dt">.x =</span> 1L<span class="op">:</span><span class="kw">length</span>(domain), <span class="dt">.f =</span> test)</span>
<span id="cb42-8"><a href="tópicos-em-estatística-computacional.html#cb42-8" aria-hidden="true"></a></span>
<span id="cb42-9"><a href="tópicos-em-estatística-computacional.html#cb42-9" aria-hidden="true"></a>   <span class="kw">plot.new</span>()</span>
<span id="cb42-10"><a href="tópicos-em-estatística-computacional.html#cb42-10" aria-hidden="true"></a>   <span class="kw">plot.window</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="kw">floor</span>(<span class="kw">min</span>(x)), <span class="kw">ceiling</span>(<span class="kw">max</span>(x))), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb42-11"><a href="tópicos-em-estatística-computacional.html#cb42-11" aria-hidden="true"></a>   <span class="kw">axis</span>(<span class="dv">1</span>); <span class="kw">axis</span>(<span class="dv">2</span>)</span>
<span id="cb42-12"><a href="tópicos-em-estatística-computacional.html#cb42-12" aria-hidden="true"></a>   <span class="kw">lines</span>(domain, prob, <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.04</span>), ...)</span>
<span id="cb42-13"><a href="tópicos-em-estatística-computacional.html#cb42-13" aria-hidden="true"></a>   <span class="kw">title</span>(<span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Probabilidade&quot;</span>, <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&quot;n = &quot;</span>, <span class="kw">length</span>(x)))</span>
<span id="cb42-14"><a href="tópicos-em-estatística-computacional.html#cb42-14" aria-hidden="true"></a>}</span>
<span id="cb42-15"><a href="tópicos-em-estatística-computacional.html#cb42-15" aria-hidden="true"></a><span class="co"># Dados proveniente da distribuição verdadeira</span></span>
<span id="cb42-16"><a href="tópicos-em-estatística-computacional.html#cb42-16" aria-hidden="true"></a><span class="co"># Weibull(alpha = 0.5, beta = 1.3):</span></span>
<span id="cb42-17"><a href="tópicos-em-estatística-computacional.html#cb42-17" aria-hidden="true"></a><span class="kw">set.seed</span>(1L)</span>
<span id="cb42-18"><a href="tópicos-em-estatística-computacional.html#cb42-18" aria-hidden="true"></a>dados &lt;-<span class="st"> </span><span class="kw">rweibull</span>(50L, <span class="dt">shape =</span> <span class="fl">1.5</span>, <span class="dt">scale =</span> <span class="fl">2.0</span>)</span>
<span id="cb42-19"><a href="tópicos-em-estatística-computacional.html#cb42-19" aria-hidden="true"></a><span class="co"># Construindo a função de distribuição empírica através dos dados:</span></span>
<span id="cb42-20"><a href="tópicos-em-estatística-computacional.html#cb42-20" aria-hidden="true"></a><span class="kw">empirical</span>(dados, <span class="dt">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb42-21"><a href="tópicos-em-estatística-computacional.html#cb42-21" aria-hidden="true"></a><span class="co"># Desenhando a função de distribuição teórica sobre o gráfico da</span></span>
<span id="cb42-22"><a href="tópicos-em-estatística-computacional.html#cb42-22" aria-hidden="true"></a><span class="co"># função de distribuição empírica:</span></span>
<span id="cb42-23"><a href="tópicos-em-estatística-computacional.html#cb42-23" aria-hidden="true"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="kw">floor</span>(<span class="kw">min</span>(dados)), <span class="dt">to =</span> <span class="kw">ceiling</span>(<span class="kw">max</span>(dados)), <span class="dt">length.out =</span> <span class="fl">1e3</span>L)</span>
<span id="cb42-24"><a href="tópicos-em-estatística-computacional.html#cb42-24" aria-hidden="true"></a><span class="kw">lines</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">pweibull</span>(<span class="dt">q =</span> x, <span class="dt">shape =</span> <span class="fl">1.5</span>, <span class="dt">scale =</span> <span class="fl">2.0</span>), <span class="dt">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb42-25"><a href="tópicos-em-estatística-computacional.html#cb42-25" aria-hidden="true"></a><span class="co"># Acrescentando uma legenda:</span></span>
<span id="cb42-26"><a href="tópicos-em-estatística-computacional.html#cb42-26" aria-hidden="true"></a><span class="kw">legend</span>(<span class="dt">x =</span> <span class="st">&quot;right&quot;</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="kw">expression</span>(F, F[n])), <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb42-27"><a href="tópicos-em-estatística-computacional.html#cb42-27" aria-hidden="true"></a>       <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="kw">rgb</span>(<span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.04</span>)))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-53"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-53-1.png" alt="Função de distribuição empírica em azul versus a função de distribuição teórica em preto para um tamanho de amostra n = 50." width="672" />
<p class="caption">
Figura 6.14: Função de distribuição empírica em azul versus a função de distribuição teórica em preto para um tamanho de amostra n = 50.
</p>
</div>
<p>Em uma abordagem não-paramétrica, um histograma poderia ser uma estimativa gráfica da função de distribuição verdadeira, uma vez que para a construção do gráfico, utiliza-se <span class="math inline">\(\pmb x\)</span>. Em um bootstrap não-paramétrico, como dito anteriormente, uma amostra bootstrap é obtida por uma reamostragem (<strong>com reposição</strong>) de <span class="math inline">\(\pmb x\)</span> e denotamos por <span class="math inline">\(\pmb x^*\)</span>, que são observações da amostra aleatória bootstrap <span class="math inline">\(\pmb X^* = (X^*_1, \ldots, X^*_n)\)</span>. Em outras palavras, reamostrar de <span class="math inline">\(\pmb x\)</span> (com reposição) quer dizer que poderemos gerar uma amostra bootstrap tomando <span class="math inline">\(n\)</span> valores inteiros <span class="math inline">\(\{i_1, \ldots, i_n\}\)</span> uniformemente distribuídos em <span class="math inline">\(\{1, \ldots, n\}\)</span> e selecionando <span class="math inline">\(\pmb x^* = (x_{i_1}, \ldots, x_{i_n})\)</span>. Isso quer dizer que para algum <span class="math inline">\(X^*_i\)</span>, seja ele denotado simplesmente por <span class="math inline">\(X^*\)</span>, tem-se:</p>
<p><span class="math display">\[P(X^* = x_i) = \frac{1}{n}, \, i = 1, \ldots, n.\]</span>
Sendo assim, note que a função de distribuição teórica de <span class="math inline">\(X^*\)</span> é dada por <span class="math inline">\(F_n\)</span>. Daí, amostrar de <span class="math inline">\(\pmb x\)</span> (<strong>com reposição</strong>) nos geram amostras bootstrap que tem a distribuição empírica como distribuição teórica e que sabemos que converge quase cetamente para <span class="math inline">\(F\)</span> (desconhecida).</p>
<p>Seja <span class="math inline">\(T_n = \hat{\theta}\)</span> um estimador de <span class="math inline">\(\theta\)</span> com base na amostra aleatória original <span class="math inline">\(\pmb X\)</span>, em que <span class="math inline">\(\theta\)</span> é um parâmetro ou vetor de parâmetros. Temos que <span class="math inline">\(t\)</span> é a estimativa obtida por <span class="math inline">\(T_n\)</span> com base nas observações originais <span class="math inline">\(\pmb x\)</span>. Analogamente, considere <span class="math inline">\(T_n^* = \hat{\theta}^*\)</span> o mesmo estimador <span class="math inline">\(T_n\)</span> sobre uma amostra aleatória bootstrap <span class="math inline">\(\pmb X^*\)</span>, em que <span class="math inline">\(t^*\)</span> é a estimativa obtida por <span class="math inline">\(T_n^*\)</span> com base em uma pseudo-amostra bootstrap <span class="math inline">\(\pmb x^*\)</span>.</p>
<p>Assim, uma estimativa da função de distribuição de <span class="math inline">\(T_n\)</span> poderá ser obtida com os passos abaixo:</p>
<ol style="list-style-type: decimal">
<li><p>Para cada réplica bootstrap, <span class="math inline">\(b = 1, \ldots, B\)</span>:</p>
<ul>
<li><p>Gere uma amostra bootstrap <span class="math inline">\(\pmb x^{*,b} = (x_1^*, \ldots, x_n^*)\)</span> por reamostragem com reposição de <span class="math inline">\(\pmb x = (x_1, \ldots, x_n)\)</span>.</p></li>
<li><p>Obtenha a estimativa <span class="math inline">\(t^*\)</span> com base em <span class="math inline">\(\pmb x^{*,b}\)</span> gerada no passo anterior.</p></li>
</ul></li>
<li><p>A estimativa bootstrap de <span class="math inline">\(F_{T_n}(\cdot)\)</span> é a função de distribuição empírica das estimativas bootstrap <span class="math inline">\(t^{*,1}, \ldots, t^{*,B}\)</span>.</p></li>
</ol>
<p><strong>Exemplo</strong>: Suponha que <span class="math inline">\(T_n = \overline{X}\)</span> e considere <span class="math inline">\(\pmb x = (x_1, \ldots, x_n)\)</span> observações de uma amostra aleatória <span class="math inline">\(\pmb X = (X_1, \ldots, X_n)\)</span>, em que <span class="math inline">\(X_i \sim \mathrm{Exp}\Big(\lambda = \frac{1}{2}\Big)\)</span>, com <span class="math inline">\(i = 1, \ldots, n\)</span>, com <span class="math inline">\(n = 250\)</span>. Então, por meio do algoritmo acima, poderemos obter, com o código abaixo, uma estimativa da distribuição de <span class="math inline">\(T_n\)</span>. Nesse caso, não é difícil perceber que a distribuição de <span class="math inline">\(T_n\)</span> terá distribuição <span class="math inline">\(\mathcal{N}(\mu, \sigma^2/n)\)</span>, em que <span class="math inline">\(\mu = \mathrm{E}(X) = 1/\lambda\)</span> e <span class="math inline">\(\sigma^2 = \mathrm{Var}(X) = 1/\lambda^2\)</span>. Nesse caso, a distribuição teórica de <span class="math inline">\(T_n\)</span> é <span class="math inline">\(\mathcal{N}(2, 0.016)\)</span>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="tópicos-em-estatística-computacional.html#cb43-1" aria-hidden="true"></a><span class="co"># Amostra original:</span></span>
<span id="cb43-2"><a href="tópicos-em-estatística-computacional.html#cb43-2" aria-hidden="true"></a>x &lt;-<span class="st"> </span><span class="kw">rexp</span>(250L, <span class="fl">0.5</span>) <span class="co"># lambda = 1/2</span></span>
<span id="cb43-3"><a href="tópicos-em-estatística-computacional.html#cb43-3" aria-hidden="true"></a></span>
<span id="cb43-4"><a href="tópicos-em-estatística-computacional.html#cb43-4" aria-hidden="true"></a>bootstraping &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">B =</span> 100L, sample_true, stat, ...){</span>
<span id="cb43-5"><a href="tópicos-em-estatística-computacional.html#cb43-5" aria-hidden="true"></a></span>
<span id="cb43-6"><a href="tópicos-em-estatística-computacional.html#cb43-6" aria-hidden="true"></a>  <span class="co"># A função resample() obtem uma amostra com reposição de x:</span></span>
<span id="cb43-7"><a href="tópicos-em-estatística-computacional.html#cb43-7" aria-hidden="true"></a>  resample &lt;-<span class="st"> </span><span class="cf">function</span>(x){</span>
<span id="cb43-8"><a href="tópicos-em-estatística-computacional.html#cb43-8" aria-hidden="true"></a>    n &lt;-<span class="st"> </span><span class="kw">length</span>(x)</span>
<span id="cb43-9"><a href="tópicos-em-estatística-computacional.html#cb43-9" aria-hidden="true"></a>    <span class="co"># Selecionando observações uniformemente distribuídas em x.</span></span>
<span id="cb43-10"><a href="tópicos-em-estatística-computacional.html#cb43-10" aria-hidden="true"></a>    <span class="co"># Poderia ser utilizado a função sample().</span></span>
<span id="cb43-11"><a href="tópicos-em-estatística-computacional.html#cb43-11" aria-hidden="true"></a>    x[<span class="kw">floor</span>(n <span class="op">*</span><span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>1L)]</span>
<span id="cb43-12"><a href="tópicos-em-estatística-computacional.html#cb43-12" aria-hidden="true"></a>  }</span>
<span id="cb43-13"><a href="tópicos-em-estatística-computacional.html#cb43-13" aria-hidden="true"></a></span>
<span id="cb43-14"><a href="tópicos-em-estatística-computacional.html#cb43-14" aria-hidden="true"></a>  <span class="co"># A função boot() calcula uma statística em uma única amostra</span></span>
<span id="cb43-15"><a href="tópicos-em-estatística-computacional.html#cb43-15" aria-hidden="true"></a>  <span class="co"># bootstrap:</span></span>
<span id="cb43-16"><a href="tópicos-em-estatística-computacional.html#cb43-16" aria-hidden="true"></a>  boot &lt;-<span class="st"> </span><span class="cf">function</span>(x, sample_true){</span>
<span id="cb43-17"><a href="tópicos-em-estatística-computacional.html#cb43-17" aria-hidden="true"></a>    <span class="kw">stat</span>(<span class="kw">resample</span>(sample_true), ...)</span>
<span id="cb43-18"><a href="tópicos-em-estatística-computacional.html#cb43-18" aria-hidden="true"></a>  }</span>
<span id="cb43-19"><a href="tópicos-em-estatística-computacional.html#cb43-19" aria-hidden="true"></a></span>
<span id="cb43-20"><a href="tópicos-em-estatística-computacional.html#cb43-20" aria-hidden="true"></a>  purrr<span class="op">::</span><span class="kw">map_dbl</span>(<span class="dt">.x =</span> 1L<span class="op">:</span>B, <span class="dt">.f =</span> boot, <span class="dt">sample_true =</span> sample_true)</span>
<span id="cb43-21"><a href="tópicos-em-estatística-computacional.html#cb43-21" aria-hidden="true"></a>  <span class="co"># or</span></span>
<span id="cb43-22"><a href="tópicos-em-estatística-computacional.html#cb43-22" aria-hidden="true"></a>  <span class="co">#lapply(X = 1L:N, FUN = boot, sample_true)</span></span>
<span id="cb43-23"><a href="tópicos-em-estatística-computacional.html#cb43-23" aria-hidden="true"></a></span>
<span id="cb43-24"><a href="tópicos-em-estatística-computacional.html#cb43-24" aria-hidden="true"></a>}</span>
<span id="cb43-25"><a href="tópicos-em-estatística-computacional.html#cb43-25" aria-hidden="true"></a><span class="co"># Fixando uma semente:</span></span>
<span id="cb43-26"><a href="tópicos-em-estatística-computacional.html#cb43-26" aria-hidden="true"></a><span class="kw">set.seed</span>(1L)</span>
<span id="cb43-27"><a href="tópicos-em-estatística-computacional.html#cb43-27" aria-hidden="true"></a><span class="co"># Observe que stat é a média amostra, uma vez que passamos a função</span></span>
<span id="cb43-28"><a href="tópicos-em-estatística-computacional.html#cb43-28" aria-hidden="true"></a><span class="co"># mean().</span></span>
<span id="cb43-29"><a href="tópicos-em-estatística-computacional.html#cb43-29" aria-hidden="true"></a>result &lt;-<span class="st"> </span><span class="kw">bootstraping</span>(<span class="dt">B =</span> <span class="fl">3e3</span>L, <span class="dt">sample_true =</span> x, <span class="dt">stat =</span> mean)</span>
<span id="cb43-30"><a href="tópicos-em-estatística-computacional.html#cb43-30" aria-hidden="true"></a><span class="kw">hist</span>(result, <span class="dt">probability =</span> <span class="ot">TRUE</span>, <span class="dt">main =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Aproximação para a densidade de &quot;</span>,  T[n])),</span>
<span id="cb43-31"><a href="tópicos-em-estatística-computacional.html#cb43-31" aria-hidden="true"></a>     <span class="dt">border =</span> <span class="ot">NA</span>, <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="dv">1</span>, <span class="fl">0.9</span>, <span class="fl">0.8</span>), <span class="dt">xlab =</span> <span class="kw">expression</span>(t<span class="op">^</span><span class="st">&quot;*&quot;</span>), <span class="dt">ylab =</span> <span class="st">&quot;Probabilidade&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-54"></span>
<img src="topicos_estatistica_computacional_files/figure-html/unnamed-chunk-54-1.png" alt="Histograma construído com base nas estimativas obtidas nas amostras bootstrap. Trata-se de uma aproximação para a densidade da estatística que nesse caso é a média amostral." width="672" />
<p class="caption">
Figura 6.15: Histograma construído com base nas estimativas obtidas nas amostras bootstrap. Trata-se de uma aproximação para a densidade da estatística que nesse caso é a média amostral.
</p>
</div>
<p><strong>Importante</strong>:</p>

<div class="rmdimportant">
<div class="text-justify">
<p>O método de bootstrap não deverá ser utilizado para estimar <span class="math inline">\(\theta\)</span>. Por exemplo, <span class="math inline">\(1/B \sum_{i = 1}^B t_i^*\)</span> pode não ser uma boa estimativa para <span class="math inline">\(\theta\)</span>. O bootstrap fornece boas aproximações para a forma e amplitude da distribuição de <span class="math inline">\(T_n\)</span> mas não necessariamente para a sua locação. Isso se deve ao fato que temos duas contes de erro, uma vez a função de distribuição empírica <span class="math inline">\(F_n^*\)</span> obtida por <span class="math inline">\(\pmb x^*\)</span> aproxima a distribuição teórica de <span class="math inline">\(X^*\)</span> que é <span class="math inline">\(F_n\)</span> e esta por sua vez aproxima <span class="math inline">\(F\)</span> por meio de <span class="math inline">\(\pmb x\)</span>.</p>
</div>
</div>
<div id="estimando-erro-padrão" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Estimando erro-padrão</h3>
<p>A estimativa bootstrap para o erro-padrão de <span class="math inline">\(T_n\)</span> poderá ser escrito como:</p>
<p><span class="math display">\[\widehat{se}(T_n)_{\mathrm{boot}} = \sqrt{\frac{1}{B-1}\sum_{i=1}^B(T_n^{*,i} - \overline{T_n^*})^2},\]</span>
em que <span class="math inline">\(\overline{T_n^*} = \frac{1}{B}\sum_{i=1}^B T^{*,i}\)</span>, sendo <span class="math inline">\(T_n^{*,i}\)</span> o estimador <span class="math inline">\(T_n\)</span> com base na <span class="math inline">\(i\)</span>-ésima amostra bootstrap. Segundo Efron e Tibshirani, no livro B. Efron and R. J. Tibshirani. <strong>An Introduction to the Bootstrap</strong>. Chapman &amp; Hall/CRC, Boca Raton, FL, 1993, p. 52, não é necessário um número de amostras bootstrap <span class="math inline">\(B\)</span> muito grande. Segundos os autores, <span class="math inline">\(B = 50\)</span> é um número suficientemente grande na maioria dos casos e <span class="math inline">\(B &gt; 200\)</span> é raramente necessário.</p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Para obtenção de uma boa estimativa do erro-padrão de <span class="math inline">\(T_n\)</span>, considere <span class="math inline">\(B \geq 250\)</span>.</p>
</div>
</div>
<p><strong>Exemplo</strong>: O código que segue calcula uma estimativa via bootstrap para o estimador <span class="math inline">\(\overline{X} = n^{-1}\sum_1^n X_i\)</span> de <span class="math inline">\(\mu\)</span>, com <span class="math inline">\(X_i, \ldots, X_n\)</span> sendo amostra aleatória tal que <span class="math inline">\(X_i \sim \mathcal{N}(\mu = 0, \sigma^2 = 1)\)</span>. Note que a função <code>bootstraping()</code> implementada em exemplo anterior realiza a reamostragem por bootstrap não-paramétrico, mais precisamente mil amostras bootstrap (<code>N = 1e3L</code>) sobre uma amostra original (<code>sample_true = amostra</code>) e obtem sobre cada uma das amostras bootstrap uma estimativa da média amostral (<code>stat = mean</code>). Assim, fazer <code>sd(bootstraping())</code> é calcular uma estimativa do erro-padrão de <span class="math inline">\(\overline{X}\)</span> utilizando o estimador bootstrap <span class="math inline">\(\widehat{se}(T_n)_{\mathrm{boot}}\)</span>. Perceba que <span class="math inline">\(\sqrt{\mathrm{Var}(\overline{X})} = \sqrt{1/250}\)</span> e que a estimativa bootstrap do erro-padrão de <span class="math inline">\(T_n = \overline{X}\)</span> é bem aproximada por <span class="math inline">\(\widehat{se}(T_n)_{\mathrm{boot}}\)</span>.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="tópicos-em-estatística-computacional.html#cb44-1" aria-hidden="true"></a><span class="co"># Fixando uma semente.</span></span>
<span id="cb44-2"><a href="tópicos-em-estatística-computacional.html#cb44-2" aria-hidden="true"></a><span class="kw">set.seed</span>(1L)</span>
<span id="cb44-3"><a href="tópicos-em-estatística-computacional.html#cb44-3" aria-hidden="true"></a><span class="co"># O objeto &quot;amostra&quot; é a amostral original.</span></span>
<span id="cb44-4"><a href="tópicos-em-estatística-computacional.html#cb44-4" aria-hidden="true"></a>amostra &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> 250L, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>) <span class="co"># Amostra original.</span></span>
<span id="cb44-5"><a href="tópicos-em-estatística-computacional.html#cb44-5" aria-hidden="true"></a><span class="co"># Obtendo mil amostras bootstrap com reposição da amostra original e calcuando</span></span>
<span id="cb44-6"><a href="tópicos-em-estatística-computacional.html#cb44-6" aria-hidden="true"></a><span class="co"># a média amostral, i.e, T_n^* é a média amostral (stat = mean). Note que fazer</span></span>
<span id="cb44-7"><a href="tópicos-em-estatística-computacional.html#cb44-7" aria-hidden="true"></a><span class="co"># var(bootstraping()) estamos obtendo uma estimativa do erro-padrão via bootstrap</span></span>
<span id="cb44-8"><a href="tópicos-em-estatística-computacional.html#cb44-8" aria-hidden="true"></a><span class="co"># da média amostral.</span></span>
<span id="cb44-9"><a href="tópicos-em-estatística-computacional.html#cb44-9" aria-hidden="true"></a><span class="kw">sd</span>(<span class="kw">bootstraping</span>(<span class="dt">N =</span> <span class="fl">1e3</span>L, <span class="dt">sample_true =</span> amostra, <span class="dt">stat =</span> mean))</span></code></pre></div>
<pre><code>## [1] 0.06307263</code></pre>
<p><strong>Impotante</strong>:</p>

<div class="rmdimportant">
<div class="text-justify">
<p>A amostra original não precisa ser observações de v.a.’s com distribuição normal. Utilizamos o caso da normal para facilitar as contas. O método bootstrap poderá ser aplicado à observações de uma amostra aleatória com distribuição qualquer.</p>
</div>
</div>
</div>
<div id="diminuindo-o-viés" class="section level3" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Diminuindo o viés</h3>
<p>Se <span class="math inline">\(T_n\)</span> é um estimador não-viesado para <span class="math inline">\(\theta\)</span>, então <span class="math inline">\(\mathrm{E}(T_n) = \theta\)</span>. Porém, alguns estimadores podem ser viesados para estimar <span class="math inline">\(\theta\)</span>, em que o seu viés poderá ser obtido por:</p>
<p><span class="math display">\[B(T_n) = \mathrm{E}(T_n - \theta) = \mathrm{E}(T_n) - \theta.\]</span>
Diremos que um <span class="math inline">\(T_n\)</span> é um estimador <strong>assintoticamente não-viesado</strong> para <span class="math inline">\(\theta\)</span> se <span class="math inline">\(\lim_{n \to \infty} B(T_n) = 0\)</span>. Alguns estimadores podem ter boas propriedades estatísticas mas serem viesados em amostras que não são suficientemente grandes. Por exemplo, os estimadores de máxima veorssimilhança podem ser viesados em pequenas amostras mas sabemos que são assintoticamente não-viesados, como é o caso do estimador de máxima verossimilhança de <span class="math inline">\(\sigma^2\)</span> dado por <span class="math inline">\(\hat{\sigma}^2 = 1/n \sum_{i=1}^{n}(X_i - \overline{X})^2\)</span>, com <span class="math inline">\(X_i, \ldots, X_n\)</span> sendo uma amostra aleatória tal que <span class="math inline">\(X_i \sim \mathcal{N}(\mu, \sigma^2)\)</span>, com <span class="math inline">\(i = 1, \ldots, n\)</span>. Nesse caso, <span class="math inline">\(\mathrm{E}(\hat{\sigma}^2) = \frac{(n-1)}{n} \sigma^2\)</span>. Daí, poderemos corrigir o víes de <span class="math inline">\(\hat{\sigma}^2\)</span> considerando <span class="math inline">\(S^2 = \frac{n}{n-1}\hat{\sigma}^2 = \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \overline{X})^2\)</span>.
Em um situação ideal, temos que o estimador <span class="math inline">\(T_n\)</span> corrigido por víes é dado por</p>
<p><span class="math display">\[T_n^{\mathrm{ideal}} = T_n - B(T_n).\]</span>
Porém, note que <span class="math inline">\(T_n^{\mathrm{ideal}}\)</span> não é um estimador, uma vez que <span class="math inline">\(T_n^{\mathrm{ideal}}\)</span> depende de <span class="math inline">\(\theta\)</span>. Assim, em uma situação quase-ideal, temos que</p>
<p><span class="math display">\[T_n^{\mathrm{quase-ideal}} = T_n  - \widehat{B(T_n)}.\]</span></p>
<p>Queremos construir um estimador <span class="math inline">\(T_n^{\mathrm{corrigido}}\)</span> semelhante à <span class="math inline">\(T_n^{\mathrm{quase-ideal}}\)</span>.</p>
<p><span class="math display">\[T_n^{\mathrm{corrigido}} = T_n - \widehat{B(T_n)} = T_n - [\widehat{\mathrm{E}(T_n)} - T_n] = 2T_n - \widehat{\mathrm{E}(T_n)}.\]</span></p>
<p>O estimador bootstrap do viés utiliza-se, assim como em qualquer método bootstrap, a distribuição bootstrap de <span class="math inline">\(T_n\)</span> para estimar a distribuição de <span class="math inline">\(T_n\)</span>. Assim, tome</p>
<p><span class="math display">\[\widehat{\mathrm{E}(T_n)} = \frac{1}{n}\sum_{i=1}^B T_n^{*,i} = \overline{T_n^{*}}.\]</span>
Portanto, o estimador <span class="math inline">\(T_n\)</span> corrigido por bootstrap é dado por:</p>
<p><span class="math display">\[T_n^{\mathrm{corrigido-boot}} = 2T_n - \overline{T_n^{*}}.\]</span></p>
<p>Dessa forma, a estimativa corrigida por bootstrap é dada por <span class="math inline">\(t_n^{\mathrm{corrigido-boot}} = 2t_n - \overline{t_n^*}\)</span>, em que <span class="math inline">\(t_n\)</span> é a estimativa obtida por <span class="math inline">\(T_n\)</span> em <span class="math inline">\(\pmb x\)</span> e <span class="math inline">\(\overline{t_n^*}\)</span> é a média das estimatativas obtidas por <span class="math inline">\(T_n\)</span> calculada sobre as amostras bootstrap <span class="math inline">\(\Big(t_n^{*,1},\ldots, t_n^{*,B}\Big)\)</span>. Sendo assim, <span class="math inline">\(t_n^{\mathrm{corrigido-boot}}\)</span> dará a estimativa para <span class="math inline">\(\theta\)</span> corrigida por bootstrap.</p>
<p><strong>Exemplo</strong>: Implemente a função <code>bias_boot(B = 100L, sample_true, f, kicks, idpar = 1L, ...)</code> que receberá como argumentos a quantidade de réplicas bootstrap (<code>B</code>), a amostra original (<code>sample_true</code>), uma f.d.p / f.p (<code>f</code>) ao qual obteremos as estimativas de máxima verossimilhança por métodos númericos, os chutes iniciais <code>kicks</code> utilizado pelo método de minimização de <span class="math inline">\(-\mathcal{l}(\pmb \theta)\)</span>, em que <span class="math inline">\(\mathcal{l}(\pmb \theta)\)</span> é a função de log-verossimilhança e <span class="math inline">\(\pmb \theta\)</span> é o vetor de parâmetros que idexam a f.d.p / f.p. Os dois últimos argumentos <code>idpar = 1L</code> e <code>...</code> informa o parâmetro ao qual desejamos corrigir por viés via bootstrap, em que <code>1L</code> indica o primeiro parâmetro de <span class="math inline">\(\pmb \theta\)</span> e argumentos adicionais passados à função de otimização <code>optim()</code>, respectivamente. A ideia é que <code>bias_boot()</code> é que seja uma função que receba, por exemplo, uma f.d.p e retorne a estimativa de máxima verossimilhança sobre a amostra original e a estimativa corrigida por bootstrap. Por exemplo, se é <span class="math inline">\(X_1, \ldots, X_n\)</span> uma sequência de v.a.’s i.i.d (amostra aleatória), tal que <span class="math inline">\(X_i \sim Weibull(\alpha = 2, \beta = 2)\)</span>, para <span class="math inline">\(i = 1, \ldots, n\)</span>, então</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="tópicos-em-estatística-computacional.html#cb46-1" aria-hidden="true"></a>amostra &lt;-<span class="st"> </span><span class="kw">rweibull</span>(<span class="dt">n =</span> 30L, <span class="dt">shape =</span> <span class="dv">2</span>, <span class="dt">scale =</span> <span class="dv">2</span>)</span>
<span id="cb46-2"><a href="tópicos-em-estatística-computacional.html#cb46-2" aria-hidden="true"></a><span class="kw">bias_boot</span>(<span class="dt">B =</span> 500L, <span class="dt">sample_true =</span> amostra, <span class="dt">f =</span> fdp_weibull,</span>
<span id="cb46-3"><a href="tópicos-em-estatística-computacional.html#cb46-3" aria-hidden="true"></a>          <span class="dt">kicks =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">idpar =</span> 1L, <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>)</span></code></pre></div>
<p>deverá retornar a estimativa de máxima verossimilhança de <span class="math inline">\(\alpha\)</span> e a respectiva estimativa corrigida por viés via bootstrap. O trecho acima, temos que 500 réplicas bootstrap, um objeto <code>amostra</code> com a amostra original, <code>fdp_weibull()</code> a função densidade de uma v.a. com distribuição Weibull, os chutes iniciais <span class="math inline">\(\alpha_0 = 1\)</span> e <span class="math inline">\(\beta_0 = 1\)</span> para o método BFGS. O argumento <code>idpar = 1L</code> indica que desejamos corrigir por viés, via bootstrap, o parâmetro <span class="math inline">\(\alpha\)</span> que fixamos em 2.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="tópicos-em-estatística-computacional.html#cb47-1" aria-hidden="true"></a>bootstraping &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">B =</span> 100L, sample_true, f, kicks, <span class="dt">idpar =</span> 1L, ...){</span>
<span id="cb47-2"><a href="tópicos-em-estatística-computacional.html#cb47-2" aria-hidden="true"></a></span>
<span id="cb47-3"><a href="tópicos-em-estatística-computacional.html#cb47-3" aria-hidden="true"></a>  log_likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(par, x){</span>
<span id="cb47-4"><a href="tópicos-em-estatística-computacional.html#cb47-4" aria-hidden="true"></a>    <span class="op">-</span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">f</span>(par, x)))</span>
<span id="cb47-5"><a href="tópicos-em-estatística-computacional.html#cb47-5" aria-hidden="true"></a>  }</span>
<span id="cb47-6"><a href="tópicos-em-estatística-computacional.html#cb47-6" aria-hidden="true"></a></span>
<span id="cb47-7"><a href="tópicos-em-estatística-computacional.html#cb47-7" aria-hidden="true"></a>  <span class="co"># A função resample() obtem uma amostra com reposição de x:</span></span>
<span id="cb47-8"><a href="tópicos-em-estatística-computacional.html#cb47-8" aria-hidden="true"></a>  resample &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</span>
<span id="cb47-9"><a href="tópicos-em-estatística-computacional.html#cb47-9" aria-hidden="true"></a>    n &lt;-<span class="st"> </span><span class="kw">length</span>(x)</span>
<span id="cb47-10"><a href="tópicos-em-estatística-computacional.html#cb47-10" aria-hidden="true"></a>    <span class="co"># Selecionando observações uniformemente distribuídas em x.</span></span>
<span id="cb47-11"><a href="tópicos-em-estatística-computacional.html#cb47-11" aria-hidden="true"></a>    <span class="co"># Poderia ser utilizado a função sample().</span></span>
<span id="cb47-12"><a href="tópicos-em-estatística-computacional.html#cb47-12" aria-hidden="true"></a>    x[<span class="kw">floor</span>(n <span class="op">*</span><span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>1L)]</span>
<span id="cb47-13"><a href="tópicos-em-estatística-computacional.html#cb47-13" aria-hidden="true"></a>  } <span class="co"># Aqui termina a função resample().</span></span>
<span id="cb47-14"><a href="tópicos-em-estatística-computacional.html#cb47-14" aria-hidden="true"></a></span>
<span id="cb47-15"><a href="tópicos-em-estatística-computacional.html#cb47-15" aria-hidden="true"></a>  <span class="co"># A função boot() calcula uma statística em uma única amostra</span></span>
<span id="cb47-16"><a href="tópicos-em-estatística-computacional.html#cb47-16" aria-hidden="true"></a>  <span class="co"># bootstrap:</span></span>
<span id="cb47-17"><a href="tópicos-em-estatística-computacional.html#cb47-17" aria-hidden="true"></a>  boot &lt;-<span class="st"> </span><span class="cf">function</span>(i) {</span>
<span id="cb47-18"><a href="tópicos-em-estatística-computacional.html#cb47-18" aria-hidden="true"></a>    <span class="co">#result &lt;- double(1L)</span></span>
<span id="cb47-19"><a href="tópicos-em-estatística-computacional.html#cb47-19" aria-hidden="true"></a>    <span class="cf">repeat</span> {</span>
<span id="cb47-20"><a href="tópicos-em-estatística-computacional.html#cb47-20" aria-hidden="true"></a>      result &lt;-<span class="st"> </span><span class="kw">optim</span>(<span class="dt">par =</span> kicks, <span class="dt">fn =</span> log_likelihood, <span class="dt">x =</span> <span class="kw">resample</span>(sample_true), ...)</span>
<span id="cb47-21"><a href="tópicos-em-estatística-computacional.html#cb47-21" aria-hidden="true"></a>      <span class="cf">if</span> (result<span class="op">$</span>convergence <span class="op">==</span><span class="st"> </span>0L) {</span>
<span id="cb47-22"><a href="tópicos-em-estatística-computacional.html#cb47-22" aria-hidden="true"></a>        result &lt;-<span class="st"> </span>result<span class="op">$</span>par[idpar]</span>
<span id="cb47-23"><a href="tópicos-em-estatística-computacional.html#cb47-23" aria-hidden="true"></a>        <span class="cf">break</span></span>
<span id="cb47-24"><a href="tópicos-em-estatística-computacional.html#cb47-24" aria-hidden="true"></a>      }</span>
<span id="cb47-25"><a href="tópicos-em-estatística-computacional.html#cb47-25" aria-hidden="true"></a>    }</span>
<span id="cb47-26"><a href="tópicos-em-estatística-computacional.html#cb47-26" aria-hidden="true"></a>    result</span>
<span id="cb47-27"><a href="tópicos-em-estatística-computacional.html#cb47-27" aria-hidden="true"></a>  } <span class="co"># Aqui termina a função boot().</span></span>
<span id="cb47-28"><a href="tópicos-em-estatística-computacional.html#cb47-28" aria-hidden="true"></a></span>
<span id="cb47-29"><a href="tópicos-em-estatística-computacional.html#cb47-29" aria-hidden="true"></a>  purrr<span class="op">::</span><span class="kw">map_dbl</span>(<span class="dt">.x =</span> 1L<span class="op">:</span>B, <span class="dt">.f =</span> boot)</span>
<span id="cb47-30"><a href="tópicos-em-estatística-computacional.html#cb47-30" aria-hidden="true"></a>}</span></code></pre></div>
<p><strong>Descervendo melhor a função <code>bootstraping()</code> acima</strong>:</p>

<div class="rmdobservation">
<div class="text-justify">
<p>O código acima apresenta uma nova implementação da função <code>bootstraping()</code> de forma que, agora, a função irá obter as estimativas de máxima verossimilhança utilizando métodos numéricos. Sendo assim, <code>bootstraping()</code> irá receber como argumento o número de réplicas bootstrap (<code>B</code>), a amostra original (<code>sample_true</code>), uma f.d.p / f.p (<code>f</code>), os chutes iniciais (<code>kicks</code>) para o método iterativo utilizado para minimizar <span class="math inline">\(-\mathcal{l(\pmb \theta)}\)</span>, em que <span class="math inline">\(\mathcal{l}(\cdot)\)</span> é a função de log-verossimilhança e <span class="math inline">\(\theta\)</span> é o vetor de parâmetros que indexa a função f.d.p / f.p passada como argumento à <code>f</code>. O argumento <code>idpar = 1L</code> refere-se à posição do parâmetro que desejamos efetuar a correção de viés via bootstrap (por padrão é o primeiro) do vetor <span class="math inline">\(\pmb \theta\)</span>. O argumento <code>...</code> irá permitir que argumentos adicionais sejam passados à função <code>bootstraping()</code> e aplicados à função <code>optim()</code> utilizada para obtenção das estimativas numéricas. Por exemplo, poderemos passar <code>method = "BFGS"</code> à <code>bootstraping()</code> que é um argumento suportado pela função <code>optim()</code>.</p>
<p>Assim como na implementação anterior da função <code>bootstraping()</code>, no exemplo logo acima, temos que <code>resample()</code> é uma função simples que é resposável por reamostrar com reposição da amostra original passada à <code>sample_true()</code>. A função <code>resample()</code> é utilizada dentro da função <code>boot()</code>. A função <code>boot()</code> obtem as estimativas numéricas de máxima verossimilhaça sobre uma amostra bootstrap. Perceba que utiliza-se a estrutura de repetição <code>repeat</code> para repetir o processo de optimização sobre outra amostras bootstrap, caso não haja convergência do método de otimização, uma vez que <code>result$convergence</code> diferente de zero indica não convergência do método iterativo de minimização. Não haver convergência sobre uma dada amostra bootstrap implica que as estimativas obtidas não são estimativas de máxima verossimilhança. Precisamos que <span class="math inline">\(T_n^*\)</span> sejam estimativas de máxima veorissmilhança, o que convêm substituir uma amostra que não houve convergência por outra amostra em que a convergência é observada.</p>
</div>
</div>
<p>No código abaixo é implementado a função <code>fdp_weibull()</code> que sejá passado como argumento para a função <code>bias_boot()</code> que é responsável por corrigir por viés, via bootstrap, a estimativa de máxima verossimilhança de um dos parâmetros que indexa <code>fdp_weibull()</code>. Por padrão, o argumento é o primeiro, isto é, <code>idpar = 1L</code>. Perceba que a função <code>bias_boot()</code> faz uso da função <code>bootstraping()</code> que é responsável por fazer todo o trabalho pesado. Ao final, <code>bias_boot()</code> retornará uma lista com a estimativa de máxima verossimilhança sem correção e a restivativa corrigida por viés, via bootstrap, respectivamente.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="tópicos-em-estatística-computacional.html#cb48-1" aria-hidden="true"></a><span class="co"># Função densidade da Weibull:</span></span>
<span id="cb48-2"><a href="tópicos-em-estatística-computacional.html#cb48-2" aria-hidden="true"></a>fdp_weibull &lt;-<span class="st"> </span><span class="cf">function</span>(par, x){</span>
<span id="cb48-3"><a href="tópicos-em-estatística-computacional.html#cb48-3" aria-hidden="true"></a>  alpha &lt;-<span class="st"> </span>par[<span class="dv">1</span>]</span>
<span id="cb48-4"><a href="tópicos-em-estatística-computacional.html#cb48-4" aria-hidden="true"></a>  beta &lt;-<span class="st"> </span>par[<span class="dv">2</span>]</span>
<span id="cb48-5"><a href="tópicos-em-estatística-computacional.html#cb48-5" aria-hidden="true"></a>  <span class="kw">dweibull</span>(x, <span class="dt">shape =</span> alpha, <span class="dt">scale =</span> beta)</span>
<span id="cb48-6"><a href="tópicos-em-estatística-computacional.html#cb48-6" aria-hidden="true"></a>}</span>
<span id="cb48-7"><a href="tópicos-em-estatística-computacional.html#cb48-7" aria-hidden="true"></a></span>
<span id="cb48-8"><a href="tópicos-em-estatística-computacional.html#cb48-8" aria-hidden="true"></a>bias_boot &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">B =</span> 100L, sample_true, f, kicks, <span class="dt">idpar =</span> 1L, ...){</span>
<span id="cb48-9"><a href="tópicos-em-estatística-computacional.html#cb48-9" aria-hidden="true"></a></span>
<span id="cb48-10"><a href="tópicos-em-estatística-computacional.html#cb48-10" aria-hidden="true"></a>  log_likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(par, x){</span>
<span id="cb48-11"><a href="tópicos-em-estatística-computacional.html#cb48-11" aria-hidden="true"></a>    <span class="op">-</span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">f</span>(par, x)))</span>
<span id="cb48-12"><a href="tópicos-em-estatística-computacional.html#cb48-12" aria-hidden="true"></a>  }</span>
<span id="cb48-13"><a href="tópicos-em-estatística-computacional.html#cb48-13" aria-hidden="true"></a></span>
<span id="cb48-14"><a href="tópicos-em-estatística-computacional.html#cb48-14" aria-hidden="true"></a>  result &lt;-<span class="st"> </span><span class="kw">optim</span>(<span class="dt">par =</span> kicks, <span class="dt">fn =</span> log_likelihood, <span class="dt">x =</span> sample_true, ...)<span class="op">$</span>par[idpar]</span>
<span id="cb48-15"><a href="tópicos-em-estatística-computacional.html#cb48-15" aria-hidden="true"></a>  result_boot &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>result <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(<span class="kw">bootstraping</span>(B, sample_true, f, kicks, idpar, ...))</span>
<span id="cb48-16"><a href="tópicos-em-estatística-computacional.html#cb48-16" aria-hidden="true"></a></span>
<span id="cb48-17"><a href="tópicos-em-estatística-computacional.html#cb48-17" aria-hidden="true"></a>  <span class="kw">list</span>(<span class="dt">stat =</span> result, <span class="dt">stat_corrigida =</span> result_boot)</span>
<span id="cb48-18"><a href="tópicos-em-estatística-computacional.html#cb48-18" aria-hidden="true"></a></span>
<span id="cb48-19"><a href="tópicos-em-estatística-computacional.html#cb48-19" aria-hidden="true"></a>}</span>
<span id="cb48-20"><a href="tópicos-em-estatística-computacional.html#cb48-20" aria-hidden="true"></a></span>
<span id="cb48-21"><a href="tópicos-em-estatística-computacional.html#cb48-21" aria-hidden="true"></a><span class="kw">set.seed</span>(1L) <span class="co"># Fixando uma semente.</span></span>
<span id="cb48-22"><a href="tópicos-em-estatística-computacional.html#cb48-22" aria-hidden="true"></a><span class="co"># O objeto &quot;amostra&quot; é a amostral original.</span></span>
<span id="cb48-23"><a href="tópicos-em-estatística-computacional.html#cb48-23" aria-hidden="true"></a>amostra &lt;-<span class="st"> </span><span class="kw">rweibull</span>(<span class="dt">n =</span> 30L, <span class="dt">shape =</span> <span class="dv">2</span>, <span class="dt">scale =</span> <span class="dv">2</span>)</span>
<span id="cb48-24"><a href="tópicos-em-estatística-computacional.html#cb48-24" aria-hidden="true"></a><span class="kw">bias_boot</span>(<span class="dt">B =</span> 500L, <span class="dt">sample_true =</span> amostra, <span class="dt">f =</span> fdp_weibull,</span>
<span id="cb48-25"><a href="tópicos-em-estatística-computacional.html#cb48-25" aria-hidden="true"></a>          <span class="dt">kicks =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">idpar =</span> 1L, <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>)</span></code></pre></div>
<pre><code>## $stat
## [1] 2.221581
## 
## $stat_corrigida
## [1] 2.064491</code></pre>
<p>Observe que a estimativa corrigida por bootstrap fornece uma melhor estimativa para o parâmetro <span class="math inline">\(\alpha = 2.\)</span></p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Segundo Efron e Tibshirani, no livro B. Efron and R. J. Tibshirani. <strong>An Introduction to the Bootstrap</strong>. Chapman &amp; Hall/CRC, Boca Raton, FL, 1993, p. 129, se</p>
<p><span class="math display">\[\frac{|\widehat{B(T_n)}|}{\widehat{se}(T_n)_{\mathrm{boot}}} \leq 0.25,\]</span>
em que <span class="math inline">\(\widehat{B(T_n)}\)</span> é o viés do estimador <span class="math inline">\(T_n\)</span> estimado por bootstrap, a correção por viés via bootstrap poderá não ser necessária.</p>
</div>
</div>
<p><strong>Exemplo</strong>: O exemplo abaixo mostra como incorporar uma <strong>barra de progresso</strong> (usando caracteres ASCII) que informará o quão próximo estamos do fim da execução da função <code>bias_boot()</code>. Note a execução repetida de <code>boot()</code>, implementada dentro do escopo da função <code>bootstraping()</code> é o que verdadeiramente torna custosa a execução da função <code>bias_boot()</code>. Dessa forma, escolheu-se dentro de <code>boot()</code> atualizar o progresso usando o comando <code>pb$tick()</code>. Perceba que antes da definição de <code>boot()</code> foi criado o objeto <code>pb</code> da classe <strong>progress_bar</strong>, em que foi informado o número total de chamadas à <code>boot()</code>. Perceba que é necessário instalar o pacote <a href="https://github.com/r-lib/progress"><strong>progress</strong></a> que está disponível nos repositórios do CRAN. Note também que foram utilizadas as funções <code>tic()</code> e <code>toc()</code> do pacote <a href="https://github.com/collectivemedia/tictoc"><strong>tictoc</strong></a> como uma alternativa para marcar o tempo de execução da função <code>bias_boot()</code>. Trata-se de uma alternativa à função <code>system.time()</code> do pacote <strong>base</strong>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="tópicos-em-estatística-computacional.html#cb50-1" aria-hidden="true"></a><span class="kw">library</span>(progress)</span>
<span id="cb50-2"><a href="tópicos-em-estatística-computacional.html#cb50-2" aria-hidden="true"></a>bootstraping &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">B =</span> 100L, sample_true, f, kicks, <span class="dt">idpar =</span> 1L, ...){</span>
<span id="cb50-3"><a href="tópicos-em-estatística-computacional.html#cb50-3" aria-hidden="true"></a>  </span>
<span id="cb50-4"><a href="tópicos-em-estatística-computacional.html#cb50-4" aria-hidden="true"></a>  log_likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(par, x){</span>
<span id="cb50-5"><a href="tópicos-em-estatística-computacional.html#cb50-5" aria-hidden="true"></a>    <span class="op">-</span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">f</span>(par, x)))</span>
<span id="cb50-6"><a href="tópicos-em-estatística-computacional.html#cb50-6" aria-hidden="true"></a>  }</span>
<span id="cb50-7"><a href="tópicos-em-estatística-computacional.html#cb50-7" aria-hidden="true"></a>  </span>
<span id="cb50-8"><a href="tópicos-em-estatística-computacional.html#cb50-8" aria-hidden="true"></a>  <span class="co"># A função resample() obtem uma amostra com reposição de x:</span></span>
<span id="cb50-9"><a href="tópicos-em-estatística-computacional.html#cb50-9" aria-hidden="true"></a>  resample &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</span>
<span id="cb50-10"><a href="tópicos-em-estatística-computacional.html#cb50-10" aria-hidden="true"></a>    n &lt;-<span class="st"> </span><span class="kw">length</span>(x)</span>
<span id="cb50-11"><a href="tópicos-em-estatística-computacional.html#cb50-11" aria-hidden="true"></a>    <span class="co"># Selecionando observações uniformemente distribuídas em x.</span></span>
<span id="cb50-12"><a href="tópicos-em-estatística-computacional.html#cb50-12" aria-hidden="true"></a>    <span class="co"># Poderia ser utilizado a função sample().</span></span>
<span id="cb50-13"><a href="tópicos-em-estatística-computacional.html#cb50-13" aria-hidden="true"></a>    x[<span class="kw">floor</span>(n <span class="op">*</span><span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>1L)]</span>
<span id="cb50-14"><a href="tópicos-em-estatística-computacional.html#cb50-14" aria-hidden="true"></a>  } <span class="co"># Aqui termina a função resample().</span></span>
<span id="cb50-15"><a href="tópicos-em-estatística-computacional.html#cb50-15" aria-hidden="true"></a>  </span>
<span id="cb50-16"><a href="tópicos-em-estatística-computacional.html#cb50-16" aria-hidden="true"></a>  <span class="co"># A função boot() calcula uma statística em uma única amostra</span></span>
<span id="cb50-17"><a href="tópicos-em-estatística-computacional.html#cb50-17" aria-hidden="true"></a>  <span class="co"># bootstrap:</span></span>
<span id="cb50-18"><a href="tópicos-em-estatística-computacional.html#cb50-18" aria-hidden="true"></a>  pb &lt;-<span class="st"> </span>progress_bar<span class="op">$</span><span class="kw">new</span>(<span class="dt">total =</span> B) <span class="co"># objeto progress_bar.</span></span>
<span id="cb50-19"><a href="tópicos-em-estatística-computacional.html#cb50-19" aria-hidden="true"></a>  boot &lt;-<span class="st"> </span><span class="cf">function</span>(i) {</span>
<span id="cb50-20"><a href="tópicos-em-estatística-computacional.html#cb50-20" aria-hidden="true"></a>    <span class="co">#result &lt;- double(1L)</span></span>
<span id="cb50-21"><a href="tópicos-em-estatística-computacional.html#cb50-21" aria-hidden="true"></a>    <span class="cf">repeat</span> {</span>
<span id="cb50-22"><a href="tópicos-em-estatística-computacional.html#cb50-22" aria-hidden="true"></a>      result &lt;-<span class="st"> </span><span class="kw">optim</span>(<span class="dt">par =</span> kicks, <span class="dt">fn =</span> log_likelihood, <span class="dt">x =</span> <span class="kw">resample</span>(sample_true), ...)</span>
<span id="cb50-23"><a href="tópicos-em-estatística-computacional.html#cb50-23" aria-hidden="true"></a>      <span class="cf">if</span> (result<span class="op">$</span>convergence <span class="op">==</span><span class="st"> </span>0L) {</span>
<span id="cb50-24"><a href="tópicos-em-estatística-computacional.html#cb50-24" aria-hidden="true"></a>        result &lt;-<span class="st"> </span>result<span class="op">$</span>par[idpar]</span>
<span id="cb50-25"><a href="tópicos-em-estatística-computacional.html#cb50-25" aria-hidden="true"></a>        <span class="cf">break</span></span>
<span id="cb50-26"><a href="tópicos-em-estatística-computacional.html#cb50-26" aria-hidden="true"></a>      }</span>
<span id="cb50-27"><a href="tópicos-em-estatística-computacional.html#cb50-27" aria-hidden="true"></a>    }</span>
<span id="cb50-28"><a href="tópicos-em-estatística-computacional.html#cb50-28" aria-hidden="true"></a>    pb<span class="op">$</span><span class="kw">tick</span>() <span class="co"># Dando um tick().</span></span>
<span id="cb50-29"><a href="tópicos-em-estatística-computacional.html#cb50-29" aria-hidden="true"></a>    result</span>
<span id="cb50-30"><a href="tópicos-em-estatística-computacional.html#cb50-30" aria-hidden="true"></a>  } <span class="co"># Aqui termina a função boot().</span></span>
<span id="cb50-31"><a href="tópicos-em-estatística-computacional.html#cb50-31" aria-hidden="true"></a>  purrr<span class="op">::</span><span class="kw">map_dbl</span>(<span class="dt">.x =</span> 1L<span class="op">:</span>B, <span class="dt">.f =</span> boot)</span>
<span id="cb50-32"><a href="tópicos-em-estatística-computacional.html#cb50-32" aria-hidden="true"></a>}</span>
<span id="cb50-33"><a href="tópicos-em-estatística-computacional.html#cb50-33" aria-hidden="true"></a><span class="kw">set.seed</span>(1L) <span class="co"># Fixando uma semente.</span></span>
<span id="cb50-34"><a href="tópicos-em-estatística-computacional.html#cb50-34" aria-hidden="true"></a><span class="co"># O objeto &quot;amostra&quot; é a amostral original.</span></span>
<span id="cb50-35"><a href="tópicos-em-estatística-computacional.html#cb50-35" aria-hidden="true"></a>amostra &lt;-<span class="st"> </span><span class="kw">rweibull</span>(<span class="dt">n =</span> 30L, <span class="dt">shape =</span> <span class="dv">2</span>, <span class="dt">scale =</span> <span class="dv">2</span>)</span>
<span id="cb50-36"><a href="tópicos-em-estatística-computacional.html#cb50-36" aria-hidden="true"></a></span>
<span id="cb50-37"><a href="tópicos-em-estatística-computacional.html#cb50-37" aria-hidden="true"></a>tictoc<span class="op">::</span><span class="kw">tic</span>()</span>
<span id="cb50-38"><a href="tópicos-em-estatística-computacional.html#cb50-38" aria-hidden="true"></a><span class="kw">bias_boot</span>(<span class="dt">B =</span> <span class="fl">2e3</span>L, <span class="dt">sample_true =</span> amostra, <span class="dt">f =</span> fdp_weibull,</span>
<span id="cb50-39"><a href="tópicos-em-estatística-computacional.html#cb50-39" aria-hidden="true"></a>          <span class="dt">kicks =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">idpar =</span> 1L, <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>)</span>
<span id="cb50-40"><a href="tópicos-em-estatística-computacional.html#cb50-40" aria-hidden="true"></a>tictoc<span class="op">::</span><span class="kw">toc</span>()</span></code></pre></div>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>O uso de uma barra informativa sobre o status da execução de uma função poderá adicionar custos computacionais.</p>
</div>
</div>
</div>
<div id="construindo-intervalos-aleatórios" class="section level3" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> Construindo intervalos aleatórios</h3>
<p>Um intervalo de confiança (IC) é uma estimativa intervalar para um parâmetro de interesse de uma população. Em vez de estimar o parâmetro por um único valor (estimativa pontual), o intervalo de confiança fornece um conjunto de estimativas possíveis para esse parâmetro de interesse através de um intervalo aleatório. Estimativas intervalares são realizadas sob um nível de confiança <span class="math inline">\(1-\alpha\)</span>, com <span class="math inline">\(\alpha \in (0,1)\)</span>, em que <span class="math inline">\(\alpha\)</span> é o nível de significância adotado e fixado pelo pesquisador. Um intervalo <span class="math inline">\(I_{\gamma}\)</span> (intervalo de nível <span class="math inline">\(\gamma\)</span>) para o parâmetro <span class="math inline">\(\theta\)</span> é tal que
<span class="math display">\[\begin{equation}
P(I_\gamma\,\, \mathrm{conter}\,\, \theta) = \gamma.
\end{equation}\]</span></p>
<p>Um intervalo de confiança bilateral é delimitado pelos limites inferior e superior <span class="math inline">\(\ell_{\frac{\alpha_1}{2}}\)</span> e <span class="math inline">\(\ell_{1-\frac{\alpha_2}{2}}\)</span> respectivamente, em que, <span class="math inline">\(\alpha_1\)</span> e <span class="math inline">\(\alpha_2\)</span> pertencem ao conjunto de valores possíveis de <span class="math inline">\(\alpha\)</span>, tal que
<span class="math display">\[\begin{equation}
P\left(\theta &lt; \ell_{\frac{\alpha_1}{2}}\right) = \frac{\alpha_1}{2}\,\,\,\, \mathrm{e}\,\,\,\, P\left(\theta &lt; \ell_{1-\frac{\alpha_2}{2}} \right) = 1 - \frac{\alpha_2}{2}.
\end{equation}\]</span></p>
<p>A cobertura do intervalo <span class="math inline">\(\left[\ell_{\alpha_1/2},\ell_{1-\alpha_2/2}\right]\)</span> é <span class="math inline">\(\gamma = 1 - (\frac{\alpha_1}{2}+\frac{\alpha_2}{2})\)</span>, com <span class="math inline">\(\alpha_1/2+\alpha_2/2 = \alpha\)</span>, sendo <span class="math inline">\(\alpha_1/2\)</span> e <span class="math inline">\(\alpha_2/2\)</span> os erros de coberturas à esquerda e à direta do intervalo <span class="math inline">\(I_\gamma\)</span>, respectivamente. As escolhas de <span class="math inline">\(\alpha_1\)</span> e <span class="math inline">\(\alpha_2\)</span> devem ser feitas de forma que a amplitude de <span class="math inline">\(I_{\gamma}\)</span> seja a menor possível. Na prática é usual escolher <span class="math inline">\(\alpha_1\)</span> e <span class="math inline">\(\alpha_2\)</span> de modo que
<span class="math display">\[P\left(\theta &lt; \ell_{\frac{\alpha_1}{2}}\right) = P\left(\theta &gt; \ell_{1-\frac{\alpha_2}{2}}\right) = \frac{\alpha}{2}.\]</span></p>
<p>Uma abordagem frequentemente utilizada na construção de intervalos de confiança paramétricos é considerar um estimador <span class="math inline">\(\widehat{\theta}\)</span> para um parâmetro <span class="math inline">\(\theta\)</span> da população, em que <span class="math inline">\(\widehat{\theta}\)</span> é usualmente um estimador de máxima verossimilhança de <span class="math inline">\(\theta\)</span>. Queremos encontrar um intervalo que contenha <span class="math inline">\(\theta\)</span> com <span class="math inline">\(100\gamma\%\)</span> de confiança. Seja <span class="math inline">\(T_n\)</span> um estimador do escalar <span class="math inline">\(\theta\)</span> baseado em <span class="math inline">\(n\)</span> observações e <span class="math inline">\(t\)</span> sua estimativa. Por simplicidade, suponhamos que <span class="math inline">\(T_n\)</span> seja uma variável aleatória contínua. Denotando-se o <span class="math inline">\(p\)</span>-ésimo quantil da distribuição da variável aleatória <span class="math inline">\(T_n - \theta\)</span> por <span class="math inline">\(a_p\)</span>, temos que
<span class="math display">\[\begin{equation}\label{eq:ic_parametrico}
P\left(T_n - \theta \leq a_{\frac{\alpha_1}{2}}\right) = \frac{\alpha}{2} = P\left(T_n - \theta \geq a_{1-\frac{\alpha_2}{2}}\right).
\end{equation}\]</span></p>
<p>Como a quantidade <span class="math inline">\(Q = T_n - \theta\)</span> é inversível em <span class="math inline">\(\theta\)</span> e <span class="math inline">\(T_n\)</span> depende apenas da amostra, podemos construir o intervalo de confiança para <span class="math inline">\(\theta\)</span> reescrevendo os eventos, ou seja, podemos reescrever os eventos <span class="math inline">\(T_n -\theta \leq a_{\frac{\alpha_1}{2}}\)</span> e <span class="math inline">\(T_n - \theta \geq a_{1-\frac{\alpha_2}{2}}\)</span> como <span class="math inline">\(\theta &gt; T_n - a_{\frac{\alpha_1}{2}}\)</span> e <span class="math inline">\(\theta &lt; T_n - a_{1-\frac{\alpha_2}{2}}\)</span>, respectivamente. Assim, o intervalo de confiança de nível <span class="math inline">\(\gamma\)</span> é dado pelos limites
<span class="math display">\[\begin{equation}\label{eq:limites_de_confiancas}
\ell_{\alpha/2} = t - a_{1-\frac{\alpha_2}{2}}, \, \, \ell_{1-\alpha/2} = t - a_{\frac{\alpha_1}{2}}.
\end{equation}\]</span></p>
<p>Em situações em que o intervalo bilateral é de interesse, a soma de <span class="math inline">\(\alpha_1/2\)</span> e <span class="math inline">\(\alpha_2/2\)</span> é igual a <span class="math inline">\(\alpha\)</span>. Quando estamos interessados em intervalos simétricos, temos que <span class="math inline">\(\alpha_1 = \alpha_2 = \alpha\)</span>. Assim, a “<strong>forma geral</strong>” de um intervalo de confiança para um parâmetro <span class="math inline">\(\theta\)</span> é:</p>
<p><span class="math display">\[\begin{equation}\label{eq:ic_geral}
\ell_{\alpha/2} = t - a_{1-\alpha/2}, \, \, \ell_{1-\alpha/2} = t - a_{\alpha/2}.
\end{equation}\]</span></p>
<p>Para os casos em que apenas um dos limites é de interesse, ou seja, o pesquisador está interessado na construção de intervalos de confiança unilaterais, temos que os limites para construção dos intervalos unilateral inferior e unilateral superior são dados por <span class="math inline">\(\ell_{1-\alpha}\)</span> e <span class="math inline">\(\ell_{\alpha}\)</span> respectivamente. Os limites serão obtidos de tal forma que <span class="math inline">\(P\left(\theta &lt; \ell_{\alpha}\right) = P\left(\theta &gt; \ell_{1-\alpha}\right) = \alpha\)</span>.</p>
<div id="bootstrap-percentil" class="section level4" number="6.5.3.1">
<h4><span class="header-section-number">6.5.3.1</span> Bootstrap Percentil</h4>
<p>Davison, A. C. e Hinkley, D. V, em <strong>Bootstrap methods and their application</strong>, Vol. 1, Cambridge university press, p. 202, (1997) afirma que existe alguma transformação de <span class="math inline">\(T_n\)</span>, <span class="math inline">\(U = h(T_n)\)</span>, tal que <span class="math inline">\(U\)</span> possui uma distribuição simétrica. Suponhamos que sabemos calcular o intervalo de confiança de nível <span class="math inline">\(1-\alpha\)</span> para <span class="math inline">\(\phi = h(\theta)\)</span>. Segundo Davison, A. C. e Hinkley, D. V (1997), podemos utilizar bootstrap para obter uma aproximação da distribuição de <span class="math inline">\(T_n-\theta\)</span> utilizando a distribuição de <span class="math inline">\(T_n^* - t\)</span>. Dessa forma, estimamos o <span class="math inline">\(p\)</span>-ésimo quantil de <span class="math inline">\(T_n-\theta\)</span> pelo <span class="math inline">\((B+1)p\)</span>-ésimo valor ordenado de <span class="math inline">\(t^* - t\)</span>, ou seja, o <span class="math inline">\(p\)</span>-ésimo quantil de <span class="math inline">\(T_n-\theta\)</span> é estimado por <span class="math inline">\(t_{((B+1)p)}^*-t\)</span>. Analogamente, o <span class="math inline">\(p\)</span>-ésimo quantil de <span class="math inline">\(h(T_n)-h(\theta) = U - \phi\)</span> poderá ser estimado pelo <span class="math inline">\((B+1)p\)</span>-ésimo valor ordenado de <span class="math inline">\(h(T_n^*)-h(t) = u^* - u\)</span>. Seja <span class="math inline">\(b_p\)</span> o <span class="math inline">\(p\)</span>-ésimo quantil de <span class="math inline">\(U-\phi\)</span>. Como <span class="math inline">\(U\)</span> tem distribuição simétrica, então <span class="math inline">\(U-\phi\)</span> também tem distribuição simétrica, logo é verdade que <span class="math inline">\(b_\frac{\alpha}{2} = - b_{1-\frac{\alpha}{2}}\)</span>. Utilizando a forma geral para intervalos de confiança e a simetria de <span class="math inline">\(U-\phi\)</span>, temos que <span class="math inline">\(h(\ell_{\alpha/2}) = u+b_{\alpha/2}\)</span> e <span class="math inline">\(h(\ell_{1-\alpha/2}) = u + b_{1-\alpha/2}\)</span>. Como <span class="math inline">\(b_{\alpha/2}\)</span> e <span class="math inline">\(b_{1-\alpha/2}\)</span> são quantis da distribuição de <span class="math inline">\(U-\phi\)</span> e sabemos calcular os quantis dessa distribuição, temos que os limites inferior e superior de confiança são dados por <span class="math inline">\(u + (u_{((B+1)\alpha/2)}^* - u)\)</span> e <span class="math inline">\(u + (u_{((B+1)(1-\alpha/2))}^* - u)\)</span>, respectivamente, implicando os limites</p>
<p><span class="math display">\[u_{((B+1)\alpha/2)}^*, \,\,\,\, u_{((B+1)(1-\alpha/2))}^*,\]</span>
cuja transformação para <span class="math inline">\(\theta\)</span> é</p>
<p><span class="math display">\[t_{(B+1)\alpha/2}^{*}, \,\,\,\, t_{(B+1)(1-\alpha/2)}^{*}.\]</span></p>
<p>Observe que não precisamos conhecer a transformação <span class="math inline">\(h\)</span>. O intervalo de nível <span class="math inline">\(1-\alpha\)</span> para o parâmetro <span class="math inline">\(\theta\)</span> não envolve <span class="math inline">\(h\)</span> e pode ser calculado sem o conhecimento desta transformação. O intervalo acima é conhecido como intervalo bootstrap percentil. Segundo Davison, A. C. &amp; Hinkley (1997), p. 203, o método percentil poderá ser aplicado a qualquer estatística.</p>
<p><strong>Nota</strong>:</p>

<div class="rmdnote">
<div class="text-justify">
<p>Segundo B. Efron and R. J. Tibshirani. <strong>An Introduction to the Bootstrap</strong>. Chapman &amp; Hall/CRC, Boca Raton, FL, 1993, p. 160, se <span class="math inline">\((B+1)\alpha/2\)</span> não é inteiro, devemos considerar como limite inferior, o valor na posição <span class="math inline">\(\lfloor(B+1)\alpha/2\rfloor\)</span> do vetor ordenado <span class="math inline">\(t_1^*, \ldots, t_B^*\)</span>, em que <span class="math inline">\(\lfloor\,\, x \,\,\rfloor\)</span> é a a parte inteira de <span class="math inline">\(x\)</span>, isto é,</p>
<p><span class="math display">\[\lfloor\,\, x \,\,\rfloor = \max\{n \in \mathbb{Z}\, :\, n \leq x\}.\]</span></p>
<p>Como limite superior do intervalo, tome o valor na posição <span class="math inline">\((B + 1 - k)\)</span> do vetor ordenado. No <a href="https://www.r-project.org/"><strong>R</strong></a>, utilize a função <code>quantile()</code> para obter os quantis desejados do vetor <span class="math inline">\(t_1^*, \ldots, t_B^*\)</span>.</p>
</div>
</div>
<!-- ### Teste de hipótes -->
</div>
</div>
</div>
<div id="exercício-4" class="section level2 unnumbered">
<h2>Exercício</h2>
<ol style="list-style-type: decimal">
<li><p>Defina função de distribuição empírica <span class="math inline">\(F_n(\cdot)\)</span>. Implemente a função <code>empirical(data, t)</code> que recebe como argumento um conjunto de dados passado como argumento à <code>data</code> e retorna <span class="math inline">\(F_n(t)\)</span>.</p></li>
<li><p>Descreva, com poucas palavras, o método de reamostragem bootstrap e cite a diferença do bootstrap paramétrico para o bootstrap paramétrico. Explique.</p></li>
<li><p>Explique o porquê reamostramos com reposição de <span class="math inline">\(\pmb x = (x_1, \ldots, x_n)\)</span>, em que <span class="math inline">\(\pmb x\)</span> é a amostra original, quando estamos fazendo uso de bootstrap não-paramétrico.</p></li>
<li><p>Seja <span class="math inline">\(\pmb X^* = (X_1^*, X_2^*, \ldots, X_n^*)\)</span> uma amostra aleatória bootstrap. Qual a distribuição teórica de <span class="math inline">\(X_i^*\)</span>, com <span class="math inline">\(i = 1, \ldots, n\)</span>? Explique.</p></li>
<li><p>Seja <span class="math inline">\(T_n\)</span> um estimador qualquer. Defina o estimador bootstrap para obtenção da estimativa do erro-padrão de <span class="math inline">\(T_n\)</span>.</p></li>
<li><p>Defina o que o viés de um estimador <span class="math inline">\(T_n\)</span> qualquer e denote por <span class="math inline">\(B(T_n)\)</span>. Como podemos utilizar o método bootstrap para obtenção da estimativa do viés de <span class="math inline">\(T_n\)</span> via bootstrap? Explique.</p></li>
<li><p>O estimador <span class="math inline">\(T_n\)</span> corrigido por viés via bootstrap é dado por <span class="math inline">\(T_n^{\mathrm{corrigido-boot}} = 2T_n - \overline{T_n^{*}}\)</span>. Explique como essa correção é obtida.</p></li>
<li><p>Suponha que <span class="math inline">\(T_n = \overline{X}\)</span> e considere <span class="math inline">\(\pmb x = (x_1, \ldots, x_n)\)</span> observações de uma amostra aleatória <span class="math inline">\(\pmb X = (X_1, \ldots, X_n)\)</span>, em que <span class="math inline">\(X_i \sim \mathrm{Exp}\Big(\lambda = \frac{1}{2}\Big)\)</span>, com <span class="math inline">\(i = 1, \ldots, n\)</span>. Para <span class="math inline">\(n = 50\)</span>, construa uma simulação de MC par avaliar <span class="math inline">\(\widehat{se}(T_n)_{\mathrm{boot}}\)</span> e <span class="math inline">\(\widehat{B(T_n)}_{\mathrm{boot}}\)</span>. Discuta o resultado. <strong>Dica</strong>: considere 100 mil réplicas de MC e ao final obtenha a média das estimativas de <span class="math inline">\(\widehat{se}(T_n)_{\mathrm{boot}}\)</span> e <span class="math inline">\(\widehat{B(T_n)}_{\mathrm{boot}}\)</span>.</p></li>
<li><p>Implemente o exercício anteiror de forma paralela. Obtenha o <strong>speedup</strong>.</p></li>
<li><p>Defina o método bootstrap percentil para obtenção de um intervalo aleatório para um parâmetro.</p></li>
<li><p>Implemente a função <code>percentile_boot(B = 250L, fun, alpha = 0.05, ...)</code> que obtém um intervalo aleatório para algum parâmetro que indexa uma função densidade de probabilidade passada como argumento à <code>fun</code>, sendo <code>B</code> a quantidade de réplicas bootstrap considerada (padrão 250) e <span class="math inline">\(\alpha\)</span> o nível de significância adotado (padrão <code>alpha = 0.05</code>). Considere <span class="math inline">\(\widehat{T_n}\)</span> a estimativa de máxima verossimilhança do parâmetro ao qual se deseja construir o intervalo. <strong>Dicas</strong>: [1] as estimativas <span class="math inline">\(t\)</span> obtida por <span class="math inline">\(\widehat{T_n}\)</span> são construídas de forma numérica. Assim, você terá que minimizar <span class="math inline">\(-\mathcal{l}(\theta)\)</span> usando a função <code>optim()</code>, em que <span class="math inline">\(\mathcal{l}(\theta)\)</span> é a função de log-verossimilhança. [2] Considere o método <strong>BFGS</strong>. [3] Lembre-se de descartar as amostras bootstrap em que não houveram convergência do método <strong>BFGS</strong>. Substituia essas amostras por outra em que a convergência poderá ser observada.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="r-miscelânea-e-tópicos-avançados.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin"],
"google": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/prdm0/aulas_computacional/edit/master/topicos_estatistica_computacional.Rmd",
"text": "Editar"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": null
},
"toolbar": {
"position": "fixed",
"download": ["aulas_r.pdf", "Aulas de R"],
"search": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
